{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 2: Deep Bag-of-Words\n",
    "\n",
    "![words.jpeg](https://cdn-images-1.medium.com/max/1600/0*JpqZhCNsQ_OGaRkB.jpg)\n",
    "\n",
    "<br>\n",
    "\n",
    "In this homework, you will be implementing a deep averaging network, detailed in [Deep Unordered Composition  Rivals Syntactic Methods for Text Classification by Iyyer et al. (2015)](https://people.cs.umass.edu/~miyyer/pubs/2015_acl_dan.pdf) and training it to do sentiment analysis on the Stanford Sentiment Treebank.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Please use all of the starter code that is provided, do not make any changes to the data processing, evaluation, and training functions. Only add code were you're asked to.**\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0: Read Paper!\n",
    "\n",
    "Read [Deep Unordered Composition  Rivals Syntactic Methods for Text Classification by Iyyer et al. (2015)](https://people.cs.umass.edu/~miyyer/pubs/2015_acl_dan.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "\n",
    "Make sure you've downloaded the Stanford Sentiment Treebank that was used in lab. You can find it [here](http://nlp.stanford.edu/sentiment/trainDevTestTrees_PTB.zip)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import re\n",
    "import random\n",
    "\n",
    "random.seed(1)\n",
    "sst_home = '../data/trees'\n",
    "\n",
    "# Let's do 2-way positive/negative classification instead of 5-way\n",
    "easy_label_map = {0:0, 1:0, 2:None, 3:1, 4:1}\n",
    "    # so labels of 0 and 1 in te 5-wayclassificaiton are 0 in the 2-way. 3 and 4 are 1, and 2 is none\n",
    "    # because we don't have a neautral class. \n",
    "\n",
    "PADDING = \"<PAD>\"\n",
    "UNKNOWN = \"<UNK>\"\n",
    "max_seq_length = 20\n",
    "\n",
    "def load_sst_data(path):\n",
    "    data = []\n",
    "    with open(path) as f:\n",
    "        for i, line in enumerate(f): \n",
    "            example = {}\n",
    "            example['label'] = easy_label_map[int(line[1])]\n",
    "            if example['label'] is None:\n",
    "                continue\n",
    "            \n",
    "            # Strip out the parse information and the phrase labels---we don't need those here\n",
    "            text = re.sub(r'\\s*(\\(\\d)|(\\))\\s*', '', line)\n",
    "            example['text'] = text[1:]\n",
    "            data.append(example)\n",
    "\n",
    "    random.seed(1)\n",
    "    random.shuffle(data)\n",
    "    return data\n",
    "     \n",
    "training_set = load_sst_data(sst_home + '/train.txt')\n",
    "dev_set = load_sst_data(sst_home + '/dev.txt')\n",
    "test_set = load_sst_data(sst_home + '/test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 0,\n",
       " 'text': 'Yet another entry in the sentimental oh-those-wacky-Brits genre that was ushered in by The Full Monty and is still straining to produce another smash hit .'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Next, we'll extract the vocabulary from the data, index each token, and finally convert the sentences into lists of indexed tokens. We are also padding and truncating all sentences to be of length=20. (Why? Think about how to handle batching. This is certainly not the only way! This is just simple.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "\n",
    "def tokenize(string):\n",
    "    return string.split()\n",
    "\n",
    "def build_dictionary(training_datasets):\n",
    "    \"\"\"\n",
    "    Extract vocabulary and build dictionary.\n",
    "    \"\"\"  \n",
    "    word_counter = collections.Counter()\n",
    "    for i, dataset in enumerate(training_datasets):\n",
    "        for example in dataset:\n",
    "            word_counter.update(tokenize(example['text']))\n",
    "        \n",
    "    vocabulary = set([word for word in word_counter])\n",
    "    vocabulary = list(vocabulary)\n",
    "    vocabulary = [PADDING, UNKNOWN] + vocabulary\n",
    "        \n",
    "    word_indices = dict(zip(vocabulary, range(len(vocabulary))))\n",
    "\n",
    "    return word_indices, len(vocabulary)\n",
    "\n",
    "def sentences_to_padded_index_sequences(word_indices, datasets):\n",
    "    \"\"\"\n",
    "    Annotate datasets with feature vectors. Adding right-sided padding. \n",
    "    \"\"\"\n",
    "    for i, dataset in enumerate(datasets):\n",
    "        for example in dataset:\n",
    "            example['text_index_sequence'] = torch.zeros(max_seq_length)\n",
    "\n",
    "            token_sequence = tokenize(example['text'])\n",
    "            padding = max_seq_length - len(token_sequence)\n",
    "\n",
    "            for i in range(max_seq_length):\n",
    "                if i >= len(token_sequence):\n",
    "                    index = word_indices[PADDING]\n",
    "                    pass\n",
    "                else:\n",
    "                    if token_sequence[i] in word_indices:\n",
    "                        index = word_indices[token_sequence[i]]\n",
    "                    else:\n",
    "                        index = word_indices[UNKNOWN]\n",
    "                example['text_index_sequence'][i] = index\n",
    "\n",
    "            example['text_index_sequence'] = example['text_index_sequence'].long().view(1,-1)\n",
    "            example['label'] = torch.LongTensor([example['label']])\n",
    "\n",
    "word_to_ix, vocab_size = build_dictionary([training_set])\n",
    "sentences_to_padded_index_sequences(word_to_ix, [training_set, dev_set, test_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training dataset: 6920\n",
      "\n",
      "First padded and indexified example in training data:\n",
      " {'label': tensor([0]), 'text': 'Yet another entry in the sentimental oh-those-wacky-Brits genre that was ushered in by The Full Monty and is still straining to produce another smash hit .', 'text_index_sequence': tensor([[ 4410, 12716,  3459,  9673,  6399, 11051,  1896,  5111, 15685, 14067,\n",
      "          1971,  9673,  6472,  6343,  3764,  4027, 14005,  1169,  8664,  4343]])}\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of training dataset:\", len(training_set))\n",
    "print(\"\\nFirst padded and indexified example in training data:\\n\", training_set[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "### Batichify data\n",
    "We're going to be doign mini-batch training. The following code makes data iterators and a batchifying function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the iterator we'll use during training. \n",
    "# It's a generator that gives you one batch at a time.\n",
    "def data_iter(source, batch_size):\n",
    "    dataset_size = len(source)\n",
    "    start = -1 * batch_size\n",
    "    order = list(range(dataset_size))\n",
    "    random.shuffle(order)\n",
    "\n",
    "    while True:\n",
    "        start += batch_size\n",
    "        if start > dataset_size - batch_size:\n",
    "            # Start another epoch.\n",
    "            start = 0\n",
    "            random.shuffle(order)   \n",
    "        batch_indices = order[start:start + batch_size]\n",
    "        batch = [source[index] for index in batch_indices]\n",
    "        yield [source[index] for index in batch_indices]\n",
    "\n",
    "# This is the iterator we use when we're evaluating our model. \n",
    "# It gives a list of batches that you can then iterate through.\n",
    "def eval_iter(source, batch_size):\n",
    "    batches = []\n",
    "    dataset_size = len(source)\n",
    "    start = -1 * batch_size\n",
    "    order = list(range(dataset_size))\n",
    "    random.shuffle(order)\n",
    "\n",
    "    while start < dataset_size - batch_size:\n",
    "        start += batch_size\n",
    "        batch_indices = order[start:start + batch_size]\n",
    "        batch = [source[index] for index in batch_indices]\n",
    "        if len(batch) == batch_size:\n",
    "            batches.append(batch)\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "    return batches\n",
    "\n",
    "# The following function gives batches of vectors and labels, \n",
    "# these are the inputs to your model and loss function\n",
    "def get_batch(batch):\n",
    "    vectors = []\n",
    "    labels = []\n",
    "    for dict in batch:\n",
    "        vectors.append(dict[\"text_index_sequence\"])\n",
    "        labels.append(dict[\"label\"])\n",
    "    return vectors, labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "We'll be looking at accuracy as our evaluation metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function outputs the accuracy on the dataset, we will use it during training.\n",
    "def evaluate(model, data_iter):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i in range(len(data_iter)):\n",
    "        vectors, labels = get_batch(data_iter[i])\n",
    "        vectors = torch.stack(vectors).squeeze()\n",
    "        labels = torch.stack(labels).squeeze()\n",
    "\n",
    "        output = model(vectors)\n",
    "        \n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "      \n",
    "    return correct / float(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Training Loop\n",
    "\n",
    "The following function trains the model and reports model accuracy on the train and dev set every 5 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(batch_size, num_epochs, model, loss_, optim, training_iter, dev_iter,\n",
    "                  train_eval_iter, verbose=True):\n",
    "    step = 0\n",
    "    epoch = 0\n",
    "    total_batches = int(len(training_set) / batch_size)\n",
    "    accuracies = []\n",
    "    while epoch <= num_epochs:\n",
    "        model.train()\n",
    "        vectors, labels = get_batch(next(training_iter)) \n",
    "        vectors = torch.stack(vectors).squeeze() # batch_size, seq_len\n",
    "        labels = torch.stack(labels).squeeze()\n",
    "        \n",
    "    \n",
    "        model.zero_grad()\n",
    "        \n",
    "        output = model(vectors)\n",
    "\n",
    "        lossy = loss_(output, labels)\n",
    "        lossy.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "        optim.step()\n",
    "        \n",
    "\n",
    "        if step % total_batches == 0:\n",
    "            model.eval()\n",
    "            if epoch % 5 == 0:\n",
    "                train_acc = evaluate(model, train_eval_iter)\n",
    "                eval_acc = evaluate(model, dev_iter)\n",
    "                accuracies.append(eval_acc)\n",
    "                if verbose:\n",
    "                    print(\"Epoch %i; Step %i; Loss %f; Train acc: %f; Dev acc %f\" \n",
    "                          %(epoch, step, lossy.item(),\\\n",
    "                            train_acc, eval_acc))\n",
    "            epoch += 1\n",
    "        step += 1\n",
    "    \n",
    "    best_dev = max(accuracies)\n",
    "    print(\"Best dev accuracy is {}\".format(best_dev))\n",
    "    return best_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Part 1: Implement DAN (40 points)\n",
    "\n",
    "Following the [paper](https://people.cs.umass.edu/~miyyer/pubs/2015_acl_dan.pdf), implement the Deep Averaging Network (DAN).\n",
    "\n",
    "Implementation details,\n",
    "- Instead of using \\code{tanh} activations however, use \\code{ReLU}. \n",
    "- Make the number of layers a variable, not a fixed value.\n",
    "- Make sure to implement word-dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DAN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, output_size, \n",
    "                 batch_size, n_layers, drop_rate):\n",
    "        super(DAN, self).__init__()\n",
    "        \n",
    "        self.embed = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.embedding_size = embedding_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.batch_size = batch_size\n",
    "        self.n_layers = n_layers\n",
    "        self.drop_rate = drop_rate\n",
    "        \n",
    "        \"\"\"\n",
    "        YOUR CODE GOES HERE\n",
    "        \"\"\"\n",
    "        self.network_dropout = nn.Dropout(0.1)\n",
    "        self.ReLU = nn.ReLU()\n",
    "        self.layer_0 = nn.Linear(self.embedding_size, self.hidden_size)\n",
    "        \n",
    "        for i in range(1, self.n_layers):\n",
    "            setattr(self, \"l{}\".format(i), nn.Linear(self.hidden_size, self.hidden_size))\n",
    "        \n",
    "        self.decoder = nn.Linear(self.hidden_size, self.output_size)\n",
    "        self.init_weights()\n",
    "    \n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        YOUR CODE GOES HERE\n",
    "        \"\"\"\n",
    "        # input -> (batch_size, seq_len)\n",
    "        batch_size, seq_len = input.size()\n",
    "        new_seq_len = int(np.ceil(seq_len*(1-drop_rate)))\n",
    "        random_indices = [torch.randperm(seq_len)[:new_seq_len] for x in range(batch_size)]\n",
    "        new_input = torch.zeros(batch_size, new_seq_len)\n",
    "        \n",
    "        for x in range(batch_size):\n",
    "            new_input[x] = input[x][random_indices[x]]\n",
    "            \n",
    "        embed = self.embed(new_input.long()) # -> batch_size, seq_len, embedding_size\n",
    "        embed = torch.mean(embed, 1) # mean over sequence, i.e. all words in the sentence\n",
    "        \n",
    "        hidden = self.ReLU(self.network_dropout(self.layer_0(embed)))\n",
    "        \n",
    "        for i in range(1, self.n_layers):\n",
    "            linear_layer = getattr(self, 'l{}'.format(i))\n",
    "            hidden = self.ReLU(linear_layer(hidden))\n",
    "        \n",
    "        output = self.ReLU(self.decoder(hidden))\n",
    "        output = F.softmax(output, 1)\n",
    "        return output\n",
    "\n",
    "    def init_hidden(self):\n",
    "        h0 = torch.zeros(self.batch_size, self.hidden_size)\n",
    "        return h0\n",
    "    \n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        lin_layers = [self.layer_0, self.decoder]\n",
    "        for i in range(1, self.n_layers):\n",
    "            lin_layers.append(getattr(self, 'l{}'.format(i)))\n",
    "        em_layer =  [self.embed]\n",
    "     \n",
    "        for layer in lin_layers+em_layer:\n",
    "            layer.weight.data.uniform_(-initrange, initrange)\n",
    "            if layer in lin_layers:\n",
    "                layer.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model!\n",
    "\n",
    "** Please use the hyperparameters and optimizer provided below. Do not make changes here. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0; Step 0; Loss 0.693148; Train acc: 0.527344; Dev acc 0.523438\n",
      "Epoch 5; Step 135; Loss 0.677439; Train acc: 0.527344; Dev acc 0.523438\n",
      "Epoch 10; Step 270; Loss 0.604049; Train acc: 0.800781; Dev acc 0.714844\n",
      "Epoch 15; Step 405; Loss 0.548171; Train acc: 0.835938; Dev acc 0.757812\n",
      "Epoch 20; Step 540; Loss 0.518067; Train acc: 0.886719; Dev acc 0.773438\n",
      "Epoch 25; Step 675; Loss 0.530321; Train acc: 0.902344; Dev acc 0.742188\n",
      "Epoch 30; Step 810; Loss 0.557709; Train acc: 0.878906; Dev acc 0.757812\n",
      "Best dev accuracy is 0.7734375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7734375"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameters \n",
    "input_size = vocab_size\n",
    "num_labels = 2\n",
    "hidden_dim = 24\n",
    "embedding_dim = 8\n",
    "batch_size = 256\n",
    "num_layers = 2\n",
    "learning_rate = 0.001\n",
    "drop_rate = 0.4\n",
    "num_epochs = 30\n",
    "\n",
    "# Build and initialize the model\n",
    "dan = DAN(vocab_size, embedding_dim, hidden_dim, num_labels, batch_size, num_layers, drop_rate)\n",
    "dan.init_weights()\n",
    "\n",
    "# Define loss function and optimizer\n",
    "loss = nn.CrossEntropyLoss()  \n",
    "optimizer = torch.optim.Adam(dan.parameters(), lr=learning_rate)\n",
    "\n",
    "# Build data iterators\n",
    "training_iter = data_iter(training_set, batch_size)\n",
    "train_eval_iter = eval_iter(training_set[0:500], batch_size)\n",
    "dev_iter = eval_iter(dev_set[:500], batch_size)\n",
    "\n",
    "# Train the model\n",
    "training_loop(batch_size, num_epochs, dan, loss, optimizer, training_iter, dev_iter, train_eval_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Part 2: Hyperparameter tuning (40 points)\n",
    "\n",
    "Tune the DAN for learning rate, number of layers, and drop-out rate. Select a range for each parameter and then do a random search over these hyperparameters, trying a minimum 5 permutations of hyperparameters. Report results and the best hyperparameters you found. Do you see any patterns in your results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "def hparameter_search_dan(model = DAN,\n",
    "                          model_criterion = torch.nn.CrossEntropyLoss(),\n",
    "                          lr_list = [1e-3, 1e-4, 1e-5],\n",
    "                          embed_list = [10, 50, 200],\n",
    "                          hidden_size_list = [64, 128],\n",
    "                          num_layers_list = [2, 3, 4, 5],\n",
    "                          weight_decay_list = [1e-8, 1e-5],\n",
    "                          dropout_rates = [0, 0.1, 0.3, 0.5],\n",
    "                          num_epochs = 30,\n",
    "                          train_iterator = data_iter(training_set, batch_size),\n",
    "                          train_eval_iterator = eval_iter(training_set[:500], batch_size),\n",
    "                          dev_iterator = eval_iter(dev_set[:500], batch_size)\n",
    "                         ):\n",
    "\n",
    "    hyper_params = {\"lr\":lr_list, \"embed_dim\":embed_list, \"hidden_size\":hidden_size_list, \n",
    "                    \"n_layers\":num_layers_list, \"weight_decay\":weight_decay_list,\n",
    "                    \"word_dropout\":dropout_rates\n",
    "                   }\n",
    "\n",
    "    param_names = [*hyper_params.keys()]\n",
    "    param_sets = [*itertools.product(*[hyper_params[key] for key in param_names])]\n",
    "    dev_accs = {}\n",
    "\n",
    "    for p_ in range(len(param_sets)):\n",
    "\n",
    "        params = param_sets[p_]\n",
    "        print (p_, \"/\", len(param_sets), \" = \",params)\n",
    "        \n",
    "        [learning_rate, embed_dim, hidden_size, \\\n",
    "         num_layers, weight_decay, word_dropout] = [params[param_names.index(x)] for x in param_names]\n",
    "\n",
    "        dan = model(vocab_size, embed_dim, hidden_size, 2, batch_size, num_layers, word_dropout)\n",
    "\n",
    "        criterion = model_criterion\n",
    "        optimizer = torch.optim.Adam(dan.parameters(), lr=learning_rate, weight_decay = weight_decay)\n",
    "\n",
    "        best_dev_acc = training_loop(batch_size, num_epochs, dan, model_criterion, \n",
    "                                          optimizer, train_iterator, dev_iterator, train_eval_iterator)\n",
    "        \n",
    "        print (\"Best accuracy: \", best_dev_acc)\n",
    "        dev_accs[param_sets[p_]] = best_dev_acc\n",
    "        \n",
    "        pd.DataFrame(dev_accs, index=range(len(dev_accs))).to_csv(\"dan_dev_accuracy.csv\")\n",
    "\n",
    "    return dev_accs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 576  =  (0.001, 10, 64, 2, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693157; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.589069; Train acc: 0.726562; Dev acc 0.699219\n",
      "Epoch 10; Step 270; Loss 0.406572; Train acc: 0.886719; Dev acc 0.726562\n",
      "Epoch 15; Step 405; Loss 0.375336; Train acc: 0.910156; Dev acc 0.773438\n",
      "Epoch 20; Step 540; Loss 0.386044; Train acc: 0.925781; Dev acc 0.773438\n",
      "Epoch 25; Step 675; Loss 0.389030; Train acc: 0.925781; Dev acc 0.710938\n",
      "Epoch 30; Step 810; Loss 0.376871; Train acc: 0.929688; Dev acc 0.726562\n",
      "Best dev accuracy is 0.7734375\n",
      "Best accuracy:  0.7734375\n",
      "1 / 576  =  (0.001, 10, 64, 2, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693137; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.601734; Train acc: 0.734375; Dev acc 0.695312\n",
      "Epoch 10; Step 270; Loss 0.575672; Train acc: 0.851562; Dev acc 0.718750\n",
      "Epoch 15; Step 405; Loss 0.534543; Train acc: 0.910156; Dev acc 0.742188\n",
      "Epoch 20; Step 540; Loss 0.546525; Train acc: 0.914062; Dev acc 0.773438\n",
      "Epoch 25; Step 675; Loss 0.552171; Train acc: 0.910156; Dev acc 0.750000\n",
      "Epoch 30; Step 810; Loss 0.545357; Train acc: 0.945312; Dev acc 0.773438\n",
      "Best dev accuracy is 0.7734375\n",
      "Best accuracy:  0.7734375\n",
      "2 / 576  =  (0.001, 10, 64, 2, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693142; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "3 / 576  =  (0.001, 10, 64, 2, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "4 / 576  =  (0.001, 10, 64, 2, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693145; Train acc: 0.519531; Dev acc 0.484375\n",
      "Epoch 5; Step 135; Loss 0.631464; Train acc: 0.691406; Dev acc 0.679688\n",
      "Epoch 10; Step 270; Loss 0.559724; Train acc: 0.871094; Dev acc 0.792969\n",
      "Epoch 15; Step 405; Loss 0.522848; Train acc: 0.863281; Dev acc 0.761719\n",
      "Epoch 20; Step 540; Loss 0.531659; Train acc: 0.921875; Dev acc 0.824219\n",
      "Epoch 25; Step 675; Loss 0.516738; Train acc: 0.937500; Dev acc 0.746094\n",
      "Epoch 30; Step 810; Loss 0.492778; Train acc: 0.949219; Dev acc 0.726562\n",
      "Best dev accuracy is 0.82421875\n",
      "Best accuracy:  0.82421875\n",
      "5 / 576  =  (0.001, 10, 64, 2, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693142; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.632020; Train acc: 0.660156; Dev acc 0.636719\n",
      "Epoch 10; Step 270; Loss 0.558104; Train acc: 0.851562; Dev acc 0.691406\n",
      "Epoch 15; Step 405; Loss 0.527983; Train acc: 0.898438; Dev acc 0.777344\n",
      "Epoch 20; Step 540; Loss 0.514848; Train acc: 0.906250; Dev acc 0.726562\n",
      "Epoch 25; Step 675; Loss 0.554651; Train acc: 0.957031; Dev acc 0.730469\n",
      "Epoch 30; Step 810; Loss 0.542520; Train acc: 0.933594; Dev acc 0.695312\n",
      "Best dev accuracy is 0.77734375\n",
      "Best accuracy:  0.77734375\n",
      "6 / 576  =  (0.001, 10, 64, 2, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693151; Train acc: 0.500000; Dev acc 0.554688\n",
      "Epoch 5; Step 135; Loss 0.631805; Train acc: 0.660156; Dev acc 0.640625\n",
      "Epoch 10; Step 270; Loss 0.542670; Train acc: 0.847656; Dev acc 0.761719\n",
      "Epoch 15; Step 405; Loss 0.555466; Train acc: 0.875000; Dev acc 0.757812\n",
      "Epoch 20; Step 540; Loss 0.543731; Train acc: 0.906250; Dev acc 0.757812\n",
      "Epoch 25; Step 675; Loss 0.521550; Train acc: 0.925781; Dev acc 0.722656\n",
      "Epoch 30; Step 810; Loss 0.533627; Train acc: 0.910156; Dev acc 0.734375\n",
      "Best dev accuracy is 0.76171875\n",
      "Best accuracy:  0.76171875\n",
      "7 / 576  =  (0.001, 10, 64, 2, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693148; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "8 / 576  =  (0.001, 10, 64, 3, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693148; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.604284; Train acc: 0.757812; Dev acc 0.691406\n",
      "Epoch 10; Step 270; Loss 0.440265; Train acc: 0.890625; Dev acc 0.757812\n",
      "Epoch 15; Step 405; Loss 0.385323; Train acc: 0.906250; Dev acc 0.750000\n",
      "Epoch 20; Step 540; Loss 0.392103; Train acc: 0.910156; Dev acc 0.722656\n",
      "Epoch 25; Step 675; Loss 0.380969; Train acc: 0.925781; Dev acc 0.699219\n",
      "Epoch 30; Step 810; Loss 0.375758; Train acc: 0.925781; Dev acc 0.734375\n",
      "Best dev accuracy is 0.7578125\n",
      "Best accuracy:  0.7578125\n",
      "9 / 576  =  (0.001, 10, 64, 3, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693141; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.580600; Train acc: 0.789062; Dev acc 0.722656\n",
      "Epoch 10; Step 270; Loss 0.429173; Train acc: 0.871094; Dev acc 0.750000\n",
      "Epoch 15; Step 405; Loss 0.377712; Train acc: 0.914062; Dev acc 0.707031\n",
      "Epoch 20; Step 540; Loss 0.376218; Train acc: 0.902344; Dev acc 0.687500\n",
      "Epoch 25; Step 675; Loss 0.395771; Train acc: 0.929688; Dev acc 0.730469\n",
      "Epoch 30; Step 810; Loss 0.359532; Train acc: 0.914062; Dev acc 0.753906\n",
      "Best dev accuracy is 0.75390625\n",
      "Best accuracy:  0.75390625\n",
      "10 / 576  =  (0.001, 10, 64, 3, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693140; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.580590; Train acc: 0.699219; Dev acc 0.660156\n",
      "Epoch 10; Step 270; Loss 0.421193; Train acc: 0.867188; Dev acc 0.722656\n",
      "Epoch 15; Step 405; Loss 0.405627; Train acc: 0.921875; Dev acc 0.738281\n",
      "Epoch 20; Step 540; Loss 0.397112; Train acc: 0.933594; Dev acc 0.722656\n",
      "Epoch 25; Step 675; Loss 0.381446; Train acc: 0.933594; Dev acc 0.714844\n",
      "Epoch 30; Step 810; Loss 0.385649; Train acc: 0.925781; Dev acc 0.738281\n",
      "Best dev accuracy is 0.73828125\n",
      "Best accuracy:  0.73828125\n",
      "11 / 576  =  (0.001, 10, 64, 3, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "12 / 576  =  (0.001, 10, 64, 3, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.601653; Train acc: 0.726562; Dev acc 0.722656\n",
      "Epoch 10; Step 270; Loss 0.552362; Train acc: 0.878906; Dev acc 0.785156\n",
      "Epoch 15; Step 405; Loss 0.555195; Train acc: 0.906250; Dev acc 0.769531\n",
      "Epoch 20; Step 540; Loss 0.556067; Train acc: 0.917969; Dev acc 0.773438\n",
      "Epoch 25; Step 675; Loss 0.518856; Train acc: 0.894531; Dev acc 0.761719\n",
      "Epoch 30; Step 810; Loss 0.537580; Train acc: 0.921875; Dev acc 0.703125\n",
      "Best dev accuracy is 0.78515625\n",
      "Best accuracy:  0.78515625\n",
      "13 / 576  =  (0.001, 10, 64, 3, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693145; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.587747; Train acc: 0.730469; Dev acc 0.679688\n",
      "Epoch 10; Step 270; Loss 0.565788; Train acc: 0.878906; Dev acc 0.757812\n",
      "Epoch 15; Step 405; Loss 0.524992; Train acc: 0.851562; Dev acc 0.726562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20; Step 540; Loss 0.525421; Train acc: 0.894531; Dev acc 0.746094\n",
      "Epoch 25; Step 675; Loss 0.535195; Train acc: 0.910156; Dev acc 0.714844\n",
      "Epoch 30; Step 810; Loss 0.537139; Train acc: 0.894531; Dev acc 0.757812\n",
      "Best dev accuracy is 0.7578125\n",
      "Best accuracy:  0.7578125\n",
      "14 / 576  =  (0.001, 10, 64, 3, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "15 / 576  =  (0.001, 10, 64, 3, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "16 / 576  =  (0.001, 10, 64, 4, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "17 / 576  =  (0.001, 10, 64, 4, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.577397; Train acc: 0.761719; Dev acc 0.710938\n",
      "Epoch 10; Step 270; Loss 0.554054; Train acc: 0.843750; Dev acc 0.769531\n",
      "Epoch 15; Step 405; Loss 0.531256; Train acc: 0.878906; Dev acc 0.761719\n",
      "Epoch 20; Step 540; Loss 0.547201; Train acc: 0.902344; Dev acc 0.722656\n",
      "Epoch 25; Step 675; Loss 0.544133; Train acc: 0.886719; Dev acc 0.781250\n",
      "Epoch 30; Step 810; Loss 0.526711; Train acc: 0.914062; Dev acc 0.726562\n",
      "Best dev accuracy is 0.78125\n",
      "Best accuracy:  0.78125\n",
      "18 / 576  =  (0.001, 10, 64, 4, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.613304; Train acc: 0.734375; Dev acc 0.734375\n",
      "Epoch 10; Step 270; Loss 0.545829; Train acc: 0.839844; Dev acc 0.757812\n",
      "Epoch 15; Step 405; Loss 0.553496; Train acc: 0.863281; Dev acc 0.746094\n",
      "Epoch 20; Step 540; Loss 0.565721; Train acc: 0.859375; Dev acc 0.714844\n",
      "Epoch 25; Step 675; Loss 0.552316; Train acc: 0.886719; Dev acc 0.730469\n",
      "Epoch 30; Step 810; Loss 0.550885; Train acc: 0.910156; Dev acc 0.714844\n",
      "Best dev accuracy is 0.7578125\n",
      "Best accuracy:  0.7578125\n",
      "19 / 576  =  (0.001, 10, 64, 4, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.605908; Train acc: 0.757812; Dev acc 0.699219\n",
      "Epoch 10; Step 270; Loss 0.585337; Train acc: 0.851562; Dev acc 0.761719\n",
      "Epoch 15; Step 405; Loss 0.560812; Train acc: 0.875000; Dev acc 0.734375\n",
      "Epoch 20; Step 540; Loss 0.540658; Train acc: 0.878906; Dev acc 0.742188\n",
      "Epoch 25; Step 675; Loss 0.538376; Train acc: 0.851562; Dev acc 0.734375\n",
      "Epoch 30; Step 810; Loss 0.521508; Train acc: 0.890625; Dev acc 0.726562\n",
      "Best dev accuracy is 0.76171875\n",
      "Best accuracy:  0.76171875\n",
      "20 / 576  =  (0.001, 10, 64, 4, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "21 / 576  =  (0.001, 10, 64, 4, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.503906; Dev acc 0.492188\n",
      "Epoch 5; Step 135; Loss 0.606262; Train acc: 0.753906; Dev acc 0.738281\n",
      "Epoch 10; Step 270; Loss 0.562817; Train acc: 0.835938; Dev acc 0.777344\n",
      "Epoch 15; Step 405; Loss 0.555563; Train acc: 0.878906; Dev acc 0.765625\n",
      "Epoch 20; Step 540; Loss 0.539871; Train acc: 0.886719; Dev acc 0.730469\n",
      "Epoch 25; Step 675; Loss 0.535048; Train acc: 0.863281; Dev acc 0.750000\n",
      "Epoch 30; Step 810; Loss 0.544950; Train acc: 0.910156; Dev acc 0.722656\n",
      "Best dev accuracy is 0.77734375\n",
      "Best accuracy:  0.77734375\n",
      "22 / 576  =  (0.001, 10, 64, 4, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.589706; Train acc: 0.777344; Dev acc 0.734375\n",
      "Epoch 10; Step 270; Loss 0.539797; Train acc: 0.847656; Dev acc 0.734375\n",
      "Epoch 15; Step 405; Loss 0.568055; Train acc: 0.863281; Dev acc 0.757812\n",
      "Epoch 20; Step 540; Loss 0.528285; Train acc: 0.878906; Dev acc 0.746094\n",
      "Epoch 25; Step 675; Loss 0.543247; Train acc: 0.902344; Dev acc 0.746094\n",
      "Epoch 30; Step 810; Loss 0.541355; Train acc: 0.890625; Dev acc 0.703125\n",
      "Best dev accuracy is 0.7578125\n",
      "Best accuracy:  0.7578125\n",
      "23 / 576  =  (0.001, 10, 64, 4, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.591970; Train acc: 0.816406; Dev acc 0.742188\n",
      "Epoch 10; Step 270; Loss 0.559192; Train acc: 0.898438; Dev acc 0.761719\n",
      "Epoch 15; Step 405; Loss 0.568783; Train acc: 0.906250; Dev acc 0.742188\n",
      "Epoch 20; Step 540; Loss 0.542358; Train acc: 0.890625; Dev acc 0.738281\n",
      "Epoch 25; Step 675; Loss 0.544970; Train acc: 0.914062; Dev acc 0.722656\n",
      "Epoch 30; Step 810; Loss 0.527133; Train acc: 0.925781; Dev acc 0.742188\n",
      "Best dev accuracy is 0.76171875\n",
      "Best accuracy:  0.76171875\n",
      "24 / 576  =  (0.001, 10, 64, 5, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.591199; Train acc: 0.796875; Dev acc 0.742188\n",
      "Epoch 10; Step 270; Loss 0.582858; Train acc: 0.835938; Dev acc 0.773438\n",
      "Epoch 15; Step 405; Loss 0.556976; Train acc: 0.855469; Dev acc 0.773438\n",
      "Epoch 20; Step 540; Loss 0.549389; Train acc: 0.894531; Dev acc 0.750000\n",
      "Epoch 25; Step 675; Loss 0.560879; Train acc: 0.902344; Dev acc 0.726562\n",
      "Epoch 30; Step 810; Loss 0.523540; Train acc: 0.906250; Dev acc 0.703125\n",
      "Best dev accuracy is 0.7734375\n",
      "Best accuracy:  0.7734375\n",
      "25 / 576  =  (0.001, 10, 64, 5, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.583744; Train acc: 0.808594; Dev acc 0.703125\n",
      "Epoch 10; Step 270; Loss 0.562400; Train acc: 0.847656; Dev acc 0.773438\n",
      "Epoch 15; Step 405; Loss 0.544418; Train acc: 0.894531; Dev acc 0.742188\n",
      "Epoch 20; Step 540; Loss 0.546127; Train acc: 0.878906; Dev acc 0.753906\n",
      "Epoch 25; Step 675; Loss 0.561170; Train acc: 0.867188; Dev acc 0.734375\n",
      "Epoch 30; Step 810; Loss 0.538774; Train acc: 0.914062; Dev acc 0.746094\n",
      "Best dev accuracy is 0.7734375\n",
      "Best accuracy:  0.7734375\n",
      "26 / 576  =  (0.001, 10, 64, 5, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "27 / 576  =  (0.001, 10, 64, 5, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.496094; Dev acc 0.546875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5; Step 135; Loss 0.563883; Train acc: 0.750000; Dev acc 0.703125\n",
      "Epoch 10; Step 270; Loss 0.564741; Train acc: 0.855469; Dev acc 0.738281\n",
      "Epoch 15; Step 405; Loss 0.552443; Train acc: 0.843750; Dev acc 0.742188\n",
      "Epoch 20; Step 540; Loss 0.559866; Train acc: 0.871094; Dev acc 0.730469\n",
      "Epoch 25; Step 675; Loss 0.564891; Train acc: 0.867188; Dev acc 0.738281\n",
      "Epoch 30; Step 810; Loss 0.547002; Train acc: 0.906250; Dev acc 0.714844\n",
      "Best dev accuracy is 0.7421875\n",
      "Best accuracy:  0.7421875\n",
      "28 / 576  =  (0.001, 10, 64, 5, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "29 / 576  =  (0.001, 10, 64, 5, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693148; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "30 / 576  =  (0.001, 10, 64, 5, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.664131; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.529657; Train acc: 0.843750; Dev acc 0.785156\n",
      "Epoch 15; Step 405; Loss 0.539122; Train acc: 0.878906; Dev acc 0.726562\n",
      "Epoch 20; Step 540; Loss 0.546728; Train acc: 0.871094; Dev acc 0.738281\n",
      "Epoch 25; Step 675; Loss 0.519485; Train acc: 0.882812; Dev acc 0.734375\n",
      "Epoch 30; Step 810; Loss 0.526258; Train acc: 0.847656; Dev acc 0.722656\n",
      "Best dev accuracy is 0.78515625\n",
      "Best accuracy:  0.78515625\n",
      "31 / 576  =  (0.001, 10, 64, 5, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "32 / 576  =  (0.001, 10, 128, 2, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693135; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.605105; Train acc: 0.726562; Dev acc 0.722656\n",
      "Epoch 10; Step 270; Loss 0.430773; Train acc: 0.859375; Dev acc 0.750000\n",
      "Epoch 15; Step 405; Loss 0.402566; Train acc: 0.890625; Dev acc 0.707031\n",
      "Epoch 20; Step 540; Loss 0.382862; Train acc: 0.933594; Dev acc 0.734375\n",
      "Epoch 25; Step 675; Loss 0.373469; Train acc: 0.910156; Dev acc 0.730469\n",
      "Epoch 30; Step 810; Loss 0.368417; Train acc: 0.921875; Dev acc 0.742188\n",
      "Best dev accuracy is 0.75\n",
      "Best accuracy:  0.75\n",
      "33 / 576  =  (0.001, 10, 128, 2, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693137; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.604302; Train acc: 0.742188; Dev acc 0.687500\n",
      "Epoch 10; Step 270; Loss 0.413707; Train acc: 0.886719; Dev acc 0.753906\n",
      "Epoch 15; Step 405; Loss 0.390760; Train acc: 0.886719; Dev acc 0.703125\n",
      "Epoch 20; Step 540; Loss 0.369600; Train acc: 0.914062; Dev acc 0.722656\n",
      "Epoch 25; Step 675; Loss 0.382105; Train acc: 0.933594; Dev acc 0.722656\n",
      "Epoch 30; Step 810; Loss 0.365075; Train acc: 0.914062; Dev acc 0.703125\n",
      "Best dev accuracy is 0.75390625\n",
      "Best accuracy:  0.75390625\n",
      "34 / 576  =  (0.001, 10, 128, 2, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693131; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.487295; Train acc: 0.816406; Dev acc 0.769531\n",
      "Epoch 10; Step 270; Loss 0.375135; Train acc: 0.890625; Dev acc 0.753906\n",
      "Epoch 15; Step 405; Loss 0.398687; Train acc: 0.929688; Dev acc 0.738281\n",
      "Epoch 20; Step 540; Loss 0.377283; Train acc: 0.925781; Dev acc 0.785156\n",
      "Epoch 25; Step 675; Loss 0.393756; Train acc: 0.945312; Dev acc 0.757812\n",
      "Epoch 30; Step 810; Loss 0.400333; Train acc: 0.941406; Dev acc 0.730469\n",
      "Best dev accuracy is 0.78515625\n",
      "Best accuracy:  0.78515625\n",
      "35 / 576  =  (0.001, 10, 128, 2, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693167; Train acc: 0.539062; Dev acc 0.539062\n",
      "Epoch 5; Step 135; Loss 0.594819; Train acc: 0.781250; Dev acc 0.687500\n",
      "Epoch 10; Step 270; Loss 0.522555; Train acc: 0.898438; Dev acc 0.703125\n",
      "Epoch 15; Step 405; Loss 0.559223; Train acc: 0.890625; Dev acc 0.750000\n",
      "Epoch 20; Step 540; Loss 0.531896; Train acc: 0.886719; Dev acc 0.730469\n",
      "Epoch 25; Step 675; Loss 0.535498; Train acc: 0.914062; Dev acc 0.742188\n",
      "Epoch 30; Step 810; Loss 0.545401; Train acc: 0.917969; Dev acc 0.761719\n",
      "Best dev accuracy is 0.76171875\n",
      "Best accuracy:  0.76171875\n",
      "36 / 576  =  (0.001, 10, 128, 2, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693154; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "37 / 576  =  (0.001, 10, 128, 2, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.582276; Train acc: 0.777344; Dev acc 0.753906\n",
      "Epoch 10; Step 270; Loss 0.557389; Train acc: 0.875000; Dev acc 0.722656\n",
      "Epoch 15; Step 405; Loss 0.533894; Train acc: 0.906250; Dev acc 0.699219\n",
      "Epoch 20; Step 540; Loss 0.510622; Train acc: 0.933594; Dev acc 0.707031\n",
      "Epoch 25; Step 675; Loss 0.543659; Train acc: 0.890625; Dev acc 0.757812\n",
      "Epoch 30; Step 810; Loss 0.504304; Train acc: 0.929688; Dev acc 0.742188\n",
      "Best dev accuracy is 0.7578125\n",
      "Best accuracy:  0.7578125\n",
      "38 / 576  =  (0.001, 10, 128, 2, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693171; Train acc: 0.507812; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "39 / 576  =  (0.001, 10, 128, 2, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693156; Train acc: 0.480469; Dev acc 0.410156\n",
      "Epoch 5; Step 135; Loss 0.600167; Train acc: 0.800781; Dev acc 0.765625\n",
      "Epoch 10; Step 270; Loss 0.572103; Train acc: 0.867188; Dev acc 0.734375\n",
      "Epoch 15; Step 405; Loss 0.556009; Train acc: 0.937500; Dev acc 0.746094\n",
      "Epoch 20; Step 540; Loss 0.523299; Train acc: 0.898438; Dev acc 0.726562\n",
      "Epoch 25; Step 675; Loss 0.537009; Train acc: 0.886719; Dev acc 0.738281\n",
      "Epoch 30; Step 810; Loss 0.537036; Train acc: 0.906250; Dev acc 0.750000\n",
      "Best dev accuracy is 0.765625\n",
      "Best accuracy:  0.765625\n",
      "40 / 576  =  (0.001, 10, 128, 3, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693141; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "41 / 576  =  (0.001, 10, 128, 3, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693149; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "42 / 576  =  (0.001, 10, 128, 3, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693143; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.478562; Train acc: 0.808594; Dev acc 0.730469\n",
      "Epoch 10; Step 270; Loss 0.420248; Train acc: 0.882812; Dev acc 0.738281\n",
      "Epoch 15; Step 405; Loss 0.397519; Train acc: 0.906250; Dev acc 0.691406\n",
      "Epoch 20; Step 540; Loss 0.372552; Train acc: 0.921875; Dev acc 0.738281\n",
      "Epoch 25; Step 675; Loss 0.350349; Train acc: 0.925781; Dev acc 0.750000\n",
      "Epoch 30; Step 810; Loss 0.356436; Train acc: 0.921875; Dev acc 0.746094\n",
      "Best dev accuracy is 0.75\n",
      "Best accuracy:  0.75\n",
      "43 / 576  =  (0.001, 10, 128, 3, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693148; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "44 / 576  =  (0.001, 10, 128, 3, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "45 / 576  =  (0.001, 10, 128, 3, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693132; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.564003; Train acc: 0.792969; Dev acc 0.738281\n",
      "Epoch 10; Step 270; Loss 0.544532; Train acc: 0.886719; Dev acc 0.726562\n",
      "Epoch 15; Step 405; Loss 0.534210; Train acc: 0.910156; Dev acc 0.757812\n",
      "Epoch 20; Step 540; Loss 0.527130; Train acc: 0.937500; Dev acc 0.773438\n",
      "Epoch 25; Step 675; Loss 0.560086; Train acc: 0.906250; Dev acc 0.695312\n",
      "Epoch 30; Step 810; Loss 0.536398; Train acc: 0.933594; Dev acc 0.703125\n",
      "Best dev accuracy is 0.7734375\n",
      "Best accuracy:  0.7734375\n",
      "46 / 576  =  (0.001, 10, 128, 3, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693145; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.554199; Train acc: 0.769531; Dev acc 0.753906\n",
      "Epoch 10; Step 270; Loss 0.547212; Train acc: 0.859375; Dev acc 0.738281\n",
      "Epoch 15; Step 405; Loss 0.543226; Train acc: 0.890625; Dev acc 0.738281\n",
      "Epoch 20; Step 540; Loss 0.526465; Train acc: 0.863281; Dev acc 0.746094\n",
      "Epoch 25; Step 675; Loss 0.532557; Train acc: 0.910156; Dev acc 0.730469\n",
      "Epoch 30; Step 810; Loss 0.529444; Train acc: 0.906250; Dev acc 0.718750\n",
      "Best dev accuracy is 0.75390625\n",
      "Best accuracy:  0.75390625\n",
      "47 / 576  =  (0.001, 10, 128, 3, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693154; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.562670; Train acc: 0.746094; Dev acc 0.781250\n",
      "Epoch 10; Step 270; Loss 0.550253; Train acc: 0.882812; Dev acc 0.796875\n",
      "Epoch 15; Step 405; Loss 0.541211; Train acc: 0.890625; Dev acc 0.722656\n",
      "Epoch 20; Step 540; Loss 0.539676; Train acc: 0.902344; Dev acc 0.761719\n",
      "Epoch 25; Step 675; Loss 0.527497; Train acc: 0.914062; Dev acc 0.742188\n",
      "Epoch 30; Step 810; Loss 0.543549; Train acc: 0.921875; Dev acc 0.757812\n",
      "Best dev accuracy is 0.796875\n",
      "Best accuracy:  0.796875\n",
      "48 / 576  =  (0.001, 10, 128, 4, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693149; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.577956; Train acc: 0.800781; Dev acc 0.718750\n",
      "Epoch 10; Step 270; Loss 0.544373; Train acc: 0.855469; Dev acc 0.753906\n",
      "Epoch 15; Step 405; Loss 0.543140; Train acc: 0.886719; Dev acc 0.746094\n",
      "Epoch 20; Step 540; Loss 0.544466; Train acc: 0.894531; Dev acc 0.753906\n",
      "Epoch 25; Step 675; Loss 0.535123; Train acc: 0.898438; Dev acc 0.777344\n",
      "Epoch 30; Step 810; Loss 0.536468; Train acc: 0.886719; Dev acc 0.773438\n",
      "Best dev accuracy is 0.77734375\n",
      "Best accuracy:  0.77734375\n",
      "49 / 576  =  (0.001, 10, 128, 4, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693145; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.572078; Train acc: 0.816406; Dev acc 0.726562\n",
      "Epoch 10; Step 270; Loss 0.569682; Train acc: 0.875000; Dev acc 0.730469\n",
      "Epoch 15; Step 405; Loss 0.566087; Train acc: 0.890625; Dev acc 0.726562\n",
      "Epoch 20; Step 540; Loss 0.533104; Train acc: 0.902344; Dev acc 0.710938\n",
      "Epoch 25; Step 675; Loss 0.547034; Train acc: 0.847656; Dev acc 0.714844\n",
      "Epoch 30; Step 810; Loss 0.528049; Train acc: 0.855469; Dev acc 0.750000\n",
      "Best dev accuracy is 0.75\n",
      "Best accuracy:  0.75\n",
      "50 / 576  =  (0.001, 10, 128, 4, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "51 / 576  =  (0.001, 10, 128, 4, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693137; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.546092; Train acc: 0.761719; Dev acc 0.765625\n",
      "Epoch 10; Step 270; Loss 0.429573; Train acc: 0.859375; Dev acc 0.734375\n",
      "Epoch 15; Step 405; Loss 0.416921; Train acc: 0.921875; Dev acc 0.726562\n",
      "Epoch 20; Step 540; Loss 0.415264; Train acc: 0.925781; Dev acc 0.761719\n",
      "Epoch 25; Step 675; Loss 0.365112; Train acc: 0.925781; Dev acc 0.765625\n",
      "Epoch 30; Step 810; Loss 0.388824; Train acc: 0.933594; Dev acc 0.703125\n",
      "Best dev accuracy is 0.765625\n",
      "Best accuracy:  0.765625\n",
      "52 / 576  =  (0.001, 10, 128, 4, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "53 / 576  =  (0.001, 10, 128, 4, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693145; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "54 / 576  =  (0.001, 10, 128, 4, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "55 / 576  =  (0.001, 10, 128, 4, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.577214; Train acc: 0.808594; Dev acc 0.738281\n",
      "Epoch 10; Step 270; Loss 0.535623; Train acc: 0.851562; Dev acc 0.738281\n",
      "Epoch 15; Step 405; Loss 0.545558; Train acc: 0.875000; Dev acc 0.753906\n",
      "Epoch 20; Step 540; Loss 0.539599; Train acc: 0.914062; Dev acc 0.781250\n",
      "Epoch 25; Step 675; Loss 0.578261; Train acc: 0.855469; Dev acc 0.785156\n",
      "Epoch 30; Step 810; Loss 0.557377; Train acc: 0.890625; Dev acc 0.738281\n",
      "Best dev accuracy is 0.78515625\n",
      "Best accuracy:  0.78515625\n",
      "56 / 576  =  (0.001, 10, 128, 5, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693145; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "57 / 576  =  (0.001, 10, 128, 5, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.601263; Train acc: 0.816406; Dev acc 0.742188\n",
      "Epoch 10; Step 270; Loss 0.577237; Train acc: 0.871094; Dev acc 0.675781\n",
      "Epoch 15; Step 405; Loss 0.546212; Train acc: 0.847656; Dev acc 0.730469\n",
      "Epoch 20; Step 540; Loss 0.575143; Train acc: 0.882812; Dev acc 0.734375\n",
      "Epoch 25; Step 675; Loss 0.521604; Train acc: 0.894531; Dev acc 0.742188\n",
      "Epoch 30; Step 810; Loss 0.556662; Train acc: 0.910156; Dev acc 0.730469\n",
      "Best dev accuracy is 0.7421875\n",
      "Best accuracy:  0.7421875\n",
      "58 / 576  =  (0.001, 10, 128, 5, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.579819; Train acc: 0.765625; Dev acc 0.707031\n",
      "Epoch 10; Step 270; Loss 0.560302; Train acc: 0.832031; Dev acc 0.753906\n",
      "Epoch 15; Step 405; Loss 0.577771; Train acc: 0.875000; Dev acc 0.738281\n",
      "Epoch 20; Step 540; Loss 0.539258; Train acc: 0.882812; Dev acc 0.746094\n",
      "Epoch 25; Step 675; Loss 0.559745; Train acc: 0.878906; Dev acc 0.734375\n",
      "Epoch 30; Step 810; Loss 0.536502; Train acc: 0.882812; Dev acc 0.753906\n",
      "Best dev accuracy is 0.75390625\n",
      "Best accuracy:  0.75390625\n",
      "59 / 576  =  (0.001, 10, 128, 5, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.598812; Train acc: 0.796875; Dev acc 0.699219\n",
      "Epoch 10; Step 270; Loss 0.573885; Train acc: 0.828125; Dev acc 0.753906\n",
      "Epoch 15; Step 405; Loss 0.561116; Train acc: 0.871094; Dev acc 0.660156\n",
      "Epoch 20; Step 540; Loss 0.530753; Train acc: 0.890625; Dev acc 0.722656\n",
      "Epoch 25; Step 675; Loss 0.558527; Train acc: 0.890625; Dev acc 0.703125\n",
      "Epoch 30; Step 810; Loss 0.538786; Train acc: 0.902344; Dev acc 0.718750\n",
      "Best dev accuracy is 0.75390625\n",
      "Best accuracy:  0.75390625\n",
      "60 / 576  =  (0.001, 10, 128, 5, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "61 / 576  =  (0.001, 10, 128, 5, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693149; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.577386; Train acc: 0.789062; Dev acc 0.714844\n",
      "Epoch 10; Step 270; Loss 0.589043; Train acc: 0.855469; Dev acc 0.718750\n",
      "Epoch 15; Step 405; Loss 0.525033; Train acc: 0.839844; Dev acc 0.738281\n",
      "Epoch 20; Step 540; Loss 0.546898; Train acc: 0.863281; Dev acc 0.726562\n",
      "Epoch 25; Step 675; Loss 0.591773; Train acc: 0.875000; Dev acc 0.703125\n",
      "Epoch 30; Step 810; Loss 0.554741; Train acc: 0.875000; Dev acc 0.718750\n",
      "Best dev accuracy is 0.73828125\n",
      "Best accuracy:  0.73828125\n",
      "62 / 576  =  (0.001, 10, 128, 5, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693148; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.572782; Train acc: 0.757812; Dev acc 0.710938\n",
      "Epoch 10; Step 270; Loss 0.561303; Train acc: 0.824219; Dev acc 0.773438\n",
      "Epoch 15; Step 405; Loss 0.557189; Train acc: 0.882812; Dev acc 0.757812\n",
      "Epoch 20; Step 540; Loss 0.524043; Train acc: 0.871094; Dev acc 0.757812\n",
      "Epoch 25; Step 675; Loss 0.515761; Train acc: 0.855469; Dev acc 0.714844\n",
      "Epoch 30; Step 810; Loss 0.528495; Train acc: 0.902344; Dev acc 0.707031\n",
      "Best dev accuracy is 0.7734375\n",
      "Best accuracy:  0.7734375\n",
      "63 / 576  =  (0.001, 10, 128, 5, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.453125; Dev acc 0.457031\n",
      "Epoch 5; Step 135; Loss 0.581729; Train acc: 0.750000; Dev acc 0.746094\n",
      "Epoch 10; Step 270; Loss 0.549159; Train acc: 0.796875; Dev acc 0.707031\n",
      "Epoch 15; Step 405; Loss 0.551231; Train acc: 0.882812; Dev acc 0.769531\n",
      "Epoch 20; Step 540; Loss 0.547241; Train acc: 0.886719; Dev acc 0.757812\n",
      "Epoch 25; Step 675; Loss 0.526515; Train acc: 0.894531; Dev acc 0.722656\n",
      "Epoch 30; Step 810; Loss 0.528670; Train acc: 0.886719; Dev acc 0.738281\n",
      "Best dev accuracy is 0.76953125\n",
      "Best accuracy:  0.76953125\n",
      "64 / 576  =  (0.001, 50, 64, 2, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693161; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.579006; Train acc: 0.835938; Dev acc 0.761719\n",
      "Epoch 10; Step 270; Loss 0.553396; Train acc: 0.902344; Dev acc 0.777344\n",
      "Epoch 15; Step 405; Loss 0.510702; Train acc: 0.882812; Dev acc 0.718750\n",
      "Epoch 20; Step 540; Loss 0.384521; Train acc: 0.925781; Dev acc 0.742188\n",
      "Epoch 25; Step 675; Loss 0.384708; Train acc: 0.929688; Dev acc 0.707031\n",
      "Epoch 30; Step 810; Loss 0.386159; Train acc: 0.921875; Dev acc 0.761719\n",
      "Best dev accuracy is 0.77734375\n",
      "Best accuracy:  0.77734375\n",
      "65 / 576  =  (0.001, 50, 64, 2, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693158; Train acc: 0.492188; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.481001; Train acc: 0.816406; Dev acc 0.753906\n",
      "Epoch 10; Step 270; Loss 0.390846; Train acc: 0.921875; Dev acc 0.714844\n",
      "Epoch 15; Step 405; Loss 0.391675; Train acc: 0.910156; Dev acc 0.746094\n",
      "Epoch 20; Step 540; Loss 0.392989; Train acc: 0.917969; Dev acc 0.746094\n",
      "Epoch 25; Step 675; Loss 0.361718; Train acc: 0.937500; Dev acc 0.695312\n",
      "Epoch 30; Step 810; Loss 0.383624; Train acc: 0.933594; Dev acc 0.753906\n",
      "Best dev accuracy is 0.75390625\n",
      "Best accuracy:  0.75390625\n",
      "66 / 576  =  (0.001, 50, 64, 2, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.496094; Dev acc 0.542969\n",
      "Epoch 5; Step 135; Loss 0.576596; Train acc: 0.808594; Dev acc 0.761719\n",
      "Epoch 10; Step 270; Loss 0.550851; Train acc: 0.890625; Dev acc 0.714844\n",
      "Epoch 15; Step 405; Loss 0.533963; Train acc: 0.882812; Dev acc 0.730469\n",
      "Epoch 20; Step 540; Loss 0.542740; Train acc: 0.890625; Dev acc 0.753906\n",
      "Epoch 25; Step 675; Loss 0.533285; Train acc: 0.917969; Dev acc 0.726562\n",
      "Epoch 30; Step 810; Loss 0.529352; Train acc: 0.929688; Dev acc 0.722656\n",
      "Best dev accuracy is 0.76171875\n",
      "Best accuracy:  0.76171875\n",
      "67 / 576  =  (0.001, 50, 64, 2, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693148; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.460875; Train acc: 0.863281; Dev acc 0.750000\n",
      "Epoch 10; Step 270; Loss 0.417473; Train acc: 0.910156; Dev acc 0.769531\n",
      "Epoch 15; Step 405; Loss 0.381010; Train acc: 0.914062; Dev acc 0.753906\n",
      "Epoch 20; Step 540; Loss 0.375086; Train acc: 0.890625; Dev acc 0.734375\n",
      "Epoch 25; Step 675; Loss 0.374831; Train acc: 0.914062; Dev acc 0.714844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30; Step 810; Loss 0.349993; Train acc: 0.945312; Dev acc 0.699219\n",
      "Best dev accuracy is 0.76953125\n",
      "Best accuracy:  0.76953125\n",
      "68 / 576  =  (0.001, 50, 64, 2, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693143; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "69 / 576  =  (0.001, 50, 64, 2, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693148; Train acc: 0.519531; Dev acc 0.566406\n",
      "Epoch 5; Step 135; Loss 0.564070; Train acc: 0.789062; Dev acc 0.726562\n",
      "Epoch 10; Step 270; Loss 0.529327; Train acc: 0.882812; Dev acc 0.718750\n",
      "Epoch 15; Step 405; Loss 0.524351; Train acc: 0.906250; Dev acc 0.750000\n",
      "Epoch 20; Step 540; Loss 0.525302; Train acc: 0.925781; Dev acc 0.734375\n",
      "Epoch 25; Step 675; Loss 0.534355; Train acc: 0.898438; Dev acc 0.750000\n",
      "Epoch 30; Step 810; Loss 0.534584; Train acc: 0.937500; Dev acc 0.730469\n",
      "Best dev accuracy is 0.75\n",
      "Best accuracy:  0.75\n",
      "70 / 576  =  (0.001, 50, 64, 2, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693143; Train acc: 0.500000; Dev acc 0.542969\n",
      "Epoch 5; Step 135; Loss 0.517248; Train acc: 0.804688; Dev acc 0.769531\n",
      "Epoch 10; Step 270; Loss 0.397719; Train acc: 0.917969; Dev acc 0.726562\n",
      "Epoch 15; Step 405; Loss 0.404281; Train acc: 0.921875; Dev acc 0.722656\n",
      "Epoch 20; Step 540; Loss 0.382278; Train acc: 0.925781; Dev acc 0.714844\n",
      "Epoch 25; Step 675; Loss 0.365308; Train acc: 0.937500; Dev acc 0.718750\n",
      "Epoch 30; Step 810; Loss 0.384988; Train acc: 0.953125; Dev acc 0.718750\n",
      "Best dev accuracy is 0.76953125\n",
      "Best accuracy:  0.76953125\n",
      "71 / 576  =  (0.001, 50, 64, 2, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.562500; Dev acc 0.496094\n",
      "Epoch 5; Step 135; Loss 0.464223; Train acc: 0.804688; Dev acc 0.761719\n",
      "Epoch 10; Step 270; Loss 0.396794; Train acc: 0.894531; Dev acc 0.761719\n",
      "Epoch 15; Step 405; Loss 0.373967; Train acc: 0.902344; Dev acc 0.703125\n",
      "Epoch 20; Step 540; Loss 0.368845; Train acc: 0.921875; Dev acc 0.699219\n",
      "Epoch 25; Step 675; Loss 0.366899; Train acc: 0.933594; Dev acc 0.750000\n",
      "Epoch 30; Step 810; Loss 0.377517; Train acc: 0.890625; Dev acc 0.746094\n",
      "Best dev accuracy is 0.76171875\n",
      "Best accuracy:  0.76171875\n",
      "72 / 576  =  (0.001, 50, 64, 3, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693142; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.541762; Train acc: 0.789062; Dev acc 0.746094\n",
      "Epoch 10; Step 270; Loss 0.533955; Train acc: 0.878906; Dev acc 0.703125\n",
      "Epoch 15; Step 405; Loss 0.517579; Train acc: 0.898438; Dev acc 0.726562\n",
      "Epoch 20; Step 540; Loss 0.544685; Train acc: 0.941406; Dev acc 0.738281\n",
      "Epoch 25; Step 675; Loss 0.527903; Train acc: 0.941406; Dev acc 0.757812\n",
      "Epoch 30; Step 810; Loss 0.545489; Train acc: 0.917969; Dev acc 0.710938\n",
      "Best dev accuracy is 0.7578125\n",
      "Best accuracy:  0.7578125\n",
      "73 / 576  =  (0.001, 50, 64, 3, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.563039; Train acc: 0.804688; Dev acc 0.742188\n",
      "Epoch 10; Step 270; Loss 0.532833; Train acc: 0.882812; Dev acc 0.734375\n",
      "Epoch 15; Step 405; Loss 0.534958; Train acc: 0.894531; Dev acc 0.738281\n",
      "Epoch 20; Step 540; Loss 0.524695; Train acc: 0.914062; Dev acc 0.734375\n",
      "Epoch 25; Step 675; Loss 0.532001; Train acc: 0.914062; Dev acc 0.750000\n",
      "Epoch 30; Step 810; Loss 0.548764; Train acc: 0.917969; Dev acc 0.718750\n",
      "Best dev accuracy is 0.75\n",
      "Best accuracy:  0.75\n",
      "74 / 576  =  (0.001, 50, 64, 3, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.573776; Train acc: 0.863281; Dev acc 0.746094\n",
      "Epoch 10; Step 270; Loss 0.552705; Train acc: 0.875000; Dev acc 0.730469\n",
      "Epoch 15; Step 405; Loss 0.523482; Train acc: 0.914062; Dev acc 0.742188\n",
      "Epoch 20; Step 540; Loss 0.529604; Train acc: 0.910156; Dev acc 0.718750\n",
      "Epoch 25; Step 675; Loss 0.525896; Train acc: 0.898438; Dev acc 0.746094\n",
      "Epoch 30; Step 810; Loss 0.523108; Train acc: 0.917969; Dev acc 0.726562\n",
      "Best dev accuracy is 0.74609375\n",
      "Best accuracy:  0.74609375\n",
      "75 / 576  =  (0.001, 50, 64, 3, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "76 / 576  =  (0.001, 50, 64, 3, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693149; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.568182; Train acc: 0.828125; Dev acc 0.773438\n",
      "Epoch 10; Step 270; Loss 0.556560; Train acc: 0.894531; Dev acc 0.730469\n",
      "Epoch 15; Step 405; Loss 0.542298; Train acc: 0.902344; Dev acc 0.699219\n",
      "Epoch 20; Step 540; Loss 0.536023; Train acc: 0.925781; Dev acc 0.742188\n",
      "Epoch 25; Step 675; Loss 0.507195; Train acc: 0.902344; Dev acc 0.777344\n",
      "Epoch 30; Step 810; Loss 0.530444; Train acc: 0.886719; Dev acc 0.726562\n",
      "Best dev accuracy is 0.77734375\n",
      "Best accuracy:  0.77734375\n",
      "77 / 576  =  (0.001, 50, 64, 3, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "78 / 576  =  (0.001, 50, 64, 3, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693148; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "79 / 576  =  (0.001, 50, 64, 3, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693144; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "80 / 576  =  (0.001, 50, 64, 4, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "81 / 576  =  (0.001, 50, 64, 4, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693143; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "82 / 576  =  (0.001, 50, 64, 4, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.517549; Train acc: 0.824219; Dev acc 0.750000\n",
      "Epoch 10; Step 270; Loss 0.552471; Train acc: 0.878906; Dev acc 0.750000\n",
      "Epoch 15; Step 405; Loss 0.550767; Train acc: 0.882812; Dev acc 0.726562\n",
      "Epoch 20; Step 540; Loss 0.509325; Train acc: 0.906250; Dev acc 0.769531\n",
      "Epoch 25; Step 675; Loss 0.535225; Train acc: 0.925781; Dev acc 0.730469\n",
      "Epoch 30; Step 810; Loss 0.515408; Train acc: 0.910156; Dev acc 0.714844\n",
      "Best dev accuracy is 0.76953125\n",
      "Best accuracy:  0.76953125\n",
      "83 / 576  =  (0.001, 50, 64, 4, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "84 / 576  =  (0.001, 50, 64, 4, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693150; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.560425; Train acc: 0.804688; Dev acc 0.722656\n",
      "Epoch 10; Step 270; Loss 0.565734; Train acc: 0.859375; Dev acc 0.703125\n",
      "Epoch 15; Step 405; Loss 0.532734; Train acc: 0.882812; Dev acc 0.734375\n",
      "Epoch 20; Step 540; Loss 0.567246; Train acc: 0.910156; Dev acc 0.679688\n",
      "Epoch 25; Step 675; Loss 0.520041; Train acc: 0.882812; Dev acc 0.742188\n",
      "Epoch 30; Step 810; Loss 0.530586; Train acc: 0.910156; Dev acc 0.730469\n",
      "Best dev accuracy is 0.7421875\n",
      "Best accuracy:  0.7421875\n",
      "85 / 576  =  (0.001, 50, 64, 4, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.689980; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.688926; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692394; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.688639; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "86 / 576  =  (0.001, 50, 64, 4, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693145; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.563378; Train acc: 0.820312; Dev acc 0.742188\n",
      "Epoch 10; Step 270; Loss 0.528714; Train acc: 0.871094; Dev acc 0.738281\n",
      "Epoch 15; Step 405; Loss 0.527080; Train acc: 0.906250; Dev acc 0.757812\n",
      "Epoch 20; Step 540; Loss 0.559879; Train acc: 0.867188; Dev acc 0.730469\n",
      "Epoch 25; Step 675; Loss 0.538606; Train acc: 0.925781; Dev acc 0.726562\n",
      "Epoch 30; Step 810; Loss 0.534279; Train acc: 0.921875; Dev acc 0.707031\n",
      "Best dev accuracy is 0.7578125\n",
      "Best accuracy:  0.7578125\n",
      "87 / 576  =  (0.001, 50, 64, 4, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693148; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.569357; Train acc: 0.765625; Dev acc 0.746094\n",
      "Epoch 10; Step 270; Loss 0.583298; Train acc: 0.855469; Dev acc 0.757812\n",
      "Epoch 15; Step 405; Loss 0.559131; Train acc: 0.875000; Dev acc 0.734375\n",
      "Epoch 20; Step 540; Loss 0.559601; Train acc: 0.910156; Dev acc 0.714844\n",
      "Epoch 25; Step 675; Loss 0.525871; Train acc: 0.910156; Dev acc 0.691406\n",
      "Epoch 30; Step 810; Loss 0.546847; Train acc: 0.875000; Dev acc 0.726562\n",
      "Best dev accuracy is 0.7578125\n",
      "Best accuracy:  0.7578125\n",
      "88 / 576  =  (0.001, 50, 64, 5, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "89 / 576  =  (0.001, 50, 64, 5, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.574881; Train acc: 0.820312; Dev acc 0.750000\n",
      "Epoch 10; Step 270; Loss 0.574731; Train acc: 0.847656; Dev acc 0.742188\n",
      "Epoch 15; Step 405; Loss 0.561743; Train acc: 0.867188; Dev acc 0.726562\n",
      "Epoch 20; Step 540; Loss 0.522595; Train acc: 0.902344; Dev acc 0.750000\n",
      "Epoch 25; Step 675; Loss 0.540444; Train acc: 0.902344; Dev acc 0.761719\n",
      "Epoch 30; Step 810; Loss 0.567880; Train acc: 0.906250; Dev acc 0.730469\n",
      "Best dev accuracy is 0.76171875\n",
      "Best accuracy:  0.76171875\n",
      "90 / 576  =  (0.001, 50, 64, 5, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "91 / 576  =  (0.001, 50, 64, 5, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.585392; Train acc: 0.859375; Dev acc 0.750000\n",
      "Epoch 10; Step 270; Loss 0.553482; Train acc: 0.867188; Dev acc 0.718750\n",
      "Epoch 15; Step 405; Loss 0.515185; Train acc: 0.921875; Dev acc 0.750000\n",
      "Epoch 20; Step 540; Loss 0.531870; Train acc: 0.863281; Dev acc 0.722656\n",
      "Epoch 25; Step 675; Loss 0.531151; Train acc: 0.941406; Dev acc 0.710938\n",
      "Epoch 30; Step 810; Loss 0.534124; Train acc: 0.890625; Dev acc 0.750000\n",
      "Best dev accuracy is 0.75\n",
      "Best accuracy:  0.75\n",
      "92 / 576  =  (0.001, 50, 64, 5, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693148; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.576858; Train acc: 0.722656; Dev acc 0.699219\n",
      "Epoch 10; Step 270; Loss 0.547184; Train acc: 0.867188; Dev acc 0.781250\n",
      "Epoch 15; Step 405; Loss 0.556705; Train acc: 0.875000; Dev acc 0.730469\n",
      "Epoch 20; Step 540; Loss 0.588406; Train acc: 0.859375; Dev acc 0.734375\n",
      "Epoch 25; Step 675; Loss 0.571219; Train acc: 0.847656; Dev acc 0.730469\n",
      "Epoch 30; Step 810; Loss 0.549971; Train acc: 0.886719; Dev acc 0.718750\n",
      "Best dev accuracy is 0.78125\n",
      "Best accuracy:  0.78125\n",
      "93 / 576  =  (0.001, 50, 64, 5, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.575240; Train acc: 0.796875; Dev acc 0.730469\n",
      "Epoch 10; Step 270; Loss 0.576751; Train acc: 0.886719; Dev acc 0.781250\n",
      "Epoch 15; Step 405; Loss 0.578175; Train acc: 0.878906; Dev acc 0.742188\n",
      "Epoch 20; Step 540; Loss 0.546019; Train acc: 0.875000; Dev acc 0.738281\n",
      "Epoch 25; Step 675; Loss 0.553490; Train acc: 0.863281; Dev acc 0.734375\n",
      "Epoch 30; Step 810; Loss 0.555006; Train acc: 0.898438; Dev acc 0.750000\n",
      "Best dev accuracy is 0.78125\n",
      "Best accuracy:  0.78125\n",
      "94 / 576  =  (0.001, 50, 64, 5, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.574077; Train acc: 0.765625; Dev acc 0.765625\n",
      "Epoch 10; Step 270; Loss 0.522081; Train acc: 0.859375; Dev acc 0.691406\n",
      "Epoch 15; Step 405; Loss 0.431936; Train acc: 0.902344; Dev acc 0.742188\n",
      "Epoch 20; Step 540; Loss 0.403330; Train acc: 0.910156; Dev acc 0.738281\n",
      "Epoch 25; Step 675; Loss 0.395925; Train acc: 0.917969; Dev acc 0.710938\n",
      "Epoch 30; Step 810; Loss 0.406893; Train acc: 0.902344; Dev acc 0.722656\n",
      "Best dev accuracy is 0.765625\n",
      "Best accuracy:  0.765625\n",
      "95 / 576  =  (0.001, 50, 64, 5, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.496094; Dev acc 0.546875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5; Step 135; Loss 0.576874; Train acc: 0.750000; Dev acc 0.750000\n",
      "Epoch 10; Step 270; Loss 0.542947; Train acc: 0.839844; Dev acc 0.753906\n",
      "Epoch 15; Step 405; Loss 0.536287; Train acc: 0.835938; Dev acc 0.722656\n",
      "Epoch 20; Step 540; Loss 0.569097; Train acc: 0.851562; Dev acc 0.695312\n",
      "Epoch 25; Step 675; Loss 0.552946; Train acc: 0.878906; Dev acc 0.738281\n",
      "Epoch 30; Step 810; Loss 0.567395; Train acc: 0.898438; Dev acc 0.738281\n",
      "Best dev accuracy is 0.75390625\n",
      "Best accuracy:  0.75390625\n",
      "96 / 576  =  (0.001, 50, 128, 2, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693111; Train acc: 0.507812; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.478870; Train acc: 0.847656; Dev acc 0.781250\n",
      "Epoch 10; Step 270; Loss 0.393499; Train acc: 0.914062; Dev acc 0.750000\n",
      "Epoch 15; Step 405; Loss 0.374153; Train acc: 0.898438; Dev acc 0.675781\n",
      "Epoch 20; Step 540; Loss 0.387798; Train acc: 0.929688; Dev acc 0.742188\n",
      "Epoch 25; Step 675; Loss 0.383931; Train acc: 0.937500; Dev acc 0.742188\n",
      "Epoch 30; Step 810; Loss 0.368387; Train acc: 0.906250; Dev acc 0.722656\n",
      "Best dev accuracy is 0.78125\n",
      "Best accuracy:  0.78125\n",
      "97 / 576  =  (0.001, 50, 128, 2, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693181; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.541924; Train acc: 0.855469; Dev acc 0.738281\n",
      "Epoch 10; Step 270; Loss 0.538853; Train acc: 0.878906; Dev acc 0.753906\n",
      "Epoch 15; Step 405; Loss 0.534533; Train acc: 0.910156; Dev acc 0.742188\n",
      "Epoch 20; Step 540; Loss 0.538568; Train acc: 0.882812; Dev acc 0.734375\n",
      "Epoch 25; Step 675; Loss 0.536582; Train acc: 0.875000; Dev acc 0.753906\n",
      "Epoch 30; Step 810; Loss 0.506090; Train acc: 0.906250; Dev acc 0.714844\n",
      "Best dev accuracy is 0.75390625\n",
      "Best accuracy:  0.75390625\n",
      "98 / 576  =  (0.001, 50, 128, 2, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693168; Train acc: 0.488281; Dev acc 0.464844\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.46484375\n",
      "Best accuracy:  0.46484375\n",
      "99 / 576  =  (0.001, 50, 128, 2, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693152; Train acc: 0.492188; Dev acc 0.582031\n",
      "Epoch 5; Step 135; Loss 0.567236; Train acc: 0.859375; Dev acc 0.730469\n",
      "Epoch 10; Step 270; Loss 0.566674; Train acc: 0.902344; Dev acc 0.734375\n",
      "Epoch 15; Step 405; Loss 0.530416; Train acc: 0.910156; Dev acc 0.738281\n",
      "Epoch 20; Step 540; Loss 0.523338; Train acc: 0.910156; Dev acc 0.761719\n",
      "Epoch 25; Step 675; Loss 0.519055; Train acc: 0.875000; Dev acc 0.750000\n",
      "Epoch 30; Step 810; Loss 0.516925; Train acc: 0.914062; Dev acc 0.734375\n",
      "Best dev accuracy is 0.76171875\n",
      "Best accuracy:  0.76171875\n",
      "100 / 576  =  (0.001, 50, 128, 2, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693150; Train acc: 0.492188; Dev acc 0.539062\n",
      "Epoch 5; Step 135; Loss 0.467452; Train acc: 0.878906; Dev acc 0.789062\n",
      "Epoch 10; Step 270; Loss 0.404871; Train acc: 0.921875; Dev acc 0.746094\n",
      "Epoch 15; Step 405; Loss 0.386010; Train acc: 0.914062; Dev acc 0.710938\n",
      "Epoch 20; Step 540; Loss 0.387782; Train acc: 0.906250; Dev acc 0.738281\n",
      "Epoch 25; Step 675; Loss 0.379440; Train acc: 0.945312; Dev acc 0.679688\n",
      "Epoch 30; Step 810; Loss 0.363206; Train acc: 0.933594; Dev acc 0.722656\n",
      "Best dev accuracy is 0.7890625\n",
      "Best accuracy:  0.7890625\n",
      "101 / 576  =  (0.001, 50, 128, 2, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693135; Train acc: 0.500000; Dev acc 0.539062\n",
      "Epoch 5; Step 135; Loss 0.546462; Train acc: 0.847656; Dev acc 0.773438\n",
      "Epoch 10; Step 270; Loss 0.543525; Train acc: 0.878906; Dev acc 0.742188\n",
      "Epoch 15; Step 405; Loss 0.416967; Train acc: 0.898438; Dev acc 0.730469\n",
      "Epoch 20; Step 540; Loss 0.397945; Train acc: 0.937500; Dev acc 0.710938\n",
      "Epoch 25; Step 675; Loss 0.394792; Train acc: 0.906250; Dev acc 0.664062\n",
      "Epoch 30; Step 810; Loss 0.381049; Train acc: 0.925781; Dev acc 0.726562\n",
      "Best dev accuracy is 0.7734375\n",
      "Best accuracy:  0.7734375\n",
      "102 / 576  =  (0.001, 50, 128, 2, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693138; Train acc: 0.503906; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.601951; Train acc: 0.839844; Dev acc 0.714844\n",
      "Epoch 10; Step 270; Loss 0.527199; Train acc: 0.910156; Dev acc 0.765625\n",
      "Epoch 15; Step 405; Loss 0.541296; Train acc: 0.910156; Dev acc 0.742188\n",
      "Epoch 20; Step 540; Loss 0.520163; Train acc: 0.863281; Dev acc 0.742188\n",
      "Epoch 25; Step 675; Loss 0.552566; Train acc: 0.917969; Dev acc 0.730469\n",
      "Epoch 30; Step 810; Loss 0.524191; Train acc: 0.898438; Dev acc 0.730469\n",
      "Best dev accuracy is 0.765625\n",
      "Best accuracy:  0.765625\n",
      "103 / 576  =  (0.001, 50, 128, 2, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693197; Train acc: 0.519531; Dev acc 0.570312\n",
      "Epoch 5; Step 135; Loss 0.580551; Train acc: 0.832031; Dev acc 0.792969\n",
      "Epoch 10; Step 270; Loss 0.529967; Train acc: 0.898438; Dev acc 0.750000\n",
      "Epoch 15; Step 405; Loss 0.530968; Train acc: 0.910156; Dev acc 0.750000\n",
      "Epoch 20; Step 540; Loss 0.534825; Train acc: 0.890625; Dev acc 0.722656\n",
      "Epoch 25; Step 675; Loss 0.519130; Train acc: 0.933594; Dev acc 0.722656\n",
      "Epoch 30; Step 810; Loss 0.527710; Train acc: 0.917969; Dev acc 0.742188\n",
      "Best dev accuracy is 0.79296875\n",
      "Best accuracy:  0.79296875\n",
      "104 / 576  =  (0.001, 50, 128, 3, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.515625; Dev acc 0.445312\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "105 / 576  =  (0.001, 50, 128, 3, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.582705; Train acc: 0.847656; Dev acc 0.722656\n",
      "Epoch 10; Step 270; Loss 0.566369; Train acc: 0.894531; Dev acc 0.757812\n",
      "Epoch 15; Step 405; Loss 0.545510; Train acc: 0.937500; Dev acc 0.785156\n",
      "Epoch 20; Step 540; Loss 0.560880; Train acc: 0.906250; Dev acc 0.761719\n",
      "Epoch 25; Step 675; Loss 0.534773; Train acc: 0.929688; Dev acc 0.726562\n",
      "Epoch 30; Step 810; Loss 0.538848; Train acc: 0.925781; Dev acc 0.722656\n",
      "Best dev accuracy is 0.78515625\n",
      "Best accuracy:  0.78515625\n",
      "106 / 576  =  (0.001, 50, 128, 3, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.568976; Train acc: 0.828125; Dev acc 0.769531\n",
      "Epoch 10; Step 270; Loss 0.563602; Train acc: 0.871094; Dev acc 0.738281\n",
      "Epoch 15; Step 405; Loss 0.548044; Train acc: 0.910156; Dev acc 0.750000\n",
      "Epoch 20; Step 540; Loss 0.551519; Train acc: 0.875000; Dev acc 0.746094\n",
      "Epoch 25; Step 675; Loss 0.537937; Train acc: 0.882812; Dev acc 0.683594\n",
      "Epoch 30; Step 810; Loss 0.550233; Train acc: 0.921875; Dev acc 0.765625\n",
      "Best dev accuracy is 0.76953125\n",
      "Best accuracy:  0.76953125\n",
      "107 / 576  =  (0.001, 50, 128, 3, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693162; Train acc: 0.496094; Dev acc 0.550781\n",
      "Epoch 5; Step 135; Loss 0.452374; Train acc: 0.835938; Dev acc 0.761719\n",
      "Epoch 10; Step 270; Loss 0.380292; Train acc: 0.917969; Dev acc 0.714844\n",
      "Epoch 15; Step 405; Loss 0.402491; Train acc: 0.925781; Dev acc 0.742188\n",
      "Epoch 20; Step 540; Loss 0.404958; Train acc: 0.917969; Dev acc 0.722656\n",
      "Epoch 25; Step 675; Loss 0.404753; Train acc: 0.933594; Dev acc 0.746094\n",
      "Epoch 30; Step 810; Loss 0.364607; Train acc: 0.941406; Dev acc 0.718750\n",
      "Best dev accuracy is 0.76171875\n",
      "Best accuracy:  0.76171875\n",
      "108 / 576  =  (0.001, 50, 128, 3, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693149; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "109 / 576  =  (0.001, 50, 128, 3, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693149; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "110 / 576  =  (0.001, 50, 128, 3, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693156; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "111 / 576  =  (0.001, 50, 128, 3, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693144; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.582214; Train acc: 0.824219; Dev acc 0.746094\n",
      "Epoch 10; Step 270; Loss 0.561559; Train acc: 0.878906; Dev acc 0.746094\n",
      "Epoch 15; Step 405; Loss 0.552355; Train acc: 0.839844; Dev acc 0.738281\n",
      "Epoch 20; Step 540; Loss 0.535623; Train acc: 0.871094; Dev acc 0.710938\n",
      "Epoch 25; Step 675; Loss 0.557191; Train acc: 0.871094; Dev acc 0.710938\n",
      "Epoch 30; Step 810; Loss 0.525909; Train acc: 0.925781; Dev acc 0.738281\n",
      "Best dev accuracy is 0.74609375\n",
      "Best accuracy:  0.74609375\n",
      "112 / 576  =  (0.001, 50, 128, 4, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693149; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.578559; Train acc: 0.808594; Dev acc 0.738281\n",
      "Epoch 10; Step 270; Loss 0.538506; Train acc: 0.878906; Dev acc 0.785156\n",
      "Epoch 15; Step 405; Loss 0.552536; Train acc: 0.878906; Dev acc 0.699219\n",
      "Epoch 20; Step 540; Loss 0.549861; Train acc: 0.898438; Dev acc 0.750000\n",
      "Epoch 25; Step 675; Loss 0.534976; Train acc: 0.902344; Dev acc 0.734375\n",
      "Epoch 30; Step 810; Loss 0.537798; Train acc: 0.878906; Dev acc 0.742188\n",
      "Best dev accuracy is 0.78515625\n",
      "Best accuracy:  0.78515625\n",
      "113 / 576  =  (0.001, 50, 128, 4, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693155; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.552494; Train acc: 0.867188; Dev acc 0.769531\n",
      "Epoch 10; Step 270; Loss 0.530672; Train acc: 0.839844; Dev acc 0.714844\n",
      "Epoch 15; Step 405; Loss 0.552628; Train acc: 0.843750; Dev acc 0.699219\n",
      "Epoch 20; Step 540; Loss 0.543579; Train acc: 0.894531; Dev acc 0.714844\n",
      "Epoch 25; Step 675; Loss 0.524080; Train acc: 0.902344; Dev acc 0.726562\n",
      "Epoch 30; Step 810; Loss 0.528119; Train acc: 0.843750; Dev acc 0.699219\n",
      "Best dev accuracy is 0.76953125\n",
      "Best accuracy:  0.76953125\n",
      "114 / 576  =  (0.001, 50, 128, 4, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693149; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "115 / 576  =  (0.001, 50, 128, 4, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693149; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "116 / 576  =  (0.001, 50, 128, 4, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693145; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693497; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693880; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.690994; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.688819; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "117 / 576  =  (0.001, 50, 128, 4, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693144; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.562136; Train acc: 0.816406; Dev acc 0.683594\n",
      "Epoch 10; Step 270; Loss 0.536195; Train acc: 0.851562; Dev acc 0.726562\n",
      "Epoch 15; Step 405; Loss 0.553465; Train acc: 0.867188; Dev acc 0.718750\n",
      "Epoch 20; Step 540; Loss 0.535806; Train acc: 0.855469; Dev acc 0.722656\n",
      "Epoch 25; Step 675; Loss 0.546140; Train acc: 0.843750; Dev acc 0.742188\n",
      "Epoch 30; Step 810; Loss 0.549242; Train acc: 0.917969; Dev acc 0.769531\n",
      "Best dev accuracy is 0.76953125\n",
      "Best accuracy:  0.76953125\n",
      "118 / 576  =  (0.001, 50, 128, 4, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693145; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.576211; Train acc: 0.828125; Dev acc 0.761719\n",
      "Epoch 10; Step 270; Loss 0.576304; Train acc: 0.816406; Dev acc 0.738281\n",
      "Epoch 15; Step 405; Loss 0.545313; Train acc: 0.906250; Dev acc 0.753906\n",
      "Epoch 20; Step 540; Loss 0.553564; Train acc: 0.875000; Dev acc 0.734375\n",
      "Epoch 25; Step 675; Loss 0.531725; Train acc: 0.898438; Dev acc 0.753906\n",
      "Epoch 30; Step 810; Loss 0.552461; Train acc: 0.890625; Dev acc 0.718750\n",
      "Best dev accuracy is 0.76171875\n",
      "Best accuracy:  0.76171875\n",
      "119 / 576  =  (0.001, 50, 128, 4, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.500000; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.584738; Train acc: 0.761719; Dev acc 0.730469\n",
      "Epoch 10; Step 270; Loss 0.563466; Train acc: 0.847656; Dev acc 0.726562\n",
      "Epoch 15; Step 405; Loss 0.574928; Train acc: 0.855469; Dev acc 0.761719\n",
      "Epoch 20; Step 540; Loss 0.560943; Train acc: 0.847656; Dev acc 0.742188\n",
      "Epoch 25; Step 675; Loss 0.550863; Train acc: 0.875000; Dev acc 0.761719\n",
      "Epoch 30; Step 810; Loss 0.548400; Train acc: 0.890625; Dev acc 0.777344\n",
      "Best dev accuracy is 0.77734375\n",
      "Best accuracy:  0.77734375\n",
      "120 / 576  =  (0.001, 50, 128, 5, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693149; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.551538; Train acc: 0.812500; Dev acc 0.734375\n",
      "Epoch 10; Step 270; Loss 0.545485; Train acc: 0.878906; Dev acc 0.738281\n",
      "Epoch 15; Step 405; Loss 0.576075; Train acc: 0.894531; Dev acc 0.738281\n",
      "Epoch 20; Step 540; Loss 0.529390; Train acc: 0.843750; Dev acc 0.769531\n",
      "Epoch 25; Step 675; Loss 0.543353; Train acc: 0.859375; Dev acc 0.710938\n",
      "Epoch 30; Step 810; Loss 0.531929; Train acc: 0.914062; Dev acc 0.742188\n",
      "Best dev accuracy is 0.76953125\n",
      "Best accuracy:  0.76953125\n",
      "121 / 576  =  (0.001, 50, 128, 5, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.492188; Dev acc 0.535156\n",
      "Epoch 5; Step 135; Loss 0.433544; Train acc: 0.847656; Dev acc 0.738281\n",
      "Epoch 10; Step 270; Loss 0.383035; Train acc: 0.898438; Dev acc 0.730469\n",
      "Epoch 15; Step 405; Loss 0.401482; Train acc: 0.914062; Dev acc 0.746094\n",
      "Epoch 20; Step 540; Loss 0.372371; Train acc: 0.914062; Dev acc 0.714844\n",
      "Epoch 25; Step 675; Loss 0.382050; Train acc: 0.921875; Dev acc 0.714844\n",
      "Epoch 30; Step 810; Loss 0.398084; Train acc: 0.949219; Dev acc 0.738281\n",
      "Best dev accuracy is 0.74609375\n",
      "Best accuracy:  0.74609375\n",
      "122 / 576  =  (0.001, 50, 128, 5, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693148; Train acc: 0.503906; Dev acc 0.453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "123 / 576  =  (0.001, 50, 128, 5, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "124 / 576  =  (0.001, 50, 128, 5, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693148; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "125 / 576  =  (0.001, 50, 128, 5, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693152; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "126 / 576  =  (0.001, 50, 128, 5, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.565902; Train acc: 0.773438; Dev acc 0.750000\n",
      "Epoch 10; Step 270; Loss 0.553886; Train acc: 0.867188; Dev acc 0.761719\n",
      "Epoch 15; Step 405; Loss 0.547350; Train acc: 0.839844; Dev acc 0.718750\n",
      "Epoch 20; Step 540; Loss 0.567529; Train acc: 0.898438; Dev acc 0.738281\n",
      "Epoch 25; Step 675; Loss 0.561687; Train acc: 0.882812; Dev acc 0.761719\n",
      "Epoch 30; Step 810; Loss 0.551070; Train acc: 0.906250; Dev acc 0.703125\n",
      "Best dev accuracy is 0.76171875\n",
      "Best accuracy:  0.76171875\n",
      "127 / 576  =  (0.001, 50, 128, 5, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693149; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.580798; Train acc: 0.808594; Dev acc 0.730469\n",
      "Epoch 10; Step 270; Loss 0.565579; Train acc: 0.847656; Dev acc 0.703125\n",
      "Epoch 15; Step 405; Loss 0.553105; Train acc: 0.871094; Dev acc 0.769531\n",
      "Epoch 20; Step 540; Loss 0.573863; Train acc: 0.882812; Dev acc 0.730469\n",
      "Epoch 25; Step 675; Loss 0.541298; Train acc: 0.863281; Dev acc 0.734375\n",
      "Epoch 30; Step 810; Loss 0.528530; Train acc: 0.910156; Dev acc 0.714844\n",
      "Best dev accuracy is 0.76953125\n",
      "Best accuracy:  0.76953125\n",
      "128 / 576  =  (0.001, 200, 64, 2, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693126; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "129 / 576  =  (0.001, 200, 64, 2, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693189; Train acc: 0.500000; Dev acc 0.480469\n",
      "Epoch 5; Step 135; Loss 0.444864; Train acc: 0.894531; Dev acc 0.753906\n",
      "Epoch 10; Step 270; Loss 0.403682; Train acc: 0.929688; Dev acc 0.738281\n",
      "Epoch 15; Step 405; Loss 0.372777; Train acc: 0.937500; Dev acc 0.738281\n",
      "Epoch 20; Step 540; Loss 0.411330; Train acc: 0.917969; Dev acc 0.714844\n",
      "Epoch 25; Step 675; Loss 0.374885; Train acc: 0.941406; Dev acc 0.726562\n",
      "Epoch 30; Step 810; Loss 0.367163; Train acc: 0.906250; Dev acc 0.738281\n",
      "Best dev accuracy is 0.75390625\n",
      "Best accuracy:  0.75390625\n",
      "130 / 576  =  (0.001, 200, 64, 2, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693160; Train acc: 0.496094; Dev acc 0.554688\n",
      "Epoch 5; Step 135; Loss 0.546699; Train acc: 0.828125; Dev acc 0.796875\n",
      "Epoch 10; Step 270; Loss 0.541808; Train acc: 0.886719; Dev acc 0.730469\n",
      "Epoch 15; Step 405; Loss 0.534822; Train acc: 0.890625; Dev acc 0.742188\n",
      "Epoch 20; Step 540; Loss 0.534191; Train acc: 0.933594; Dev acc 0.746094\n",
      "Epoch 25; Step 675; Loss 0.527375; Train acc: 0.937500; Dev acc 0.726562\n",
      "Epoch 30; Step 810; Loss 0.541816; Train acc: 0.917969; Dev acc 0.757812\n",
      "Best dev accuracy is 0.796875\n",
      "Best accuracy:  0.796875\n",
      "131 / 576  =  (0.001, 200, 64, 2, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693113; Train acc: 0.546875; Dev acc 0.539062\n",
      "Epoch 5; Step 135; Loss 0.438541; Train acc: 0.871094; Dev acc 0.769531\n",
      "Epoch 10; Step 270; Loss 0.403908; Train acc: 0.914062; Dev acc 0.734375\n",
      "Epoch 15; Step 405; Loss 0.362345; Train acc: 0.929688; Dev acc 0.757812\n",
      "Epoch 20; Step 540; Loss 0.358322; Train acc: 0.953125; Dev acc 0.722656\n",
      "Epoch 25; Step 675; Loss 0.386044; Train acc: 0.949219; Dev acc 0.710938\n",
      "Epoch 30; Step 810; Loss 0.367969; Train acc: 0.937500; Dev acc 0.761719\n",
      "Best dev accuracy is 0.76953125\n",
      "Best accuracy:  0.76953125\n",
      "132 / 576  =  (0.001, 200, 64, 2, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693187; Train acc: 0.531250; Dev acc 0.554688\n",
      "Epoch 5; Step 135; Loss 0.569064; Train acc: 0.878906; Dev acc 0.761719\n",
      "Epoch 10; Step 270; Loss 0.526116; Train acc: 0.871094; Dev acc 0.734375\n",
      "Epoch 15; Step 405; Loss 0.523430; Train acc: 0.882812; Dev acc 0.738281\n",
      "Epoch 20; Step 540; Loss 0.525518; Train acc: 0.851562; Dev acc 0.746094\n",
      "Epoch 25; Step 675; Loss 0.548685; Train acc: 0.882812; Dev acc 0.687500\n",
      "Epoch 30; Step 810; Loss 0.527083; Train acc: 0.886719; Dev acc 0.734375\n",
      "Best dev accuracy is 0.76171875\n",
      "Best accuracy:  0.76171875\n",
      "133 / 576  =  (0.001, 200, 64, 2, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693155; Train acc: 0.535156; Dev acc 0.527344\n",
      "Epoch 5; Step 135; Loss 0.473500; Train acc: 0.839844; Dev acc 0.746094\n",
      "Epoch 10; Step 270; Loss 0.411380; Train acc: 0.886719; Dev acc 0.742188\n",
      "Epoch 15; Step 405; Loss 0.380864; Train acc: 0.917969; Dev acc 0.710938\n",
      "Epoch 20; Step 540; Loss 0.375294; Train acc: 0.921875; Dev acc 0.722656\n",
      "Epoch 25; Step 675; Loss 0.382501; Train acc: 0.902344; Dev acc 0.707031\n",
      "Epoch 30; Step 810; Loss 0.401256; Train acc: 0.890625; Dev acc 0.695312\n",
      "Best dev accuracy is 0.74609375\n",
      "Best accuracy:  0.74609375\n",
      "134 / 576  =  (0.001, 200, 64, 2, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693154; Train acc: 0.515625; Dev acc 0.503906\n",
      "Epoch 5; Step 135; Loss 0.479524; Train acc: 0.839844; Dev acc 0.746094\n",
      "Epoch 10; Step 270; Loss 0.431833; Train acc: 0.886719; Dev acc 0.734375\n",
      "Epoch 15; Step 405; Loss 0.375198; Train acc: 0.921875; Dev acc 0.746094\n",
      "Epoch 20; Step 540; Loss 0.400244; Train acc: 0.906250; Dev acc 0.753906\n",
      "Epoch 25; Step 675; Loss 0.396574; Train acc: 0.914062; Dev acc 0.742188\n",
      "Epoch 30; Step 810; Loss 0.394813; Train acc: 0.937500; Dev acc 0.742188\n",
      "Best dev accuracy is 0.75390625\n",
      "Best accuracy:  0.75390625\n",
      "135 / 576  =  (0.001, 200, 64, 2, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693164; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "136 / 576  =  (0.001, 200, 64, 3, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693152; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.548386; Train acc: 0.859375; Dev acc 0.781250\n",
      "Epoch 10; Step 270; Loss 0.550646; Train acc: 0.882812; Dev acc 0.730469\n",
      "Epoch 15; Step 405; Loss 0.551900; Train acc: 0.898438; Dev acc 0.746094\n",
      "Epoch 20; Step 540; Loss 0.560019; Train acc: 0.898438; Dev acc 0.730469\n",
      "Epoch 25; Step 675; Loss 0.544064; Train acc: 0.906250; Dev acc 0.753906\n",
      "Epoch 30; Step 810; Loss 0.530598; Train acc: 0.906250; Dev acc 0.730469\n",
      "Best dev accuracy is 0.78125\n",
      "Best accuracy:  0.78125\n",
      "137 / 576  =  (0.001, 200, 64, 3, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693164; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.583750; Train acc: 0.824219; Dev acc 0.699219\n",
      "Epoch 10; Step 270; Loss 0.564228; Train acc: 0.871094; Dev acc 0.746094\n",
      "Epoch 15; Step 405; Loss 0.522809; Train acc: 0.894531; Dev acc 0.667969\n",
      "Epoch 20; Step 540; Loss 0.529970; Train acc: 0.894531; Dev acc 0.742188\n",
      "Epoch 25; Step 675; Loss 0.537697; Train acc: 0.902344; Dev acc 0.707031\n",
      "Epoch 30; Step 810; Loss 0.539248; Train acc: 0.933594; Dev acc 0.718750\n",
      "Best dev accuracy is 0.74609375\n",
      "Best accuracy:  0.74609375\n",
      "138 / 576  =  (0.001, 200, 64, 3, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693155; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "139 / 576  =  (0.001, 200, 64, 3, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693150; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.443441; Train acc: 0.882812; Dev acc 0.753906\n",
      "Epoch 10; Step 270; Loss 0.407228; Train acc: 0.910156; Dev acc 0.710938\n",
      "Epoch 15; Step 405; Loss 0.373655; Train acc: 0.933594; Dev acc 0.714844\n",
      "Epoch 20; Step 540; Loss 0.377968; Train acc: 0.917969; Dev acc 0.695312\n",
      "Epoch 25; Step 675; Loss 0.383771; Train acc: 0.925781; Dev acc 0.714844\n",
      "Epoch 30; Step 810; Loss 0.354290; Train acc: 0.933594; Dev acc 0.687500\n",
      "Best dev accuracy is 0.75390625\n",
      "Best accuracy:  0.75390625\n",
      "140 / 576  =  (0.001, 200, 64, 3, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693175; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.450709; Train acc: 0.832031; Dev acc 0.738281\n",
      "Epoch 10; Step 270; Loss 0.394788; Train acc: 0.855469; Dev acc 0.714844\n",
      "Epoch 15; Step 405; Loss 0.401806; Train acc: 0.906250; Dev acc 0.761719\n",
      "Epoch 20; Step 540; Loss 0.398561; Train acc: 0.914062; Dev acc 0.757812\n",
      "Epoch 25; Step 675; Loss 0.408866; Train acc: 0.917969; Dev acc 0.722656\n",
      "Epoch 30; Step 810; Loss 0.365152; Train acc: 0.902344; Dev acc 0.738281\n",
      "Best dev accuracy is 0.76171875\n",
      "Best accuracy:  0.76171875\n",
      "141 / 576  =  (0.001, 200, 64, 3, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693142; Train acc: 0.484375; Dev acc 0.441406\n",
      "Epoch 5; Step 135; Loss 0.571434; Train acc: 0.828125; Dev acc 0.753906\n",
      "Epoch 10; Step 270; Loss 0.559132; Train acc: 0.792969; Dev acc 0.726562\n",
      "Epoch 15; Step 405; Loss 0.568583; Train acc: 0.835938; Dev acc 0.753906\n",
      "Epoch 20; Step 540; Loss 0.562785; Train acc: 0.839844; Dev acc 0.734375\n",
      "Epoch 25; Step 675; Loss 0.534708; Train acc: 0.902344; Dev acc 0.722656\n",
      "Epoch 30; Step 810; Loss 0.559146; Train acc: 0.875000; Dev acc 0.738281\n",
      "Best dev accuracy is 0.75390625\n",
      "Best accuracy:  0.75390625\n",
      "142 / 576  =  (0.001, 200, 64, 3, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693144; Train acc: 0.480469; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.571081; Train acc: 0.796875; Dev acc 0.742188\n",
      "Epoch 10; Step 270; Loss 0.542651; Train acc: 0.859375; Dev acc 0.746094\n",
      "Epoch 15; Step 405; Loss 0.540952; Train acc: 0.855469; Dev acc 0.699219\n",
      "Epoch 20; Step 540; Loss 0.569881; Train acc: 0.914062; Dev acc 0.714844\n",
      "Epoch 25; Step 675; Loss 0.544360; Train acc: 0.871094; Dev acc 0.777344\n",
      "Epoch 30; Step 810; Loss 0.550771; Train acc: 0.925781; Dev acc 0.746094\n",
      "Best dev accuracy is 0.77734375\n",
      "Best accuracy:  0.77734375\n",
      "143 / 576  =  (0.001, 200, 64, 3, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.503906; Dev acc 0.550781\n",
      "Epoch 5; Step 135; Loss 0.568240; Train acc: 0.824219; Dev acc 0.753906\n",
      "Epoch 10; Step 270; Loss 0.400163; Train acc: 0.882812; Dev acc 0.753906\n",
      "Epoch 15; Step 405; Loss 0.440446; Train acc: 0.902344; Dev acc 0.738281\n",
      "Epoch 20; Step 540; Loss 0.391077; Train acc: 0.914062; Dev acc 0.734375\n",
      "Epoch 25; Step 675; Loss 0.366944; Train acc: 0.925781; Dev acc 0.765625\n",
      "Epoch 30; Step 810; Loss 0.385339; Train acc: 0.898438; Dev acc 0.722656\n",
      "Best dev accuracy is 0.765625\n",
      "Best accuracy:  0.765625\n",
      "144 / 576  =  (0.001, 200, 64, 4, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.492188; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.414009; Train acc: 0.859375; Dev acc 0.722656\n",
      "Epoch 10; Step 270; Loss 0.376279; Train acc: 0.859375; Dev acc 0.710938\n",
      "Epoch 15; Step 405; Loss 0.400595; Train acc: 0.902344; Dev acc 0.703125\n",
      "Epoch 20; Step 540; Loss 0.372073; Train acc: 0.906250; Dev acc 0.734375\n",
      "Epoch 25; Step 675; Loss 0.384895; Train acc: 0.933594; Dev acc 0.746094\n",
      "Epoch 30; Step 810; Loss 0.359205; Train acc: 0.937500; Dev acc 0.691406\n",
      "Best dev accuracy is 0.74609375\n",
      "Best accuracy:  0.74609375\n",
      "145 / 576  =  (0.001, 200, 64, 4, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693149; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.581421; Train acc: 0.824219; Dev acc 0.730469\n",
      "Epoch 10; Step 270; Loss 0.557017; Train acc: 0.890625; Dev acc 0.742188\n",
      "Epoch 15; Step 405; Loss 0.548217; Train acc: 0.867188; Dev acc 0.738281\n",
      "Epoch 20; Step 540; Loss 0.540396; Train acc: 0.890625; Dev acc 0.675781\n",
      "Epoch 25; Step 675; Loss 0.553280; Train acc: 0.925781; Dev acc 0.742188\n",
      "Epoch 30; Step 810; Loss 0.530595; Train acc: 0.914062; Dev acc 0.750000\n",
      "Best dev accuracy is 0.75\n",
      "Best accuracy:  0.75\n",
      "146 / 576  =  (0.001, 200, 64, 4, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693148; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "147 / 576  =  (0.001, 200, 64, 4, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693143; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.567904; Train acc: 0.859375; Dev acc 0.722656\n",
      "Epoch 10; Step 270; Loss 0.542299; Train acc: 0.886719; Dev acc 0.718750\n",
      "Epoch 15; Step 405; Loss 0.551014; Train acc: 0.847656; Dev acc 0.710938\n",
      "Epoch 20; Step 540; Loss 0.543164; Train acc: 0.882812; Dev acc 0.707031\n",
      "Epoch 25; Step 675; Loss 0.546078; Train acc: 0.890625; Dev acc 0.718750\n",
      "Epoch 30; Step 810; Loss 0.539311; Train acc: 0.882812; Dev acc 0.699219\n",
      "Best dev accuracy is 0.72265625\n",
      "Best accuracy:  0.72265625\n",
      "148 / 576  =  (0.001, 200, 64, 4, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693152; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "149 / 576  =  (0.001, 200, 64, 4, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693150; Train acc: 0.503906; Dev acc 0.453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5; Step 135; Loss 0.563684; Train acc: 0.820312; Dev acc 0.746094\n",
      "Epoch 10; Step 270; Loss 0.568554; Train acc: 0.835938; Dev acc 0.742188\n",
      "Epoch 15; Step 405; Loss 0.548570; Train acc: 0.855469; Dev acc 0.753906\n",
      "Epoch 20; Step 540; Loss 0.533792; Train acc: 0.886719; Dev acc 0.730469\n",
      "Epoch 25; Step 675; Loss 0.565474; Train acc: 0.863281; Dev acc 0.773438\n",
      "Epoch 30; Step 810; Loss 0.519691; Train acc: 0.886719; Dev acc 0.757812\n",
      "Best dev accuracy is 0.7734375\n",
      "Best accuracy:  0.7734375\n",
      "150 / 576  =  (0.001, 200, 64, 4, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693145; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.584764; Train acc: 0.835938; Dev acc 0.773438\n",
      "Epoch 10; Step 270; Loss 0.537414; Train acc: 0.855469; Dev acc 0.734375\n",
      "Epoch 15; Step 405; Loss 0.541919; Train acc: 0.867188; Dev acc 0.746094\n",
      "Epoch 20; Step 540; Loss 0.527888; Train acc: 0.878906; Dev acc 0.714844\n",
      "Epoch 25; Step 675; Loss 0.538851; Train acc: 0.894531; Dev acc 0.746094\n",
      "Epoch 30; Step 810; Loss 0.546046; Train acc: 0.902344; Dev acc 0.714844\n",
      "Best dev accuracy is 0.7734375\n",
      "Best accuracy:  0.7734375\n",
      "151 / 576  =  (0.001, 200, 64, 4, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "152 / 576  =  (0.001, 200, 64, 5, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "153 / 576  =  (0.001, 200, 64, 5, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693149; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.568003; Train acc: 0.804688; Dev acc 0.761719\n",
      "Epoch 10; Step 270; Loss 0.555631; Train acc: 0.867188; Dev acc 0.710938\n",
      "Epoch 15; Step 405; Loss 0.550719; Train acc: 0.886719; Dev acc 0.718750\n",
      "Epoch 20; Step 540; Loss 0.532612; Train acc: 0.902344; Dev acc 0.695312\n",
      "Epoch 25; Step 675; Loss 0.533858; Train acc: 0.914062; Dev acc 0.687500\n",
      "Epoch 30; Step 810; Loss 0.566950; Train acc: 0.917969; Dev acc 0.722656\n",
      "Best dev accuracy is 0.76171875\n",
      "Best accuracy:  0.76171875\n",
      "154 / 576  =  (0.001, 200, 64, 5, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693148; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.556795; Train acc: 0.812500; Dev acc 0.746094\n",
      "Epoch 10; Step 270; Loss 0.549878; Train acc: 0.882812; Dev acc 0.738281\n",
      "Epoch 15; Step 405; Loss 0.560359; Train acc: 0.855469; Dev acc 0.710938\n",
      "Epoch 20; Step 540; Loss 0.522734; Train acc: 0.878906; Dev acc 0.722656\n",
      "Epoch 25; Step 675; Loss 0.534178; Train acc: 0.921875; Dev acc 0.734375\n",
      "Epoch 30; Step 810; Loss 0.575271; Train acc: 0.906250; Dev acc 0.738281\n",
      "Best dev accuracy is 0.74609375\n",
      "Best accuracy:  0.74609375\n",
      "155 / 576  =  (0.001, 200, 64, 5, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.570106; Train acc: 0.820312; Dev acc 0.703125\n",
      "Epoch 10; Step 270; Loss 0.541458; Train acc: 0.832031; Dev acc 0.738281\n",
      "Epoch 15; Step 405; Loss 0.554789; Train acc: 0.886719; Dev acc 0.695312\n",
      "Epoch 20; Step 540; Loss 0.534011; Train acc: 0.890625; Dev acc 0.742188\n",
      "Epoch 25; Step 675; Loss 0.568700; Train acc: 0.902344; Dev acc 0.742188\n",
      "Epoch 30; Step 810; Loss 0.530365; Train acc: 0.886719; Dev acc 0.710938\n",
      "Best dev accuracy is 0.7421875\n",
      "Best accuracy:  0.7421875\n",
      "156 / 576  =  (0.001, 200, 64, 5, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.476562; Dev acc 0.511719\n",
      "Epoch 5; Step 135; Loss 0.561480; Train acc: 0.800781; Dev acc 0.738281\n",
      "Epoch 10; Step 270; Loss 0.577779; Train acc: 0.835938; Dev acc 0.718750\n",
      "Epoch 15; Step 405; Loss 0.541970; Train acc: 0.886719; Dev acc 0.722656\n",
      "Epoch 20; Step 540; Loss 0.518284; Train acc: 0.894531; Dev acc 0.738281\n",
      "Epoch 25; Step 675; Loss 0.534172; Train acc: 0.867188; Dev acc 0.718750\n",
      "Epoch 30; Step 810; Loss 0.546354; Train acc: 0.859375; Dev acc 0.753906\n",
      "Best dev accuracy is 0.75390625\n",
      "Best accuracy:  0.75390625\n",
      "157 / 576  =  (0.001, 200, 64, 5, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "158 / 576  =  (0.001, 200, 64, 5, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.599368; Train acc: 0.816406; Dev acc 0.714844\n",
      "Epoch 10; Step 270; Loss 0.592797; Train acc: 0.816406; Dev acc 0.714844\n",
      "Epoch 15; Step 405; Loss 0.540945; Train acc: 0.851562; Dev acc 0.707031\n",
      "Epoch 20; Step 540; Loss 0.574904; Train acc: 0.847656; Dev acc 0.746094\n",
      "Epoch 25; Step 675; Loss 0.550215; Train acc: 0.871094; Dev acc 0.730469\n",
      "Epoch 30; Step 810; Loss 0.554011; Train acc: 0.871094; Dev acc 0.753906\n",
      "Best dev accuracy is 0.75390625\n",
      "Best accuracy:  0.75390625\n",
      "159 / 576  =  (0.001, 200, 64, 5, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693148; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "160 / 576  =  (0.001, 200, 128, 2, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.507812; Dev acc 0.554688\n",
      "Epoch 5; Step 135; Loss 0.560610; Train acc: 0.851562; Dev acc 0.726562\n",
      "Epoch 10; Step 270; Loss 0.509842; Train acc: 0.886719; Dev acc 0.730469\n",
      "Epoch 15; Step 405; Loss 0.542639; Train acc: 0.871094; Dev acc 0.753906\n",
      "Epoch 20; Step 540; Loss 0.563336; Train acc: 0.890625; Dev acc 0.746094\n",
      "Epoch 25; Step 675; Loss 0.533033; Train acc: 0.929688; Dev acc 0.742188\n",
      "Epoch 30; Step 810; Loss 0.519932; Train acc: 0.921875; Dev acc 0.707031\n",
      "Best dev accuracy is 0.75390625\n",
      "Best accuracy:  0.75390625\n",
      "161 / 576  =  (0.001, 200, 128, 2, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693104; Train acc: 0.519531; Dev acc 0.535156\n",
      "Epoch 5; Step 135; Loss 0.445266; Train acc: 0.894531; Dev acc 0.726562\n",
      "Epoch 10; Step 270; Loss 0.406806; Train acc: 0.910156; Dev acc 0.742188\n",
      "Epoch 15; Step 405; Loss 0.410648; Train acc: 0.953125; Dev acc 0.699219\n",
      "Epoch 20; Step 540; Loss 0.387545; Train acc: 0.921875; Dev acc 0.742188\n",
      "Epoch 25; Step 675; Loss 0.361288; Train acc: 0.929688; Dev acc 0.734375\n",
      "Epoch 30; Step 810; Loss 0.393191; Train acc: 0.925781; Dev acc 0.710938\n",
      "Best dev accuracy is 0.7421875\n",
      "Best accuracy:  0.7421875\n",
      "162 / 576  =  (0.001, 200, 128, 2, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693157; Train acc: 0.503906; Dev acc 0.449219\n",
      "Epoch 5; Step 135; Loss 0.573849; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.549750; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.538514; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.528147; Train acc: 0.503906; Dev acc 0.453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25; Step 675; Loss 0.573714; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.555395; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "163 / 576  =  (0.001, 200, 128, 2, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693137; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.550953; Train acc: 0.828125; Dev acc 0.718750\n",
      "Epoch 10; Step 270; Loss 0.541932; Train acc: 0.890625; Dev acc 0.750000\n",
      "Epoch 15; Step 405; Loss 0.548044; Train acc: 0.910156; Dev acc 0.730469\n",
      "Epoch 20; Step 540; Loss 0.533375; Train acc: 0.910156; Dev acc 0.738281\n",
      "Epoch 25; Step 675; Loss 0.524231; Train acc: 0.941406; Dev acc 0.699219\n",
      "Epoch 30; Step 810; Loss 0.568483; Train acc: 0.921875; Dev acc 0.730469\n",
      "Best dev accuracy is 0.75\n",
      "Best accuracy:  0.75\n",
      "164 / 576  =  (0.001, 200, 128, 2, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693039; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "165 / 576  =  (0.001, 200, 128, 2, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693145; Train acc: 0.500000; Dev acc 0.585938\n",
      "Epoch 5; Step 135; Loss 0.435772; Train acc: 0.871094; Dev acc 0.753906\n",
      "Epoch 10; Step 270; Loss 0.398511; Train acc: 0.921875; Dev acc 0.734375\n",
      "Epoch 15; Step 405; Loss 0.393337; Train acc: 0.914062; Dev acc 0.742188\n",
      "Epoch 20; Step 540; Loss 0.379179; Train acc: 0.929688; Dev acc 0.742188\n",
      "Epoch 25; Step 675; Loss 0.370800; Train acc: 0.910156; Dev acc 0.722656\n",
      "Epoch 30; Step 810; Loss 0.389449; Train acc: 0.933594; Dev acc 0.718750\n",
      "Best dev accuracy is 0.75390625\n",
      "Best accuracy:  0.75390625\n",
      "166 / 576  =  (0.001, 200, 128, 2, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693199; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "167 / 576  =  (0.001, 200, 128, 2, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693116; Train acc: 0.496094; Dev acc 0.542969\n",
      "Epoch 5; Step 135; Loss 0.563074; Train acc: 0.863281; Dev acc 0.738281\n",
      "Epoch 10; Step 270; Loss 0.415994; Train acc: 0.855469; Dev acc 0.746094\n",
      "Epoch 15; Step 405; Loss 0.414823; Train acc: 0.890625; Dev acc 0.722656\n",
      "Epoch 20; Step 540; Loss 0.418364; Train acc: 0.898438; Dev acc 0.718750\n",
      "Epoch 25; Step 675; Loss 0.392211; Train acc: 0.894531; Dev acc 0.718750\n",
      "Epoch 30; Step 810; Loss 0.368054; Train acc: 0.914062; Dev acc 0.753906\n",
      "Best dev accuracy is 0.75390625\n",
      "Best accuracy:  0.75390625\n",
      "168 / 576  =  (0.001, 200, 128, 3, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693135; Train acc: 0.523438; Dev acc 0.531250\n",
      "Epoch 5; Step 135; Loss 0.563301; Train acc: 0.824219; Dev acc 0.773438\n",
      "Epoch 10; Step 270; Loss 0.542584; Train acc: 0.859375; Dev acc 0.722656\n",
      "Epoch 15; Step 405; Loss 0.542051; Train acc: 0.890625; Dev acc 0.734375\n",
      "Epoch 20; Step 540; Loss 0.561801; Train acc: 0.902344; Dev acc 0.730469\n",
      "Epoch 25; Step 675; Loss 0.550902; Train acc: 0.914062; Dev acc 0.707031\n",
      "Epoch 30; Step 810; Loss 0.507066; Train acc: 0.906250; Dev acc 0.753906\n",
      "Best dev accuracy is 0.7734375\n",
      "Best accuracy:  0.7734375\n",
      "169 / 576  =  (0.001, 200, 128, 3, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693134; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.567301; Train acc: 0.812500; Dev acc 0.757812\n",
      "Epoch 10; Step 270; Loss 0.557847; Train acc: 0.886719; Dev acc 0.714844\n",
      "Epoch 15; Step 405; Loss 0.561867; Train acc: 0.890625; Dev acc 0.722656\n",
      "Epoch 20; Step 540; Loss 0.550744; Train acc: 0.929688; Dev acc 0.714844\n",
      "Epoch 25; Step 675; Loss 0.518464; Train acc: 0.898438; Dev acc 0.683594\n",
      "Epoch 30; Step 810; Loss 0.554073; Train acc: 0.898438; Dev acc 0.703125\n",
      "Best dev accuracy is 0.7578125\n",
      "Best accuracy:  0.7578125\n",
      "170 / 576  =  (0.001, 200, 128, 3, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693169; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.416115; Train acc: 0.878906; Dev acc 0.761719\n",
      "Epoch 10; Step 270; Loss 0.396186; Train acc: 0.906250; Dev acc 0.750000\n",
      "Epoch 15; Step 405; Loss 0.375528; Train acc: 0.894531; Dev acc 0.699219\n",
      "Epoch 20; Step 540; Loss 0.361141; Train acc: 0.902344; Dev acc 0.750000\n",
      "Epoch 25; Step 675; Loss 0.381739; Train acc: 0.945312; Dev acc 0.718750\n",
      "Epoch 30; Step 810; Loss 0.388439; Train acc: 0.921875; Dev acc 0.730469\n",
      "Best dev accuracy is 0.76171875\n",
      "Best accuracy:  0.76171875\n",
      "171 / 576  =  (0.001, 200, 128, 3, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693171; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "172 / 576  =  (0.001, 200, 128, 3, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693148; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.489615; Train acc: 0.871094; Dev acc 0.695312\n",
      "Epoch 10; Step 270; Loss 0.413480; Train acc: 0.917969; Dev acc 0.730469\n",
      "Epoch 15; Step 405; Loss 0.374226; Train acc: 0.894531; Dev acc 0.718750\n",
      "Epoch 20; Step 540; Loss 0.388735; Train acc: 0.925781; Dev acc 0.738281\n",
      "Epoch 25; Step 675; Loss 0.375017; Train acc: 0.921875; Dev acc 0.757812\n",
      "Epoch 30; Step 810; Loss 0.364547; Train acc: 0.910156; Dev acc 0.710938\n",
      "Best dev accuracy is 0.7578125\n",
      "Best accuracy:  0.7578125\n",
      "173 / 576  =  (0.001, 200, 128, 3, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693148; Train acc: 0.390625; Dev acc 0.468750\n",
      "Epoch 5; Step 135; Loss 0.578817; Train acc: 0.804688; Dev acc 0.707031\n",
      "Epoch 10; Step 270; Loss 0.562557; Train acc: 0.863281; Dev acc 0.742188\n",
      "Epoch 15; Step 405; Loss 0.529837; Train acc: 0.859375; Dev acc 0.746094\n",
      "Epoch 20; Step 540; Loss 0.534174; Train acc: 0.871094; Dev acc 0.726562\n",
      "Epoch 25; Step 675; Loss 0.554603; Train acc: 0.867188; Dev acc 0.757812\n",
      "Epoch 30; Step 810; Loss 0.532115; Train acc: 0.890625; Dev acc 0.742188\n",
      "Best dev accuracy is 0.7578125\n",
      "Best accuracy:  0.7578125\n",
      "174 / 576  =  (0.001, 200, 128, 3, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693173; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "175 / 576  =  (0.001, 200, 128, 3, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693157; Train acc: 0.488281; Dev acc 0.550781\n",
      "Epoch 5; Step 135; Loss 0.444929; Train acc: 0.871094; Dev acc 0.742188\n",
      "Epoch 10; Step 270; Loss 0.394849; Train acc: 0.921875; Dev acc 0.703125\n",
      "Epoch 15; Step 405; Loss 0.405096; Train acc: 0.894531; Dev acc 0.730469\n",
      "Epoch 20; Step 540; Loss 0.379779; Train acc: 0.921875; Dev acc 0.738281\n",
      "Epoch 25; Step 675; Loss 0.388198; Train acc: 0.910156; Dev acc 0.746094\n",
      "Epoch 30; Step 810; Loss 0.390334; Train acc: 0.910156; Dev acc 0.726562\n",
      "Best dev accuracy is 0.74609375\n",
      "Best accuracy:  0.74609375\n",
      "176 / 576  =  (0.001, 200, 128, 4, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693157; Train acc: 0.496094; Dev acc 0.535156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5; Step 135; Loss 0.423543; Train acc: 0.871094; Dev acc 0.750000\n",
      "Epoch 10; Step 270; Loss 0.408875; Train acc: 0.878906; Dev acc 0.738281\n",
      "Epoch 15; Step 405; Loss 0.366811; Train acc: 0.898438; Dev acc 0.718750\n",
      "Epoch 20; Step 540; Loss 0.376635; Train acc: 0.929688; Dev acc 0.695312\n",
      "Epoch 25; Step 675; Loss 0.382887; Train acc: 0.925781; Dev acc 0.734375\n",
      "Epoch 30; Step 810; Loss 0.375623; Train acc: 0.921875; Dev acc 0.703125\n",
      "Best dev accuracy is 0.75\n",
      "Best accuracy:  0.75\n",
      "177 / 576  =  (0.001, 200, 128, 4, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.438320; Train acc: 0.855469; Dev acc 0.710938\n",
      "Epoch 10; Step 270; Loss 0.387626; Train acc: 0.875000; Dev acc 0.710938\n",
      "Epoch 15; Step 405; Loss 0.410676; Train acc: 0.929688; Dev acc 0.707031\n",
      "Epoch 20; Step 540; Loss 0.389913; Train acc: 0.929688; Dev acc 0.730469\n",
      "Epoch 25; Step 675; Loss 0.400345; Train acc: 0.925781; Dev acc 0.734375\n",
      "Epoch 30; Step 810; Loss 0.368083; Train acc: 0.949219; Dev acc 0.734375\n",
      "Best dev accuracy is 0.734375\n",
      "Best accuracy:  0.734375\n",
      "178 / 576  =  (0.001, 200, 128, 4, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.492188; Dev acc 0.558594\n",
      "Epoch 5; Step 135; Loss 0.445561; Train acc: 0.863281; Dev acc 0.746094\n",
      "Epoch 10; Step 270; Loss 0.393317; Train acc: 0.914062; Dev acc 0.750000\n",
      "Epoch 15; Step 405; Loss 0.371200; Train acc: 0.914062; Dev acc 0.753906\n",
      "Epoch 20; Step 540; Loss 0.362576; Train acc: 0.898438; Dev acc 0.718750\n",
      "Epoch 25; Step 675; Loss 0.372360; Train acc: 0.941406; Dev acc 0.718750\n",
      "Epoch 30; Step 810; Loss 0.363654; Train acc: 0.937500; Dev acc 0.675781\n",
      "Best dev accuracy is 0.75390625\n",
      "Best accuracy:  0.75390625\n",
      "179 / 576  =  (0.001, 200, 128, 4, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693156; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.588025; Train acc: 0.808594; Dev acc 0.734375\n",
      "Epoch 10; Step 270; Loss 0.545754; Train acc: 0.875000; Dev acc 0.726562\n",
      "Epoch 15; Step 405; Loss 0.553882; Train acc: 0.882812; Dev acc 0.730469\n",
      "Epoch 20; Step 540; Loss 0.534383; Train acc: 0.871094; Dev acc 0.703125\n",
      "Epoch 25; Step 675; Loss 0.548846; Train acc: 0.882812; Dev acc 0.707031\n",
      "Epoch 30; Step 810; Loss 0.523440; Train acc: 0.906250; Dev acc 0.742188\n",
      "Best dev accuracy is 0.7421875\n",
      "Best accuracy:  0.7421875\n",
      "180 / 576  =  (0.001, 200, 128, 4, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693144; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.468775; Train acc: 0.812500; Dev acc 0.722656\n",
      "Epoch 10; Step 270; Loss 0.411955; Train acc: 0.886719; Dev acc 0.769531\n",
      "Epoch 15; Step 405; Loss 0.399742; Train acc: 0.910156; Dev acc 0.714844\n",
      "Epoch 20; Step 540; Loss 0.390224; Train acc: 0.882812; Dev acc 0.722656\n",
      "Epoch 25; Step 675; Loss 0.391497; Train acc: 0.890625; Dev acc 0.707031\n",
      "Epoch 30; Step 810; Loss 0.367925; Train acc: 0.906250; Dev acc 0.753906\n",
      "Best dev accuracy is 0.76953125\n",
      "Best accuracy:  0.76953125\n",
      "181 / 576  =  (0.001, 200, 128, 4, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693145; Train acc: 0.488281; Dev acc 0.445312\n",
      "Epoch 5; Step 135; Loss 0.442745; Train acc: 0.859375; Dev acc 0.714844\n",
      "Epoch 10; Step 270; Loss 0.399991; Train acc: 0.878906; Dev acc 0.679688\n",
      "Epoch 15; Step 405; Loss 0.443773; Train acc: 0.925781; Dev acc 0.714844\n",
      "Epoch 20; Step 540; Loss 0.408570; Train acc: 0.925781; Dev acc 0.750000\n",
      "Epoch 25; Step 675; Loss 0.380924; Train acc: 0.894531; Dev acc 0.750000\n",
      "Epoch 30; Step 810; Loss 0.398323; Train acc: 0.906250; Dev acc 0.746094\n",
      "Best dev accuracy is 0.75\n",
      "Best accuracy:  0.75\n",
      "182 / 576  =  (0.001, 200, 128, 4, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693142; Train acc: 0.500000; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.454519; Train acc: 0.863281; Dev acc 0.800781\n",
      "Epoch 10; Step 270; Loss 0.401249; Train acc: 0.867188; Dev acc 0.718750\n",
      "Epoch 15; Step 405; Loss 0.428708; Train acc: 0.890625; Dev acc 0.714844\n",
      "Epoch 20; Step 540; Loss 0.393827; Train acc: 0.886719; Dev acc 0.773438\n",
      "Epoch 25; Step 675; Loss 0.380266; Train acc: 0.914062; Dev acc 0.699219\n",
      "Epoch 30; Step 810; Loss 0.406547; Train acc: 0.945312; Dev acc 0.742188\n",
      "Best dev accuracy is 0.80078125\n",
      "Best accuracy:  0.80078125\n",
      "183 / 576  =  (0.001, 200, 128, 4, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693150; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "184 / 576  =  (0.001, 200, 128, 5, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693149; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "185 / 576  =  (0.001, 200, 128, 5, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693152; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "186 / 576  =  (0.001, 200, 128, 5, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693151; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.565413; Train acc: 0.804688; Dev acc 0.703125\n",
      "Epoch 10; Step 270; Loss 0.572851; Train acc: 0.871094; Dev acc 0.726562\n",
      "Epoch 15; Step 405; Loss 0.556877; Train acc: 0.878906; Dev acc 0.742188\n",
      "Epoch 20; Step 540; Loss 0.525690; Train acc: 0.902344; Dev acc 0.703125\n",
      "Epoch 25; Step 675; Loss 0.522351; Train acc: 0.894531; Dev acc 0.722656\n",
      "Epoch 30; Step 810; Loss 0.535826; Train acc: 0.906250; Dev acc 0.738281\n",
      "Best dev accuracy is 0.7421875\n",
      "Best accuracy:  0.7421875\n",
      "187 / 576  =  (0.001, 200, 128, 5, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.564203; Train acc: 0.824219; Dev acc 0.753906\n",
      "Epoch 10; Step 270; Loss 0.573388; Train acc: 0.820312; Dev acc 0.718750\n",
      "Epoch 15; Step 405; Loss 0.538578; Train acc: 0.878906; Dev acc 0.753906\n",
      "Epoch 20; Step 540; Loss 0.531357; Train acc: 0.875000; Dev acc 0.730469\n",
      "Epoch 25; Step 675; Loss 0.520334; Train acc: 0.898438; Dev acc 0.726562\n",
      "Epoch 30; Step 810; Loss 0.414247; Train acc: 0.890625; Dev acc 0.753906\n",
      "Best dev accuracy is 0.75390625\n",
      "Best accuracy:  0.75390625\n",
      "188 / 576  =  (0.001, 200, 128, 5, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "189 / 576  =  (0.001, 200, 128, 5, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693132; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "190 / 576  =  (0.001, 200, 128, 5, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693152; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.562413; Train acc: 0.808594; Dev acc 0.773438\n",
      "Epoch 10; Step 270; Loss 0.594115; Train acc: 0.832031; Dev acc 0.722656\n",
      "Epoch 15; Step 405; Loss 0.547715; Train acc: 0.835938; Dev acc 0.722656\n",
      "Epoch 20; Step 540; Loss 0.540663; Train acc: 0.882812; Dev acc 0.777344\n",
      "Epoch 25; Step 675; Loss 0.544735; Train acc: 0.871094; Dev acc 0.765625\n",
      "Epoch 30; Step 810; Loss 0.549445; Train acc: 0.875000; Dev acc 0.765625\n",
      "Best dev accuracy is 0.77734375\n",
      "Best accuracy:  0.77734375\n",
      "191 / 576  =  (0.001, 200, 128, 5, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693145; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.577209; Train acc: 0.812500; Dev acc 0.765625\n",
      "Epoch 10; Step 270; Loss 0.550714; Train acc: 0.816406; Dev acc 0.750000\n",
      "Epoch 15; Step 405; Loss 0.543069; Train acc: 0.851562; Dev acc 0.730469\n",
      "Epoch 20; Step 540; Loss 0.576316; Train acc: 0.878906; Dev acc 0.753906\n",
      "Epoch 25; Step 675; Loss 0.563067; Train acc: 0.882812; Dev acc 0.742188\n",
      "Epoch 30; Step 810; Loss 0.547274; Train acc: 0.843750; Dev acc 0.718750\n",
      "Best dev accuracy is 0.765625\n",
      "Best accuracy:  0.765625\n",
      "192 / 576  =  (0.0001, 10, 64, 2, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693141; Train acc: 0.503906; Dev acc 0.507812\n",
      "Epoch 5; Step 135; Loss 0.692091; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.691037; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.682579; Train acc: 0.589844; Dev acc 0.609375\n",
      "Epoch 20; Step 540; Loss 0.657141; Train acc: 0.699219; Dev acc 0.660156\n",
      "Epoch 25; Step 675; Loss 0.623174; Train acc: 0.730469; Dev acc 0.710938\n",
      "Epoch 30; Step 810; Loss 0.578858; Train acc: 0.792969; Dev acc 0.699219\n",
      "Best dev accuracy is 0.7109375\n",
      "Best accuracy:  0.7109375\n",
      "193 / 576  =  (0.0001, 10, 64, 2, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693149; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.692587; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.690540; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.690066; Train acc: 0.554688; Dev acc 0.582031\n",
      "Epoch 20; Step 540; Loss 0.655761; Train acc: 0.640625; Dev acc 0.613281\n",
      "Epoch 25; Step 675; Loss 0.612459; Train acc: 0.734375; Dev acc 0.644531\n",
      "Epoch 30; Step 810; Loss 0.576473; Train acc: 0.757812; Dev acc 0.687500\n",
      "Best dev accuracy is 0.6875\n",
      "Best accuracy:  0.6875\n",
      "194 / 576  =  (0.0001, 10, 64, 2, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.503906; Dev acc 0.531250\n",
      "Epoch 5; Step 135; Loss 0.692919; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.692434; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.686540; Train acc: 0.511719; Dev acc 0.558594\n",
      "Epoch 20; Step 540; Loss 0.674778; Train acc: 0.546875; Dev acc 0.589844\n",
      "Epoch 25; Step 675; Loss 0.640614; Train acc: 0.636719; Dev acc 0.621094\n",
      "Epoch 30; Step 810; Loss 0.603572; Train acc: 0.703125; Dev acc 0.675781\n",
      "Best dev accuracy is 0.67578125\n",
      "Best accuracy:  0.67578125\n",
      "195 / 576  =  (0.0001, 10, 64, 2, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.511719; Dev acc 0.464844\n",
      "Epoch 5; Step 135; Loss 0.692759; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.690247; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.687677; Train acc: 0.503906; Dev acc 0.554688\n",
      "Epoch 20; Step 540; Loss 0.677448; Train acc: 0.574219; Dev acc 0.566406\n",
      "Epoch 25; Step 675; Loss 0.657970; Train acc: 0.585938; Dev acc 0.628906\n",
      "Epoch 30; Step 810; Loss 0.624935; Train acc: 0.644531; Dev acc 0.632812\n",
      "Best dev accuracy is 0.6328125\n",
      "Best accuracy:  0.6328125\n",
      "196 / 576  =  (0.0001, 10, 64, 2, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693141; Train acc: 0.496094; Dev acc 0.550781\n",
      "Epoch 5; Step 135; Loss 0.692495; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.690044; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.689358; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.671236; Train acc: 0.570312; Dev acc 0.621094\n",
      "Epoch 25; Step 675; Loss 0.639664; Train acc: 0.691406; Dev acc 0.699219\n",
      "Epoch 30; Step 810; Loss 0.608174; Train acc: 0.765625; Dev acc 0.734375\n",
      "Best dev accuracy is 0.734375\n",
      "Best accuracy:  0.734375\n",
      "197 / 576  =  (0.0001, 10, 64, 2, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693140; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.692679; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.690684; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.689120; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.677640; Train acc: 0.515625; Dev acc 0.566406\n",
      "Epoch 25; Step 675; Loss 0.660005; Train acc: 0.570312; Dev acc 0.601562\n",
      "Epoch 30; Step 810; Loss 0.633262; Train acc: 0.609375; Dev acc 0.617188\n",
      "Best dev accuracy is 0.6171875\n",
      "Best accuracy:  0.6171875\n",
      "198 / 576  =  (0.0001, 10, 64, 2, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693145; Train acc: 0.488281; Dev acc 0.574219\n",
      "Epoch 5; Step 135; Loss 0.693147; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.691204; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.691333; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.674475; Train acc: 0.535156; Dev acc 0.558594\n",
      "Epoch 25; Step 675; Loss 0.664631; Train acc: 0.582031; Dev acc 0.582031\n",
      "Epoch 30; Step 810; Loss 0.634508; Train acc: 0.664062; Dev acc 0.636719\n",
      "Best dev accuracy is 0.63671875\n",
      "Best accuracy:  0.63671875\n",
      "199 / 576  =  (0.0001, 10, 64, 2, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693121; Train acc: 0.488281; Dev acc 0.539062\n",
      "Epoch 5; Step 135; Loss 0.692877; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.692532; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.692758; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.675270; Train acc: 0.523438; Dev acc 0.578125\n",
      "Epoch 25; Step 675; Loss 0.642934; Train acc: 0.566406; Dev acc 0.585938\n",
      "Epoch 30; Step 810; Loss 0.636507; Train acc: 0.648438; Dev acc 0.628906\n",
      "Best dev accuracy is 0.62890625\n",
      "Best accuracy:  0.62890625\n",
      "200 / 576  =  (0.0001, 10, 64, 3, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "201 / 576  =  (0.0001, 10, 64, 3, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.500000; Dev acc 0.445312\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "202 / 576  =  (0.0001, 10, 64, 3, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.496094; Dev acc 0.457031\n",
      "Epoch 5; Step 135; Loss 0.693743; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.691086; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.667376; Train acc: 0.597656; Dev acc 0.589844\n",
      "Epoch 20; Step 540; Loss 0.612872; Train acc: 0.707031; Dev acc 0.699219\n",
      "Epoch 25; Step 675; Loss 0.524138; Train acc: 0.781250; Dev acc 0.699219\n",
      "Epoch 30; Step 810; Loss 0.460117; Train acc: 0.816406; Dev acc 0.753906\n",
      "Best dev accuracy is 0.75390625\n",
      "Best accuracy:  0.75390625\n",
      "203 / 576  =  (0.0001, 10, 64, 3, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.503906; Dev acc 0.453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "204 / 576  =  (0.0001, 10, 64, 3, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693155; Train acc: 0.484375; Dev acc 0.472656\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.47265625\n",
      "Best accuracy:  0.47265625\n",
      "205 / 576  =  (0.0001, 10, 64, 3, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "206 / 576  =  (0.0001, 10, 64, 3, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693148; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "207 / 576  =  (0.0001, 10, 64, 3, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693150; Train acc: 0.484375; Dev acc 0.554688\n",
      "Epoch 5; Step 135; Loss 0.692984; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.694134; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.689821; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.647284; Train acc: 0.625000; Dev acc 0.648438\n",
      "Epoch 25; Step 675; Loss 0.593555; Train acc: 0.726562; Dev acc 0.718750\n",
      "Epoch 30; Step 810; Loss 0.512647; Train acc: 0.824219; Dev acc 0.761719\n",
      "Best dev accuracy is 0.76171875\n",
      "Best accuracy:  0.76171875\n",
      "208 / 576  =  (0.0001, 10, 64, 4, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "209 / 576  =  (0.0001, 10, 64, 4, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.692164; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.689847; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.669553; Train acc: 0.546875; Dev acc 0.597656\n",
      "Epoch 20; Step 540; Loss 0.623479; Train acc: 0.636719; Dev acc 0.648438\n",
      "Epoch 25; Step 675; Loss 0.585510; Train acc: 0.800781; Dev acc 0.660156\n",
      "Epoch 30; Step 810; Loss 0.574884; Train acc: 0.792969; Dev acc 0.730469\n",
      "Best dev accuracy is 0.73046875\n",
      "Best accuracy:  0.73046875\n",
      "210 / 576  =  (0.0001, 10, 64, 4, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.693237; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.691707; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.658291; Train acc: 0.562500; Dev acc 0.601562\n",
      "Epoch 20; Step 540; Loss 0.593697; Train acc: 0.718750; Dev acc 0.675781\n",
      "Epoch 25; Step 675; Loss 0.531592; Train acc: 0.781250; Dev acc 0.714844\n",
      "Epoch 30; Step 810; Loss 0.503832; Train acc: 0.812500; Dev acc 0.722656\n",
      "Best dev accuracy is 0.72265625\n",
      "Best accuracy:  0.72265625\n",
      "211 / 576  =  (0.0001, 10, 64, 4, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.693251; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.690589; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.674584; Train acc: 0.578125; Dev acc 0.640625\n",
      "Epoch 20; Step 540; Loss 0.589936; Train acc: 0.718750; Dev acc 0.714844\n",
      "Epoch 25; Step 675; Loss 0.535121; Train acc: 0.765625; Dev acc 0.757812\n",
      "Epoch 30; Step 810; Loss 0.470400; Train acc: 0.828125; Dev acc 0.710938\n",
      "Best dev accuracy is 0.7578125\n",
      "Best accuracy:  0.7578125\n",
      "212 / 576  =  (0.0001, 10, 64, 4, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.500000; Dev acc 0.457031\n",
      "Epoch 5; Step 135; Loss 0.692688; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.692434; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.689157; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.644601; Train acc: 0.628906; Dev acc 0.605469\n",
      "Epoch 25; Step 675; Loss 0.580029; Train acc: 0.742188; Dev acc 0.714844\n",
      "Epoch 30; Step 810; Loss 0.497372; Train acc: 0.824219; Dev acc 0.757812\n",
      "Best dev accuracy is 0.7578125\n",
      "Best accuracy:  0.7578125\n",
      "213 / 576  =  (0.0001, 10, 64, 4, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "214 / 576  =  (0.0001, 10, 64, 4, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.693453; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.692746; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.687658; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.629588; Train acc: 0.601562; Dev acc 0.648438\n",
      "Epoch 25; Step 675; Loss 0.589834; Train acc: 0.769531; Dev acc 0.699219\n",
      "Epoch 30; Step 810; Loss 0.588785; Train acc: 0.789062; Dev acc 0.738281\n",
      "Best dev accuracy is 0.73828125\n",
      "Best accuracy:  0.73828125\n",
      "215 / 576  =  (0.0001, 10, 64, 4, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.693175; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.691812; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.692636; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.649731; Train acc: 0.613281; Dev acc 0.621094\n",
      "Epoch 25; Step 675; Loss 0.592188; Train acc: 0.726562; Dev acc 0.714844\n",
      "Epoch 30; Step 810; Loss 0.566096; Train acc: 0.800781; Dev acc 0.753906\n",
      "Best dev accuracy is 0.75390625\n",
      "Best accuracy:  0.75390625\n",
      "216 / 576  =  (0.0001, 10, 64, 5, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.692419; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.691586; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.685357; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.610431; Train acc: 0.679688; Dev acc 0.652344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25; Step 675; Loss 0.523137; Train acc: 0.750000; Dev acc 0.746094\n",
      "Epoch 30; Step 810; Loss 0.482149; Train acc: 0.800781; Dev acc 0.722656\n",
      "Best dev accuracy is 0.74609375\n",
      "Best accuracy:  0.74609375\n",
      "217 / 576  =  (0.0001, 10, 64, 5, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.693502; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.687573; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.660601; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.611091; Train acc: 0.726562; Dev acc 0.695312\n",
      "Epoch 25; Step 675; Loss 0.531883; Train acc: 0.789062; Dev acc 0.730469\n",
      "Epoch 30; Step 810; Loss 0.494630; Train acc: 0.812500; Dev acc 0.761719\n",
      "Best dev accuracy is 0.76171875\n",
      "Best accuracy:  0.76171875\n",
      "218 / 576  =  (0.0001, 10, 64, 5, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "219 / 576  =  (0.0001, 10, 64, 5, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "220 / 576  =  (0.0001, 10, 64, 5, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "221 / 576  =  (0.0001, 10, 64, 5, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "222 / 576  =  (0.0001, 10, 64, 5, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693148; Train acc: 0.500000; Dev acc 0.531250\n",
      "Epoch 5; Step 135; Loss 0.693531; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.689424; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.694394; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693014; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.634401; Train acc: 0.687500; Dev acc 0.671875\n",
      "Epoch 30; Step 810; Loss 0.567956; Train acc: 0.820312; Dev acc 0.703125\n",
      "Best dev accuracy is 0.703125\n",
      "Best accuracy:  0.703125\n",
      "223 / 576  =  (0.0001, 10, 64, 5, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.692508; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.690825; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.689348; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.678015; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.621038; Train acc: 0.742188; Dev acc 0.675781\n",
      "Epoch 30; Step 810; Loss 0.530294; Train acc: 0.800781; Dev acc 0.789062\n",
      "Best dev accuracy is 0.7890625\n",
      "Best accuracy:  0.7890625\n",
      "224 / 576  =  (0.0001, 10, 128, 2, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693138; Train acc: 0.484375; Dev acc 0.531250\n",
      "Epoch 5; Step 135; Loss 0.691410; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.690646; Train acc: 0.515625; Dev acc 0.566406\n",
      "Epoch 15; Step 405; Loss 0.657948; Train acc: 0.613281; Dev acc 0.644531\n",
      "Epoch 20; Step 540; Loss 0.614963; Train acc: 0.667969; Dev acc 0.703125\n",
      "Epoch 25; Step 675; Loss 0.543905; Train acc: 0.753906; Dev acc 0.691406\n",
      "Epoch 30; Step 810; Loss 0.509284; Train acc: 0.816406; Dev acc 0.734375\n",
      "Best dev accuracy is 0.734375\n",
      "Best accuracy:  0.734375\n",
      "225 / 576  =  (0.0001, 10, 128, 2, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693140; Train acc: 0.492188; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.692514; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.692477; Train acc: 0.500000; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.665469; Train acc: 0.617188; Dev acc 0.671875\n",
      "Epoch 20; Step 540; Loss 0.610579; Train acc: 0.683594; Dev acc 0.652344\n",
      "Epoch 25; Step 675; Loss 0.555637; Train acc: 0.765625; Dev acc 0.722656\n",
      "Epoch 30; Step 810; Loss 0.502526; Train acc: 0.824219; Dev acc 0.722656\n",
      "Best dev accuracy is 0.72265625\n",
      "Best accuracy:  0.72265625\n",
      "226 / 576  =  (0.0001, 10, 128, 2, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693151; Train acc: 0.523438; Dev acc 0.488281\n",
      "Epoch 5; Step 135; Loss 0.692022; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.689007; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.675385; Train acc: 0.542969; Dev acc 0.566406\n",
      "Epoch 20; Step 540; Loss 0.655065; Train acc: 0.593750; Dev acc 0.609375\n",
      "Epoch 25; Step 675; Loss 0.609231; Train acc: 0.632812; Dev acc 0.640625\n",
      "Epoch 30; Step 810; Loss 0.590961; Train acc: 0.691406; Dev acc 0.734375\n",
      "Best dev accuracy is 0.734375\n",
      "Best accuracy:  0.734375\n",
      "227 / 576  =  (0.0001, 10, 128, 2, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.503906; Dev acc 0.527344\n",
      "Epoch 5; Step 135; Loss 0.692761; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.689540; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.654680; Train acc: 0.601562; Dev acc 0.632812\n",
      "Epoch 20; Step 540; Loss 0.598106; Train acc: 0.722656; Dev acc 0.660156\n",
      "Epoch 25; Step 675; Loss 0.531394; Train acc: 0.765625; Dev acc 0.765625\n",
      "Epoch 30; Step 810; Loss 0.482910; Train acc: 0.800781; Dev acc 0.773438\n",
      "Best dev accuracy is 0.7734375\n",
      "Best accuracy:  0.7734375\n",
      "228 / 576  =  (0.0001, 10, 128, 2, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693156; Train acc: 0.507812; Dev acc 0.457031\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.45703125\n",
      "Best accuracy:  0.45703125\n",
      "229 / 576  =  (0.0001, 10, 128, 2, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693155; Train acc: 0.484375; Dev acc 0.488281\n",
      "Epoch 5; Step 135; Loss 0.693815; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.687237; Train acc: 0.507812; Dev acc 0.578125\n",
      "Epoch 15; Step 405; Loss 0.654626; Train acc: 0.640625; Dev acc 0.675781\n",
      "Epoch 20; Step 540; Loss 0.600152; Train acc: 0.781250; Dev acc 0.679688\n",
      "Epoch 25; Step 675; Loss 0.540048; Train acc: 0.800781; Dev acc 0.761719\n",
      "Epoch 30; Step 810; Loss 0.498694; Train acc: 0.816406; Dev acc 0.738281\n",
      "Best dev accuracy is 0.76171875\n",
      "Best accuracy:  0.76171875\n",
      "230 / 576  =  (0.0001, 10, 128, 2, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693151; Train acc: 0.460938; Dev acc 0.558594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5; Step 135; Loss 0.693155; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.689574; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.674706; Train acc: 0.609375; Dev acc 0.593750\n",
      "Epoch 20; Step 540; Loss 0.631594; Train acc: 0.667969; Dev acc 0.660156\n",
      "Epoch 25; Step 675; Loss 0.560524; Train acc: 0.730469; Dev acc 0.718750\n",
      "Epoch 30; Step 810; Loss 0.498904; Train acc: 0.800781; Dev acc 0.789062\n",
      "Best dev accuracy is 0.7890625\n",
      "Best accuracy:  0.7890625\n",
      "231 / 576  =  (0.0001, 10, 128, 2, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693139; Train acc: 0.480469; Dev acc 0.542969\n",
      "Epoch 5; Step 135; Loss 0.692380; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.690818; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.664748; Train acc: 0.542969; Dev acc 0.628906\n",
      "Epoch 20; Step 540; Loss 0.614425; Train acc: 0.667969; Dev acc 0.742188\n",
      "Epoch 25; Step 675; Loss 0.546993; Train acc: 0.746094; Dev acc 0.742188\n",
      "Epoch 30; Step 810; Loss 0.506474; Train acc: 0.808594; Dev acc 0.761719\n",
      "Best dev accuracy is 0.76171875\n",
      "Best accuracy:  0.76171875\n",
      "232 / 576  =  (0.0001, 10, 128, 3, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.519531; Dev acc 0.500000\n",
      "Epoch 5; Step 135; Loss 0.690822; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.680994; Train acc: 0.531250; Dev acc 0.554688\n",
      "Epoch 15; Step 405; Loss 0.620805; Train acc: 0.632812; Dev acc 0.664062\n",
      "Epoch 20; Step 540; Loss 0.595138; Train acc: 0.707031; Dev acc 0.738281\n",
      "Epoch 25; Step 675; Loss 0.570472; Train acc: 0.750000; Dev acc 0.734375\n",
      "Epoch 30; Step 810; Loss 0.561229; Train acc: 0.750000; Dev acc 0.718750\n",
      "Best dev accuracy is 0.73828125\n",
      "Best accuracy:  0.73828125\n",
      "233 / 576  =  (0.0001, 10, 128, 3, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693167; Train acc: 0.500000; Dev acc 0.468750\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.46875\n",
      "Best accuracy:  0.46875\n",
      "234 / 576  =  (0.0001, 10, 128, 3, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.500000; Dev acc 0.496094\n",
      "Epoch 5; Step 135; Loss 0.693437; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.680918; Train acc: 0.546875; Dev acc 0.562500\n",
      "Epoch 15; Step 405; Loss 0.622897; Train acc: 0.699219; Dev acc 0.621094\n",
      "Epoch 20; Step 540; Loss 0.535867; Train acc: 0.750000; Dev acc 0.683594\n",
      "Epoch 25; Step 675; Loss 0.470361; Train acc: 0.832031; Dev acc 0.691406\n",
      "Epoch 30; Step 810; Loss 0.490520; Train acc: 0.847656; Dev acc 0.722656\n",
      "Best dev accuracy is 0.72265625\n",
      "Best accuracy:  0.72265625\n",
      "235 / 576  =  (0.0001, 10, 128, 3, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693148; Train acc: 0.480469; Dev acc 0.449219\n",
      "Epoch 5; Step 135; Loss 0.690905; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.677048; Train acc: 0.601562; Dev acc 0.601562\n",
      "Epoch 15; Step 405; Loss 0.600982; Train acc: 0.742188; Dev acc 0.683594\n",
      "Epoch 20; Step 540; Loss 0.522465; Train acc: 0.777344; Dev acc 0.718750\n",
      "Epoch 25; Step 675; Loss 0.466464; Train acc: 0.800781; Dev acc 0.761719\n",
      "Epoch 30; Step 810; Loss 0.466767; Train acc: 0.824219; Dev acc 0.761719\n",
      "Best dev accuracy is 0.76171875\n",
      "Best accuracy:  0.76171875\n",
      "236 / 576  =  (0.0001, 10, 128, 3, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.503906; Dev acc 0.468750\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.46875\n",
      "Best accuracy:  0.46875\n",
      "237 / 576  =  (0.0001, 10, 128, 3, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.484375; Dev acc 0.542969\n",
      "Epoch 5; Step 135; Loss 0.692829; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.685156; Train acc: 0.496094; Dev acc 0.550781\n",
      "Epoch 15; Step 405; Loss 0.630540; Train acc: 0.667969; Dev acc 0.664062\n",
      "Epoch 20; Step 540; Loss 0.540054; Train acc: 0.781250; Dev acc 0.734375\n",
      "Epoch 25; Step 675; Loss 0.485697; Train acc: 0.765625; Dev acc 0.699219\n",
      "Epoch 30; Step 810; Loss 0.455988; Train acc: 0.851562; Dev acc 0.789062\n",
      "Best dev accuracy is 0.7890625\n",
      "Best accuracy:  0.7890625\n",
      "238 / 576  =  (0.0001, 10, 128, 3, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693152; Train acc: 0.496094; Dev acc 0.562500\n",
      "Epoch 5; Step 135; Loss 0.693643; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.687329; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.644254; Train acc: 0.597656; Dev acc 0.613281\n",
      "Epoch 20; Step 540; Loss 0.547594; Train acc: 0.734375; Dev acc 0.730469\n",
      "Epoch 25; Step 675; Loss 0.499838; Train acc: 0.816406; Dev acc 0.746094\n",
      "Epoch 30; Step 810; Loss 0.474711; Train acc: 0.843750; Dev acc 0.734375\n",
      "Best dev accuracy is 0.74609375\n",
      "Best accuracy:  0.74609375\n",
      "239 / 576  =  (0.0001, 10, 128, 3, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693150; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "240 / 576  =  (0.0001, 10, 128, 4, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "241 / 576  =  (0.0001, 10, 128, 4, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.484375; Dev acc 0.484375\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.484375\n",
      "Best accuracy:  0.484375\n",
      "242 / 576  =  (0.0001, 10, 128, 4, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.691713; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.666536; Train acc: 0.570312; Dev acc 0.585938\n",
      "Epoch 15; Step 405; Loss 0.625499; Train acc: 0.664062; Dev acc 0.660156\n",
      "Epoch 20; Step 540; Loss 0.594790; Train acc: 0.722656; Dev acc 0.707031\n",
      "Epoch 25; Step 675; Loss 0.592541; Train acc: 0.792969; Dev acc 0.699219\n",
      "Epoch 30; Step 810; Loss 0.556506; Train acc: 0.816406; Dev acc 0.738281\n",
      "Best dev accuracy is 0.73828125\n",
      "Best accuracy:  0.73828125\n",
      "243 / 576  =  (0.0001, 10, 128, 4, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.460938; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.690897; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.674734; Train acc: 0.542969; Dev acc 0.550781\n",
      "Epoch 15; Step 405; Loss 0.623515; Train acc: 0.714844; Dev acc 0.683594\n",
      "Epoch 20; Step 540; Loss 0.614594; Train acc: 0.742188; Dev acc 0.667969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25; Step 675; Loss 0.563358; Train acc: 0.792969; Dev acc 0.714844\n",
      "Epoch 30; Step 810; Loss 0.562932; Train acc: 0.773438; Dev acc 0.695312\n",
      "Best dev accuracy is 0.71484375\n",
      "Best accuracy:  0.71484375\n",
      "244 / 576  =  (0.0001, 10, 128, 4, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "245 / 576  =  (0.0001, 10, 128, 4, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.496094; Dev acc 0.550781\n",
      "Epoch 5; Step 135; Loss 0.690828; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.685172; Train acc: 0.496094; Dev acc 0.550781\n",
      "Epoch 15; Step 405; Loss 0.611489; Train acc: 0.652344; Dev acc 0.664062\n",
      "Epoch 20; Step 540; Loss 0.549754; Train acc: 0.703125; Dev acc 0.742188\n",
      "Epoch 25; Step 675; Loss 0.493822; Train acc: 0.812500; Dev acc 0.753906\n",
      "Epoch 30; Step 810; Loss 0.477893; Train acc: 0.824219; Dev acc 0.710938\n",
      "Best dev accuracy is 0.75390625\n",
      "Best accuracy:  0.75390625\n",
      "246 / 576  =  (0.0001, 10, 128, 4, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693138; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.690817; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.670477; Train acc: 0.535156; Dev acc 0.570312\n",
      "Epoch 15; Step 405; Loss 0.598927; Train acc: 0.640625; Dev acc 0.667969\n",
      "Epoch 20; Step 540; Loss 0.523398; Train acc: 0.789062; Dev acc 0.710938\n",
      "Epoch 25; Step 675; Loss 0.489914; Train acc: 0.824219; Dev acc 0.710938\n",
      "Epoch 30; Step 810; Loss 0.441160; Train acc: 0.851562; Dev acc 0.718750\n",
      "Best dev accuracy is 0.71875\n",
      "Best accuracy:  0.71875\n",
      "247 / 576  =  (0.0001, 10, 128, 4, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693148; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "248 / 576  =  (0.0001, 10, 128, 5, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.480469; Dev acc 0.542969\n",
      "Epoch 5; Step 135; Loss 0.689503; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.681231; Train acc: 0.539062; Dev acc 0.593750\n",
      "Epoch 15; Step 405; Loss 0.614589; Train acc: 0.687500; Dev acc 0.703125\n",
      "Epoch 20; Step 540; Loss 0.582455; Train acc: 0.750000; Dev acc 0.710938\n",
      "Epoch 25; Step 675; Loss 0.586072; Train acc: 0.781250; Dev acc 0.714844\n",
      "Epoch 30; Step 810; Loss 0.557815; Train acc: 0.804688; Dev acc 0.738281\n",
      "Best dev accuracy is 0.73828125\n",
      "Best accuracy:  0.73828125\n",
      "249 / 576  =  (0.0001, 10, 128, 5, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "250 / 576  =  (0.0001, 10, 128, 5, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.690208; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.686812; Train acc: 0.574219; Dev acc 0.574219\n",
      "Epoch 15; Step 405; Loss 0.619973; Train acc: 0.617188; Dev acc 0.640625\n",
      "Epoch 20; Step 540; Loss 0.630315; Train acc: 0.683594; Dev acc 0.660156\n",
      "Epoch 25; Step 675; Loss 0.580253; Train acc: 0.699219; Dev acc 0.644531\n",
      "Epoch 30; Step 810; Loss 0.556814; Train acc: 0.746094; Dev acc 0.738281\n",
      "Best dev accuracy is 0.73828125\n",
      "Best accuracy:  0.73828125\n",
      "251 / 576  =  (0.0001, 10, 128, 5, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "252 / 576  =  (0.0001, 10, 128, 5, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693728; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.690844; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.621138; Train acc: 0.632812; Dev acc 0.660156\n",
      "Epoch 20; Step 540; Loss 0.532087; Train acc: 0.761719; Dev acc 0.738281\n",
      "Epoch 25; Step 675; Loss 0.456389; Train acc: 0.820312; Dev acc 0.730469\n",
      "Epoch 30; Step 810; Loss 0.460541; Train acc: 0.875000; Dev acc 0.722656\n",
      "Best dev accuracy is 0.73828125\n",
      "Best accuracy:  0.73828125\n",
      "253 / 576  =  (0.0001, 10, 128, 5, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.692383; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693483; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.609254; Train acc: 0.707031; Dev acc 0.660156\n",
      "Epoch 20; Step 540; Loss 0.621649; Train acc: 0.804688; Dev acc 0.730469\n",
      "Epoch 25; Step 675; Loss 0.592519; Train acc: 0.828125; Dev acc 0.730469\n",
      "Epoch 30; Step 810; Loss 0.575682; Train acc: 0.812500; Dev acc 0.761719\n",
      "Best dev accuracy is 0.76171875\n",
      "Best accuracy:  0.76171875\n",
      "254 / 576  =  (0.0001, 10, 128, 5, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.690835; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.688954; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.580503; Train acc: 0.699219; Dev acc 0.687500\n",
      "Epoch 20; Step 540; Loss 0.609817; Train acc: 0.781250; Dev acc 0.707031\n",
      "Epoch 25; Step 675; Loss 0.592042; Train acc: 0.800781; Dev acc 0.730469\n",
      "Epoch 30; Step 810; Loss 0.570885; Train acc: 0.800781; Dev acc 0.710938\n",
      "Best dev accuracy is 0.73046875\n",
      "Best accuracy:  0.73046875\n",
      "255 / 576  =  (0.0001, 10, 128, 5, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693149; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "256 / 576  =  (0.0001, 50, 64, 2, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693115; Train acc: 0.503906; Dev acc 0.554688\n",
      "Epoch 5; Step 135; Loss 0.692254; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.686779; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.660674; Train acc: 0.648438; Dev acc 0.613281\n",
      "Epoch 20; Step 540; Loss 0.579247; Train acc: 0.714844; Dev acc 0.699219\n",
      "Epoch 25; Step 675; Loss 0.516789; Train acc: 0.812500; Dev acc 0.753906\n",
      "Epoch 30; Step 810; Loss 0.459391; Train acc: 0.828125; Dev acc 0.738281\n",
      "Best dev accuracy is 0.75390625\n",
      "Best accuracy:  0.75390625\n",
      "257 / 576  =  (0.0001, 50, 64, 2, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693140; Train acc: 0.476562; Dev acc 0.511719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5; Step 135; Loss 0.693587; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.689788; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.666931; Train acc: 0.589844; Dev acc 0.605469\n",
      "Epoch 20; Step 540; Loss 0.616309; Train acc: 0.738281; Dev acc 0.679688\n",
      "Epoch 25; Step 675; Loss 0.525817; Train acc: 0.808594; Dev acc 0.761719\n",
      "Epoch 30; Step 810; Loss 0.498935; Train acc: 0.851562; Dev acc 0.742188\n",
      "Best dev accuracy is 0.76171875\n",
      "Best accuracy:  0.76171875\n",
      "258 / 576  =  (0.0001, 50, 64, 2, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693139; Train acc: 0.484375; Dev acc 0.550781\n",
      "Epoch 5; Step 135; Loss 0.692815; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.691913; Train acc: 0.515625; Dev acc 0.558594\n",
      "Epoch 15; Step 405; Loss 0.662960; Train acc: 0.628906; Dev acc 0.601562\n",
      "Epoch 20; Step 540; Loss 0.604707; Train acc: 0.710938; Dev acc 0.699219\n",
      "Epoch 25; Step 675; Loss 0.541367; Train acc: 0.835938; Dev acc 0.750000\n",
      "Epoch 30; Step 810; Loss 0.476165; Train acc: 0.847656; Dev acc 0.730469\n",
      "Best dev accuracy is 0.75\n",
      "Best accuracy:  0.75\n",
      "259 / 576  =  (0.0001, 50, 64, 2, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693149; Train acc: 0.480469; Dev acc 0.496094\n",
      "Epoch 5; Step 135; Loss 0.692995; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.688329; Train acc: 0.503906; Dev acc 0.550781\n",
      "Epoch 15; Step 405; Loss 0.664037; Train acc: 0.625000; Dev acc 0.644531\n",
      "Epoch 20; Step 540; Loss 0.607050; Train acc: 0.750000; Dev acc 0.703125\n",
      "Epoch 25; Step 675; Loss 0.533341; Train acc: 0.855469; Dev acc 0.726562\n",
      "Epoch 30; Step 810; Loss 0.469230; Train acc: 0.855469; Dev acc 0.746094\n",
      "Best dev accuracy is 0.74609375\n",
      "Best accuracy:  0.74609375\n",
      "260 / 576  =  (0.0001, 50, 64, 2, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693159; Train acc: 0.523438; Dev acc 0.519531\n",
      "Epoch 5; Step 135; Loss 0.693115; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.691673; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.674307; Train acc: 0.605469; Dev acc 0.625000\n",
      "Epoch 20; Step 540; Loss 0.612650; Train acc: 0.750000; Dev acc 0.718750\n",
      "Epoch 25; Step 675; Loss 0.540035; Train acc: 0.808594; Dev acc 0.753906\n",
      "Epoch 30; Step 810; Loss 0.464049; Train acc: 0.832031; Dev acc 0.781250\n",
      "Best dev accuracy is 0.78125\n",
      "Best accuracy:  0.78125\n",
      "261 / 576  =  (0.0001, 50, 64, 2, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693137; Train acc: 0.468750; Dev acc 0.484375\n",
      "Epoch 5; Step 135; Loss 0.693066; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.689029; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.668012; Train acc: 0.628906; Dev acc 0.660156\n",
      "Epoch 20; Step 540; Loss 0.612327; Train acc: 0.773438; Dev acc 0.734375\n",
      "Epoch 25; Step 675; Loss 0.531605; Train acc: 0.855469; Dev acc 0.773438\n",
      "Epoch 30; Step 810; Loss 0.490165; Train acc: 0.843750; Dev acc 0.753906\n",
      "Best dev accuracy is 0.7734375\n",
      "Best accuracy:  0.7734375\n",
      "262 / 576  =  (0.0001, 50, 64, 2, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693152; Train acc: 0.511719; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.692879; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.690126; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.678294; Train acc: 0.546875; Dev acc 0.601562\n",
      "Epoch 20; Step 540; Loss 0.630470; Train acc: 0.636719; Dev acc 0.613281\n",
      "Epoch 25; Step 675; Loss 0.594686; Train acc: 0.691406; Dev acc 0.683594\n",
      "Epoch 30; Step 810; Loss 0.568745; Train acc: 0.843750; Dev acc 0.785156\n",
      "Best dev accuracy is 0.78515625\n",
      "Best accuracy:  0.78515625\n",
      "263 / 576  =  (0.0001, 50, 64, 2, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693134; Train acc: 0.488281; Dev acc 0.515625\n",
      "Epoch 5; Step 135; Loss 0.692874; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.692012; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.680380; Train acc: 0.523438; Dev acc 0.574219\n",
      "Epoch 20; Step 540; Loss 0.627797; Train acc: 0.679688; Dev acc 0.667969\n",
      "Epoch 25; Step 675; Loss 0.556718; Train acc: 0.800781; Dev acc 0.714844\n",
      "Epoch 30; Step 810; Loss 0.489207; Train acc: 0.851562; Dev acc 0.765625\n",
      "Best dev accuracy is 0.765625\n",
      "Best accuracy:  0.765625\n",
      "264 / 576  =  (0.0001, 50, 64, 3, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.496094; Dev acc 0.558594\n",
      "Epoch 5; Step 135; Loss 0.692368; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.681690; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.631488; Train acc: 0.613281; Dev acc 0.656250\n",
      "Epoch 20; Step 540; Loss 0.589929; Train acc: 0.718750; Dev acc 0.703125\n",
      "Epoch 25; Step 675; Loss 0.559346; Train acc: 0.820312; Dev acc 0.761719\n",
      "Epoch 30; Step 810; Loss 0.550412; Train acc: 0.867188; Dev acc 0.781250\n",
      "Best dev accuracy is 0.78125\n",
      "Best accuracy:  0.78125\n",
      "265 / 576  =  (0.0001, 50, 64, 3, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693137; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "266 / 576  =  (0.0001, 50, 64, 3, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "267 / 576  =  (0.0001, 50, 64, 3, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.488281; Dev acc 0.488281\n",
      "Epoch 5; Step 135; Loss 0.692943; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.691232; Train acc: 0.496094; Dev acc 0.542969\n",
      "Epoch 15; Step 405; Loss 0.643737; Train acc: 0.628906; Dev acc 0.621094\n",
      "Epoch 20; Step 540; Loss 0.625517; Train acc: 0.710938; Dev acc 0.687500\n",
      "Epoch 25; Step 675; Loss 0.566823; Train acc: 0.789062; Dev acc 0.750000\n",
      "Epoch 30; Step 810; Loss 0.557020; Train acc: 0.816406; Dev acc 0.703125\n",
      "Best dev accuracy is 0.75\n",
      "Best accuracy:  0.75\n",
      "268 / 576  =  (0.0001, 50, 64, 3, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693144; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.692902; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.691260; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.650962; Train acc: 0.585938; Dev acc 0.609375\n",
      "Epoch 20; Step 540; Loss 0.605055; Train acc: 0.734375; Dev acc 0.710938\n",
      "Epoch 25; Step 675; Loss 0.572271; Train acc: 0.835938; Dev acc 0.742188\n",
      "Epoch 30; Step 810; Loss 0.549888; Train acc: 0.832031; Dev acc 0.753906\n",
      "Best dev accuracy is 0.75390625\n",
      "Best accuracy:  0.75390625\n",
      "269 / 576  =  (0.0001, 50, 64, 3, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.550781; Dev acc 0.542969\n",
      "Epoch 5; Step 135; Loss 0.692782; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.690214; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.658683; Train acc: 0.593750; Dev acc 0.597656\n",
      "Epoch 20; Step 540; Loss 0.603788; Train acc: 0.710938; Dev acc 0.664062\n",
      "Epoch 25; Step 675; Loss 0.575965; Train acc: 0.792969; Dev acc 0.734375\n",
      "Epoch 30; Step 810; Loss 0.557284; Train acc: 0.847656; Dev acc 0.769531\n",
      "Best dev accuracy is 0.76953125\n",
      "Best accuracy:  0.76953125\n",
      "270 / 576  =  (0.0001, 50, 64, 3, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693150; Train acc: 0.511719; Dev acc 0.542969\n",
      "Epoch 5; Step 135; Loss 0.693048; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.686605; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.656785; Train acc: 0.613281; Dev acc 0.628906\n",
      "Epoch 20; Step 540; Loss 0.595691; Train acc: 0.761719; Dev acc 0.687500\n",
      "Epoch 25; Step 675; Loss 0.559663; Train acc: 0.812500; Dev acc 0.738281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30; Step 810; Loss 0.550149; Train acc: 0.851562; Dev acc 0.750000\n",
      "Best dev accuracy is 0.75\n",
      "Best accuracy:  0.75\n",
      "271 / 576  =  (0.0001, 50, 64, 3, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693145; Train acc: 0.472656; Dev acc 0.449219\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "272 / 576  =  (0.0001, 50, 64, 4, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693145; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.693524; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.674986; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.603520; Train acc: 0.714844; Dev acc 0.750000\n",
      "Epoch 20; Step 540; Loss 0.534180; Train acc: 0.843750; Dev acc 0.734375\n",
      "Epoch 25; Step 675; Loss 0.491375; Train acc: 0.851562; Dev acc 0.722656\n",
      "Epoch 30; Step 810; Loss 0.425623; Train acc: 0.882812; Dev acc 0.765625\n",
      "Best dev accuracy is 0.765625\n",
      "Best accuracy:  0.765625\n",
      "273 / 576  =  (0.0001, 50, 64, 4, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693150; Train acc: 0.480469; Dev acc 0.445312\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "274 / 576  =  (0.0001, 50, 64, 4, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "275 / 576  =  (0.0001, 50, 64, 4, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693143; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.694567; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.678678; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.592624; Train acc: 0.734375; Dev acc 0.703125\n",
      "Epoch 20; Step 540; Loss 0.512882; Train acc: 0.828125; Dev acc 0.765625\n",
      "Epoch 25; Step 675; Loss 0.454915; Train acc: 0.859375; Dev acc 0.773438\n",
      "Epoch 30; Step 810; Loss 0.403408; Train acc: 0.906250; Dev acc 0.781250\n",
      "Best dev accuracy is 0.78125\n",
      "Best accuracy:  0.78125\n",
      "276 / 576  =  (0.0001, 50, 64, 4, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.496094; Dev acc 0.539062\n",
      "Epoch 5; Step 135; Loss 0.692940; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.689729; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.650481; Train acc: 0.593750; Dev acc 0.644531\n",
      "Epoch 20; Step 540; Loss 0.598265; Train acc: 0.738281; Dev acc 0.730469\n",
      "Epoch 25; Step 675; Loss 0.558181; Train acc: 0.808594; Dev acc 0.734375\n",
      "Epoch 30; Step 810; Loss 0.548539; Train acc: 0.832031; Dev acc 0.742188\n",
      "Best dev accuracy is 0.7421875\n",
      "Best accuracy:  0.7421875\n",
      "277 / 576  =  (0.0001, 50, 64, 4, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "278 / 576  =  (0.0001, 50, 64, 4, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.500000; Dev acc 0.449219\n",
      "Epoch 5; Step 135; Loss 0.692883; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693317; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.683592; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.608636; Train acc: 0.683594; Dev acc 0.679688\n",
      "Epoch 25; Step 675; Loss 0.572897; Train acc: 0.742188; Dev acc 0.718750\n",
      "Epoch 30; Step 810; Loss 0.532056; Train acc: 0.820312; Dev acc 0.718750\n",
      "Best dev accuracy is 0.71875\n",
      "Best accuracy:  0.71875\n",
      "279 / 576  =  (0.0001, 50, 64, 4, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693148; Train acc: 0.507812; Dev acc 0.449219\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "280 / 576  =  (0.0001, 50, 64, 5, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "281 / 576  =  (0.0001, 50, 64, 5, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "282 / 576  =  (0.0001, 50, 64, 5, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693602; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.683010; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.590197; Train acc: 0.691406; Dev acc 0.687500\n",
      "Epoch 20; Step 540; Loss 0.467416; Train acc: 0.855469; Dev acc 0.769531\n",
      "Epoch 25; Step 675; Loss 0.414079; Train acc: 0.878906; Dev acc 0.722656\n",
      "Epoch 30; Step 810; Loss 0.406674; Train acc: 0.886719; Dev acc 0.738281\n",
      "Best dev accuracy is 0.76953125\n",
      "Best accuracy:  0.76953125\n",
      "283 / 576  =  (0.0001, 50, 64, 5, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.492188; Dev acc 0.550781\n",
      "Epoch 5; Step 135; Loss 0.694015; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.688972; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.624185; Train acc: 0.714844; Dev acc 0.710938\n",
      "Epoch 20; Step 540; Loss 0.570123; Train acc: 0.804688; Dev acc 0.734375\n",
      "Epoch 25; Step 675; Loss 0.524313; Train acc: 0.843750; Dev acc 0.742188\n",
      "Epoch 30; Step 810; Loss 0.540786; Train acc: 0.875000; Dev acc 0.707031\n",
      "Best dev accuracy is 0.7421875\n",
      "Best accuracy:  0.7421875\n",
      "284 / 576  =  (0.0001, 50, 64, 5, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.692651; Train acc: 0.496094; Dev acc 0.546875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10; Step 270; Loss 0.693180; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.698337; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.652586; Train acc: 0.656250; Dev acc 0.679688\n",
      "Epoch 25; Step 675; Loss 0.567405; Train acc: 0.773438; Dev acc 0.750000\n",
      "Epoch 30; Step 810; Loss 0.582592; Train acc: 0.808594; Dev acc 0.738281\n",
      "Best dev accuracy is 0.75\n",
      "Best accuracy:  0.75\n",
      "285 / 576  =  (0.0001, 50, 64, 5, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.500000; Dev acc 0.460938\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.4609375\n",
      "Best accuracy:  0.4609375\n",
      "286 / 576  =  (0.0001, 50, 64, 5, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.692527; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693070; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.673595; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.574205; Train acc: 0.710938; Dev acc 0.710938\n",
      "Epoch 25; Step 675; Loss 0.542713; Train acc: 0.812500; Dev acc 0.773438\n",
      "Epoch 30; Step 810; Loss 0.500046; Train acc: 0.886719; Dev acc 0.769531\n",
      "Best dev accuracy is 0.7734375\n",
      "Best accuracy:  0.7734375\n",
      "287 / 576  =  (0.0001, 50, 64, 5, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.693175; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.687848; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.673624; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.592981; Train acc: 0.730469; Dev acc 0.679688\n",
      "Epoch 25; Step 675; Loss 0.560704; Train acc: 0.820312; Dev acc 0.781250\n",
      "Epoch 30; Step 810; Loss 0.545652; Train acc: 0.828125; Dev acc 0.808594\n",
      "Best dev accuracy is 0.80859375\n",
      "Best accuracy:  0.80859375\n",
      "288 / 576  =  (0.0001, 50, 128, 2, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693115; Train acc: 0.535156; Dev acc 0.503906\n",
      "Epoch 5; Step 135; Loss 0.692694; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.678782; Train acc: 0.628906; Dev acc 0.601562\n",
      "Epoch 15; Step 405; Loss 0.597444; Train acc: 0.742188; Dev acc 0.714844\n",
      "Epoch 20; Step 540; Loss 0.517409; Train acc: 0.851562; Dev acc 0.777344\n",
      "Epoch 25; Step 675; Loss 0.446703; Train acc: 0.882812; Dev acc 0.777344\n",
      "Epoch 30; Step 810; Loss 0.423812; Train acc: 0.878906; Dev acc 0.753906\n",
      "Best dev accuracy is 0.77734375\n",
      "Best accuracy:  0.77734375\n",
      "289 / 576  =  (0.0001, 50, 128, 2, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693134; Train acc: 0.492188; Dev acc 0.433594\n",
      "Epoch 5; Step 135; Loss 0.691448; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.678246; Train acc: 0.593750; Dev acc 0.593750\n",
      "Epoch 15; Step 405; Loss 0.584838; Train acc: 0.718750; Dev acc 0.656250\n",
      "Epoch 20; Step 540; Loss 0.516906; Train acc: 0.839844; Dev acc 0.750000\n",
      "Epoch 25; Step 675; Loss 0.462206; Train acc: 0.859375; Dev acc 0.773438\n",
      "Epoch 30; Step 810; Loss 0.413822; Train acc: 0.871094; Dev acc 0.761719\n",
      "Best dev accuracy is 0.7734375\n",
      "Best accuracy:  0.7734375\n",
      "290 / 576  =  (0.0001, 50, 128, 2, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693164; Train acc: 0.503906; Dev acc 0.484375\n",
      "Epoch 5; Step 135; Loss 0.692338; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.677916; Train acc: 0.605469; Dev acc 0.589844\n",
      "Epoch 15; Step 405; Loss 0.592621; Train acc: 0.769531; Dev acc 0.667969\n",
      "Epoch 20; Step 540; Loss 0.498720; Train acc: 0.816406; Dev acc 0.746094\n",
      "Epoch 25; Step 675; Loss 0.441927; Train acc: 0.871094; Dev acc 0.695312\n",
      "Epoch 30; Step 810; Loss 0.427549; Train acc: 0.851562; Dev acc 0.757812\n",
      "Best dev accuracy is 0.7578125\n",
      "Best accuracy:  0.7578125\n",
      "291 / 576  =  (0.0001, 50, 128, 2, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693090; Train acc: 0.492188; Dev acc 0.562500\n",
      "Epoch 5; Step 135; Loss 0.690962; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.672349; Train acc: 0.605469; Dev acc 0.621094\n",
      "Epoch 15; Step 405; Loss 0.594760; Train acc: 0.734375; Dev acc 0.683594\n",
      "Epoch 20; Step 540; Loss 0.523285; Train acc: 0.828125; Dev acc 0.734375\n",
      "Epoch 25; Step 675; Loss 0.452438; Train acc: 0.871094; Dev acc 0.750000\n",
      "Epoch 30; Step 810; Loss 0.442704; Train acc: 0.890625; Dev acc 0.738281\n",
      "Best dev accuracy is 0.75\n",
      "Best accuracy:  0.75\n",
      "292 / 576  =  (0.0001, 50, 128, 2, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693132; Train acc: 0.503906; Dev acc 0.476562\n",
      "Epoch 5; Step 135; Loss 0.692260; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.679362; Train acc: 0.597656; Dev acc 0.628906\n",
      "Epoch 15; Step 405; Loss 0.601259; Train acc: 0.753906; Dev acc 0.660156\n",
      "Epoch 20; Step 540; Loss 0.519381; Train acc: 0.863281; Dev acc 0.742188\n",
      "Epoch 25; Step 675; Loss 0.448105; Train acc: 0.882812; Dev acc 0.722656\n",
      "Epoch 30; Step 810; Loss 0.401725; Train acc: 0.863281; Dev acc 0.750000\n",
      "Best dev accuracy is 0.75\n",
      "Best accuracy:  0.75\n",
      "293 / 576  =  (0.0001, 50, 128, 2, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693190; Train acc: 0.527344; Dev acc 0.476562\n",
      "Epoch 5; Step 135; Loss 0.692311; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.681863; Train acc: 0.535156; Dev acc 0.554688\n",
      "Epoch 15; Step 405; Loss 0.638100; Train acc: 0.664062; Dev acc 0.656250\n",
      "Epoch 20; Step 540; Loss 0.542971; Train acc: 0.804688; Dev acc 0.714844\n",
      "Epoch 25; Step 675; Loss 0.465918; Train acc: 0.871094; Dev acc 0.761719\n",
      "Epoch 30; Step 810; Loss 0.443681; Train acc: 0.906250; Dev acc 0.773438\n",
      "Best dev accuracy is 0.7734375\n",
      "Best accuracy:  0.7734375\n",
      "294 / 576  =  (0.0001, 50, 128, 2, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693162; Train acc: 0.523438; Dev acc 0.429688\n",
      "Epoch 5; Step 135; Loss 0.692467; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.685163; Train acc: 0.546875; Dev acc 0.597656\n",
      "Epoch 15; Step 405; Loss 0.601009; Train acc: 0.691406; Dev acc 0.675781\n",
      "Epoch 20; Step 540; Loss 0.501790; Train acc: 0.792969; Dev acc 0.769531\n",
      "Epoch 25; Step 675; Loss 0.447827; Train acc: 0.820312; Dev acc 0.757812\n",
      "Epoch 30; Step 810; Loss 0.442116; Train acc: 0.878906; Dev acc 0.761719\n",
      "Best dev accuracy is 0.76953125\n",
      "Best accuracy:  0.76953125\n",
      "295 / 576  =  (0.0001, 50, 128, 2, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693121; Train acc: 0.507812; Dev acc 0.539062\n",
      "Epoch 5; Step 135; Loss 0.693398; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.678021; Train acc: 0.585938; Dev acc 0.597656\n",
      "Epoch 15; Step 405; Loss 0.592604; Train acc: 0.691406; Dev acc 0.660156\n",
      "Epoch 20; Step 540; Loss 0.514821; Train acc: 0.839844; Dev acc 0.718750\n",
      "Epoch 25; Step 675; Loss 0.453105; Train acc: 0.867188; Dev acc 0.757812\n",
      "Epoch 30; Step 810; Loss 0.442912; Train acc: 0.863281; Dev acc 0.742188\n",
      "Best dev accuracy is 0.7578125\n",
      "Best accuracy:  0.7578125\n",
      "296 / 576  =  (0.0001, 50, 128, 3, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693170; Train acc: 0.496094; Dev acc 0.476562\n",
      "Epoch 5; Step 135; Loss 0.693056; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.649175; Train acc: 0.628906; Dev acc 0.597656\n",
      "Epoch 15; Step 405; Loss 0.601571; Train acc: 0.757812; Dev acc 0.710938\n",
      "Epoch 20; Step 540; Loss 0.564507; Train acc: 0.808594; Dev acc 0.691406\n",
      "Epoch 25; Step 675; Loss 0.546340; Train acc: 0.878906; Dev acc 0.714844\n",
      "Epoch 30; Step 810; Loss 0.550005; Train acc: 0.835938; Dev acc 0.730469\n",
      "Best dev accuracy is 0.73046875\n",
      "Best accuracy:  0.73046875\n",
      "297 / 576  =  (0.0001, 50, 128, 3, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693152; Train acc: 0.500000; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.692200; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.663906; Train acc: 0.585938; Dev acc 0.605469\n",
      "Epoch 15; Step 405; Loss 0.574292; Train acc: 0.738281; Dev acc 0.683594\n",
      "Epoch 20; Step 540; Loss 0.553769; Train acc: 0.812500; Dev acc 0.718750\n",
      "Epoch 25; Step 675; Loss 0.552132; Train acc: 0.851562; Dev acc 0.750000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30; Step 810; Loss 0.538638; Train acc: 0.894531; Dev acc 0.734375\n",
      "Best dev accuracy is 0.75\n",
      "Best accuracy:  0.75\n",
      "298 / 576  =  (0.0001, 50, 128, 3, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.515625; Dev acc 0.468750\n",
      "Epoch 5; Step 135; Loss 0.692490; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.642363; Train acc: 0.648438; Dev acc 0.679688\n",
      "Epoch 15; Step 405; Loss 0.485710; Train acc: 0.785156; Dev acc 0.718750\n",
      "Epoch 20; Step 540; Loss 0.480074; Train acc: 0.875000; Dev acc 0.750000\n",
      "Epoch 25; Step 675; Loss 0.416090; Train acc: 0.871094; Dev acc 0.753906\n",
      "Epoch 30; Step 810; Loss 0.398598; Train acc: 0.894531; Dev acc 0.753906\n",
      "Best dev accuracy is 0.75390625\n",
      "Best accuracy:  0.75390625\n",
      "299 / 576  =  (0.0001, 50, 128, 3, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693141; Train acc: 0.500000; Dev acc 0.570312\n",
      "Epoch 5; Step 135; Loss 0.691531; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.660201; Train acc: 0.621094; Dev acc 0.617188\n",
      "Epoch 15; Step 405; Loss 0.520542; Train acc: 0.820312; Dev acc 0.703125\n",
      "Epoch 20; Step 540; Loss 0.460853; Train acc: 0.863281; Dev acc 0.750000\n",
      "Epoch 25; Step 675; Loss 0.430444; Train acc: 0.859375; Dev acc 0.769531\n",
      "Epoch 30; Step 810; Loss 0.386438; Train acc: 0.863281; Dev acc 0.804688\n",
      "Best dev accuracy is 0.8046875\n",
      "Best accuracy:  0.8046875\n",
      "300 / 576  =  (0.0001, 50, 128, 3, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693153; Train acc: 0.523438; Dev acc 0.492188\n",
      "Epoch 5; Step 135; Loss 0.691299; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.662568; Train acc: 0.542969; Dev acc 0.628906\n",
      "Epoch 15; Step 405; Loss 0.540091; Train acc: 0.757812; Dev acc 0.746094\n",
      "Epoch 20; Step 540; Loss 0.469039; Train acc: 0.847656; Dev acc 0.722656\n",
      "Epoch 25; Step 675; Loss 0.393700; Train acc: 0.875000; Dev acc 0.765625\n",
      "Epoch 30; Step 810; Loss 0.426787; Train acc: 0.894531; Dev acc 0.781250\n",
      "Best dev accuracy is 0.78125\n",
      "Best accuracy:  0.78125\n",
      "301 / 576  =  (0.0001, 50, 128, 3, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693155; Train acc: 0.511719; Dev acc 0.503906\n",
      "Epoch 5; Step 135; Loss 0.693263; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.668617; Train acc: 0.546875; Dev acc 0.582031\n",
      "Epoch 15; Step 405; Loss 0.527981; Train acc: 0.769531; Dev acc 0.699219\n",
      "Epoch 20; Step 540; Loss 0.441139; Train acc: 0.851562; Dev acc 0.765625\n",
      "Epoch 25; Step 675; Loss 0.417167; Train acc: 0.863281; Dev acc 0.753906\n",
      "Epoch 30; Step 810; Loss 0.403555; Train acc: 0.906250; Dev acc 0.757812\n",
      "Best dev accuracy is 0.765625\n",
      "Best accuracy:  0.765625\n",
      "302 / 576  =  (0.0001, 50, 128, 3, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693149; Train acc: 0.523438; Dev acc 0.542969\n",
      "Epoch 5; Step 135; Loss 0.694990; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.665420; Train acc: 0.554688; Dev acc 0.585938\n",
      "Epoch 15; Step 405; Loss 0.600849; Train acc: 0.742188; Dev acc 0.687500\n",
      "Epoch 20; Step 540; Loss 0.559024; Train acc: 0.824219; Dev acc 0.707031\n",
      "Epoch 25; Step 675; Loss 0.560468; Train acc: 0.863281; Dev acc 0.750000\n",
      "Epoch 30; Step 810; Loss 0.550447; Train acc: 0.898438; Dev acc 0.746094\n",
      "Best dev accuracy is 0.75\n",
      "Best accuracy:  0.75\n",
      "303 / 576  =  (0.0001, 50, 128, 3, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693150; Train acc: 0.500000; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "304 / 576  =  (0.0001, 50, 128, 4, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693153; Train acc: 0.519531; Dev acc 0.496094\n",
      "Epoch 5; Step 135; Loss 0.689861; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.596596; Train acc: 0.679688; Dev acc 0.695312\n",
      "Epoch 15; Step 405; Loss 0.453793; Train acc: 0.816406; Dev acc 0.742188\n",
      "Epoch 20; Step 540; Loss 0.442624; Train acc: 0.890625; Dev acc 0.765625\n",
      "Epoch 25; Step 675; Loss 0.410902; Train acc: 0.863281; Dev acc 0.730469\n",
      "Epoch 30; Step 810; Loss 0.391061; Train acc: 0.898438; Dev acc 0.750000\n",
      "Best dev accuracy is 0.765625\n",
      "Best accuracy:  0.765625\n",
      "305 / 576  =  (0.0001, 50, 128, 4, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693149; Train acc: 0.511719; Dev acc 0.511719\n",
      "Epoch 5; Step 135; Loss 0.689214; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.606762; Train acc: 0.667969; Dev acc 0.671875\n",
      "Epoch 15; Step 405; Loss 0.475225; Train acc: 0.808594; Dev acc 0.781250\n",
      "Epoch 20; Step 540; Loss 0.413131; Train acc: 0.878906; Dev acc 0.757812\n",
      "Epoch 25; Step 675; Loss 0.408933; Train acc: 0.871094; Dev acc 0.765625\n",
      "Epoch 30; Step 810; Loss 0.414273; Train acc: 0.906250; Dev acc 0.753906\n",
      "Best dev accuracy is 0.78125\n",
      "Best accuracy:  0.78125\n",
      "306 / 576  =  (0.0001, 50, 128, 4, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693156; Train acc: 0.496094; Dev acc 0.449219\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "307 / 576  =  (0.0001, 50, 128, 4, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693140; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.690935; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.625506; Train acc: 0.699219; Dev acc 0.671875\n",
      "Epoch 15; Step 405; Loss 0.576719; Train acc: 0.800781; Dev acc 0.707031\n",
      "Epoch 20; Step 540; Loss 0.567057; Train acc: 0.847656; Dev acc 0.738281\n",
      "Epoch 25; Step 675; Loss 0.538253; Train acc: 0.863281; Dev acc 0.726562\n",
      "Epoch 30; Step 810; Loss 0.539879; Train acc: 0.902344; Dev acc 0.750000\n",
      "Best dev accuracy is 0.75\n",
      "Best accuracy:  0.75\n",
      "308 / 576  =  (0.0001, 50, 128, 4, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693143; Train acc: 0.500000; Dev acc 0.558594\n",
      "Epoch 5; Step 135; Loss 0.694727; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.625430; Train acc: 0.605469; Dev acc 0.648438\n",
      "Epoch 15; Step 405; Loss 0.478862; Train acc: 0.816406; Dev acc 0.789062\n",
      "Epoch 20; Step 540; Loss 0.420806; Train acc: 0.851562; Dev acc 0.761719\n",
      "Epoch 25; Step 675; Loss 0.416139; Train acc: 0.890625; Dev acc 0.796875\n",
      "Epoch 30; Step 810; Loss 0.373326; Train acc: 0.882812; Dev acc 0.765625\n",
      "Best dev accuracy is 0.796875\n",
      "Best accuracy:  0.796875\n",
      "309 / 576  =  (0.0001, 50, 128, 4, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693145; Train acc: 0.488281; Dev acc 0.570312\n",
      "Epoch 5; Step 135; Loss 0.688747; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.637539; Train acc: 0.574219; Dev acc 0.609375\n",
      "Epoch 15; Step 405; Loss 0.566927; Train acc: 0.734375; Dev acc 0.753906\n",
      "Epoch 20; Step 540; Loss 0.568313; Train acc: 0.835938; Dev acc 0.722656\n",
      "Epoch 25; Step 675; Loss 0.566226; Train acc: 0.886719; Dev acc 0.730469\n",
      "Epoch 30; Step 810; Loss 0.534199; Train acc: 0.839844; Dev acc 0.750000\n",
      "Best dev accuracy is 0.75390625\n",
      "Best accuracy:  0.75390625\n",
      "310 / 576  =  (0.0001, 50, 128, 4, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693145; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "311 / 576  =  (0.0001, 50, 128, 4, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693148; Train acc: 0.500000; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "312 / 576  =  (0.0001, 50, 128, 5, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693149; Train acc: 0.496094; Dev acc 0.542969\n",
      "Epoch 5; Step 135; Loss 0.693819; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.640986; Train acc: 0.679688; Dev acc 0.671875\n",
      "Epoch 15; Step 405; Loss 0.464176; Train acc: 0.808594; Dev acc 0.765625\n",
      "Epoch 20; Step 540; Loss 0.465047; Train acc: 0.863281; Dev acc 0.722656\n",
      "Epoch 25; Step 675; Loss 0.424751; Train acc: 0.878906; Dev acc 0.738281\n",
      "Epoch 30; Step 810; Loss 0.372994; Train acc: 0.886719; Dev acc 0.757812\n",
      "Best dev accuracy is 0.765625\n",
      "Best accuracy:  0.765625\n",
      "313 / 576  =  (0.0001, 50, 128, 5, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693151; Train acc: 0.496094; Dev acc 0.460938\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.4609375\n",
      "Best accuracy:  0.4609375\n",
      "314 / 576  =  (0.0001, 50, 128, 5, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693149; Train acc: 0.507812; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "315 / 576  =  (0.0001, 50, 128, 5, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693145; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.688897; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.646715; Train acc: 0.625000; Dev acc 0.652344\n",
      "Epoch 15; Step 405; Loss 0.565432; Train acc: 0.796875; Dev acc 0.789062\n",
      "Epoch 20; Step 540; Loss 0.563676; Train acc: 0.843750; Dev acc 0.710938\n",
      "Epoch 25; Step 675; Loss 0.540515; Train acc: 0.871094; Dev acc 0.730469\n",
      "Epoch 30; Step 810; Loss 0.540230; Train acc: 0.871094; Dev acc 0.746094\n",
      "Best dev accuracy is 0.7890625\n",
      "Best accuracy:  0.7890625\n",
      "316 / 576  =  (0.0001, 50, 128, 5, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693149; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.688478; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.632625; Train acc: 0.667969; Dev acc 0.644531\n",
      "Epoch 15; Step 405; Loss 0.560115; Train acc: 0.796875; Dev acc 0.734375\n",
      "Epoch 20; Step 540; Loss 0.488414; Train acc: 0.871094; Dev acc 0.707031\n",
      "Epoch 25; Step 675; Loss 0.414943; Train acc: 0.875000; Dev acc 0.757812\n",
      "Epoch 30; Step 810; Loss 0.395300; Train acc: 0.878906; Dev acc 0.746094\n",
      "Best dev accuracy is 0.7578125\n",
      "Best accuracy:  0.7578125\n",
      "317 / 576  =  (0.0001, 50, 128, 5, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "318 / 576  =  (0.0001, 50, 128, 5, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "319 / 576  =  (0.0001, 50, 128, 5, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693143; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.692717; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.632433; Train acc: 0.644531; Dev acc 0.671875\n",
      "Epoch 15; Step 405; Loss 0.524005; Train acc: 0.742188; Dev acc 0.765625\n",
      "Epoch 20; Step 540; Loss 0.469759; Train acc: 0.835938; Dev acc 0.734375\n",
      "Epoch 25; Step 675; Loss 0.403618; Train acc: 0.890625; Dev acc 0.753906\n",
      "Epoch 30; Step 810; Loss 0.418556; Train acc: 0.871094; Dev acc 0.777344\n",
      "Best dev accuracy is 0.77734375\n",
      "Best accuracy:  0.77734375\n",
      "320 / 576  =  (0.0001, 200, 64, 2, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693176; Train acc: 0.519531; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.692914; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.683106; Train acc: 0.617188; Dev acc 0.601562\n",
      "Epoch 15; Step 405; Loss 0.605859; Train acc: 0.773438; Dev acc 0.753906\n",
      "Epoch 20; Step 540; Loss 0.507319; Train acc: 0.871094; Dev acc 0.761719\n",
      "Epoch 25; Step 675; Loss 0.445908; Train acc: 0.839844; Dev acc 0.726562\n",
      "Epoch 30; Step 810; Loss 0.431698; Train acc: 0.894531; Dev acc 0.734375\n",
      "Best dev accuracy is 0.76171875\n",
      "Best accuracy:  0.76171875\n",
      "321 / 576  =  (0.0001, 200, 64, 2, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693144; Train acc: 0.496094; Dev acc 0.503906\n",
      "Epoch 5; Step 135; Loss 0.691721; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.682127; Train acc: 0.542969; Dev acc 0.566406\n",
      "Epoch 15; Step 405; Loss 0.640781; Train acc: 0.644531; Dev acc 0.636719\n",
      "Epoch 20; Step 540; Loss 0.587883; Train acc: 0.773438; Dev acc 0.707031\n",
      "Epoch 25; Step 675; Loss 0.560496; Train acc: 0.804688; Dev acc 0.738281\n",
      "Epoch 30; Step 810; Loss 0.551525; Train acc: 0.843750; Dev acc 0.718750\n",
      "Best dev accuracy is 0.73828125\n",
      "Best accuracy:  0.73828125\n",
      "322 / 576  =  (0.0001, 200, 64, 2, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693157; Train acc: 0.472656; Dev acc 0.488281\n",
      "Epoch 5; Step 135; Loss 0.692620; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.687822; Train acc: 0.500000; Dev acc 0.562500\n",
      "Epoch 15; Step 405; Loss 0.660428; Train acc: 0.632812; Dev acc 0.625000\n",
      "Epoch 20; Step 540; Loss 0.605924; Train acc: 0.753906; Dev acc 0.691406\n",
      "Epoch 25; Step 675; Loss 0.581875; Train acc: 0.812500; Dev acc 0.722656\n",
      "Epoch 30; Step 810; Loss 0.559326; Train acc: 0.824219; Dev acc 0.742188\n",
      "Best dev accuracy is 0.7421875\n",
      "Best accuracy:  0.7421875\n",
      "323 / 576  =  (0.0001, 200, 64, 2, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693151; Train acc: 0.503906; Dev acc 0.523438\n",
      "Epoch 5; Step 135; Loss 0.692714; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.680308; Train acc: 0.664062; Dev acc 0.625000\n",
      "Epoch 15; Step 405; Loss 0.609342; Train acc: 0.757812; Dev acc 0.734375\n",
      "Epoch 20; Step 540; Loss 0.528264; Train acc: 0.835938; Dev acc 0.765625\n",
      "Epoch 25; Step 675; Loss 0.453042; Train acc: 0.898438; Dev acc 0.785156\n",
      "Epoch 30; Step 810; Loss 0.415913; Train acc: 0.910156; Dev acc 0.765625\n",
      "Best dev accuracy is 0.78515625\n",
      "Best accuracy:  0.78515625\n",
      "324 / 576  =  (0.0001, 200, 64, 2, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693131; Train acc: 0.511719; Dev acc 0.472656\n",
      "Epoch 5; Step 135; Loss 0.692687; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.685692; Train acc: 0.621094; Dev acc 0.585938\n",
      "Epoch 15; Step 405; Loss 0.630655; Train acc: 0.753906; Dev acc 0.722656\n",
      "Epoch 20; Step 540; Loss 0.537799; Train acc: 0.828125; Dev acc 0.753906\n",
      "Epoch 25; Step 675; Loss 0.457222; Train acc: 0.882812; Dev acc 0.757812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30; Step 810; Loss 0.418571; Train acc: 0.902344; Dev acc 0.769531\n",
      "Best dev accuracy is 0.76953125\n",
      "Best accuracy:  0.76953125\n",
      "325 / 576  =  (0.0001, 200, 64, 2, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693137; Train acc: 0.507812; Dev acc 0.464844\n",
      "Epoch 5; Step 135; Loss 0.692451; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.688003; Train acc: 0.515625; Dev acc 0.531250\n",
      "Epoch 15; Step 405; Loss 0.641686; Train acc: 0.679688; Dev acc 0.687500\n",
      "Epoch 20; Step 540; Loss 0.512664; Train acc: 0.828125; Dev acc 0.816406\n",
      "Epoch 25; Step 675; Loss 0.450847; Train acc: 0.863281; Dev acc 0.812500\n",
      "Epoch 30; Step 810; Loss 0.407072; Train acc: 0.886719; Dev acc 0.738281\n",
      "Best dev accuracy is 0.81640625\n",
      "Best accuracy:  0.81640625\n",
      "326 / 576  =  (0.0001, 200, 64, 2, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693173; Train acc: 0.539062; Dev acc 0.496094\n",
      "Epoch 5; Step 135; Loss 0.693000; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.685867; Train acc: 0.574219; Dev acc 0.601562\n",
      "Epoch 15; Step 405; Loss 0.629651; Train acc: 0.742188; Dev acc 0.707031\n",
      "Epoch 20; Step 540; Loss 0.539709; Train acc: 0.824219; Dev acc 0.777344\n",
      "Epoch 25; Step 675; Loss 0.443698; Train acc: 0.863281; Dev acc 0.761719\n",
      "Epoch 30; Step 810; Loss 0.427239; Train acc: 0.902344; Dev acc 0.792969\n",
      "Best dev accuracy is 0.79296875\n",
      "Best accuracy:  0.79296875\n",
      "327 / 576  =  (0.0001, 200, 64, 2, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693101; Train acc: 0.488281; Dev acc 0.550781\n",
      "Epoch 5; Step 135; Loss 0.691432; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.682407; Train acc: 0.515625; Dev acc 0.562500\n",
      "Epoch 15; Step 405; Loss 0.618198; Train acc: 0.703125; Dev acc 0.699219\n",
      "Epoch 20; Step 540; Loss 0.508026; Train acc: 0.812500; Dev acc 0.804688\n",
      "Epoch 25; Step 675; Loss 0.457545; Train acc: 0.878906; Dev acc 0.789062\n",
      "Epoch 30; Step 810; Loss 0.411014; Train acc: 0.910156; Dev acc 0.769531\n",
      "Best dev accuracy is 0.8046875\n",
      "Best accuracy:  0.8046875\n",
      "328 / 576  =  (0.0001, 200, 64, 3, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693140; Train acc: 0.523438; Dev acc 0.492188\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.4921875\n",
      "Best accuracy:  0.4921875\n",
      "329 / 576  =  (0.0001, 200, 64, 3, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693138; Train acc: 0.507812; Dev acc 0.539062\n",
      "Epoch 5; Step 135; Loss 0.690831; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.667382; Train acc: 0.597656; Dev acc 0.621094\n",
      "Epoch 15; Step 405; Loss 0.561136; Train acc: 0.789062; Dev acc 0.742188\n",
      "Epoch 20; Step 540; Loss 0.480451; Train acc: 0.863281; Dev acc 0.800781\n",
      "Epoch 25; Step 675; Loss 0.434963; Train acc: 0.902344; Dev acc 0.773438\n",
      "Epoch 30; Step 810; Loss 0.382736; Train acc: 0.910156; Dev acc 0.761719\n",
      "Best dev accuracy is 0.80078125\n",
      "Best accuracy:  0.80078125\n",
      "330 / 576  =  (0.0001, 200, 64, 3, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693145; Train acc: 0.535156; Dev acc 0.511719\n",
      "Epoch 5; Step 135; Loss 0.692861; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.673587; Train acc: 0.531250; Dev acc 0.597656\n",
      "Epoch 15; Step 405; Loss 0.597570; Train acc: 0.675781; Dev acc 0.683594\n",
      "Epoch 20; Step 540; Loss 0.560065; Train acc: 0.871094; Dev acc 0.726562\n",
      "Epoch 25; Step 675; Loss 0.535042; Train acc: 0.871094; Dev acc 0.738281\n",
      "Epoch 30; Step 810; Loss 0.547856; Train acc: 0.886719; Dev acc 0.765625\n",
      "Best dev accuracy is 0.765625\n",
      "Best accuracy:  0.765625\n",
      "331 / 576  =  (0.0001, 200, 64, 3, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693148; Train acc: 0.527344; Dev acc 0.503906\n",
      "Epoch 5; Step 135; Loss 0.692064; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.664600; Train acc: 0.539062; Dev acc 0.593750\n",
      "Epoch 15; Step 405; Loss 0.610497; Train acc: 0.722656; Dev acc 0.695312\n",
      "Epoch 20; Step 540; Loss 0.574121; Train acc: 0.835938; Dev acc 0.769531\n",
      "Epoch 25; Step 675; Loss 0.572342; Train acc: 0.871094; Dev acc 0.753906\n",
      "Epoch 30; Step 810; Loss 0.556415; Train acc: 0.886719; Dev acc 0.714844\n",
      "Best dev accuracy is 0.76953125\n",
      "Best accuracy:  0.76953125\n",
      "332 / 576  =  (0.0001, 200, 64, 3, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693145; Train acc: 0.542969; Dev acc 0.476562\n",
      "Epoch 5; Step 135; Loss 0.693247; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.689548; Train acc: 0.507812; Dev acc 0.554688\n",
      "Epoch 15; Step 405; Loss 0.634273; Train acc: 0.621094; Dev acc 0.667969\n",
      "Epoch 20; Step 540; Loss 0.580701; Train acc: 0.761719; Dev acc 0.722656\n",
      "Epoch 25; Step 675; Loss 0.563240; Train acc: 0.878906; Dev acc 0.781250\n",
      "Epoch 30; Step 810; Loss 0.548408; Train acc: 0.890625; Dev acc 0.761719\n",
      "Best dev accuracy is 0.78125\n",
      "Best accuracy:  0.78125\n",
      "333 / 576  =  (0.0001, 200, 64, 3, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693121; Train acc: 0.492188; Dev acc 0.542969\n",
      "Epoch 5; Step 135; Loss 0.692834; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.679477; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.602326; Train acc: 0.734375; Dev acc 0.671875\n",
      "Epoch 20; Step 540; Loss 0.524046; Train acc: 0.839844; Dev acc 0.765625\n",
      "Epoch 25; Step 675; Loss 0.462988; Train acc: 0.886719; Dev acc 0.789062\n",
      "Epoch 30; Step 810; Loss 0.411192; Train acc: 0.933594; Dev acc 0.761719\n",
      "Best dev accuracy is 0.7890625\n",
      "Best accuracy:  0.7890625\n",
      "334 / 576  =  (0.0001, 200, 64, 3, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693151; Train acc: 0.523438; Dev acc 0.445312\n",
      "Epoch 5; Step 135; Loss 0.692630; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.677679; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.615970; Train acc: 0.695312; Dev acc 0.683594\n",
      "Epoch 20; Step 540; Loss 0.528996; Train acc: 0.835938; Dev acc 0.738281\n",
      "Epoch 25; Step 675; Loss 0.454537; Train acc: 0.890625; Dev acc 0.753906\n",
      "Epoch 30; Step 810; Loss 0.412365; Train acc: 0.917969; Dev acc 0.769531\n",
      "Best dev accuracy is 0.76953125\n",
      "Best accuracy:  0.76953125\n",
      "335 / 576  =  (0.0001, 200, 64, 3, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693145; Train acc: 0.488281; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.692291; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.680540; Train acc: 0.500000; Dev acc 0.550781\n",
      "Epoch 15; Step 405; Loss 0.626921; Train acc: 0.687500; Dev acc 0.664062\n",
      "Epoch 20; Step 540; Loss 0.563779; Train acc: 0.828125; Dev acc 0.773438\n",
      "Epoch 25; Step 675; Loss 0.563713; Train acc: 0.863281; Dev acc 0.738281\n",
      "Epoch 30; Step 810; Loss 0.546637; Train acc: 0.863281; Dev acc 0.769531\n",
      "Best dev accuracy is 0.7734375\n",
      "Best accuracy:  0.7734375\n",
      "336 / 576  =  (0.0001, 200, 64, 4, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693157; Train acc: 0.515625; Dev acc 0.484375\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.484375\n",
      "Best accuracy:  0.484375\n",
      "337 / 576  =  (0.0001, 200, 64, 4, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693139; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.692792; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.665321; Train acc: 0.585938; Dev acc 0.601562\n",
      "Epoch 15; Step 405; Loss 0.584881; Train acc: 0.777344; Dev acc 0.738281\n",
      "Epoch 20; Step 540; Loss 0.577666; Train acc: 0.847656; Dev acc 0.753906\n",
      "Epoch 25; Step 675; Loss 0.547830; Train acc: 0.863281; Dev acc 0.769531\n",
      "Epoch 30; Step 810; Loss 0.540627; Train acc: 0.894531; Dev acc 0.753906\n",
      "Best dev accuracy is 0.76953125\n",
      "Best accuracy:  0.76953125\n",
      "338 / 576  =  (0.0001, 200, 64, 4, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693158; Train acc: 0.476562; Dev acc 0.550781\n",
      "Epoch 5; Step 135; Loss 0.693448; Train acc: 0.496094; Dev acc 0.546875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10; Step 270; Loss 0.639771; Train acc: 0.597656; Dev acc 0.617188\n",
      "Epoch 15; Step 405; Loss 0.559577; Train acc: 0.839844; Dev acc 0.765625\n",
      "Epoch 20; Step 540; Loss 0.435758; Train acc: 0.890625; Dev acc 0.777344\n",
      "Epoch 25; Step 675; Loss 0.418308; Train acc: 0.925781; Dev acc 0.738281\n",
      "Epoch 30; Step 810; Loss 0.406437; Train acc: 0.878906; Dev acc 0.777344\n",
      "Best dev accuracy is 0.77734375\n",
      "Best accuracy:  0.77734375\n",
      "339 / 576  =  (0.0001, 200, 64, 4, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.500000; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.691481; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.647036; Train acc: 0.597656; Dev acc 0.582031\n",
      "Epoch 15; Step 405; Loss 0.560687; Train acc: 0.804688; Dev acc 0.718750\n",
      "Epoch 20; Step 540; Loss 0.468607; Train acc: 0.855469; Dev acc 0.742188\n",
      "Epoch 25; Step 675; Loss 0.404271; Train acc: 0.898438; Dev acc 0.757812\n",
      "Epoch 30; Step 810; Loss 0.390902; Train acc: 0.894531; Dev acc 0.722656\n",
      "Best dev accuracy is 0.7578125\n",
      "Best accuracy:  0.7578125\n",
      "340 / 576  =  (0.0001, 200, 64, 4, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.500000; Dev acc 0.457031\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.45703125\n",
      "Best accuracy:  0.45703125\n",
      "341 / 576  =  (0.0001, 200, 64, 4, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693150; Train acc: 0.507812; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "342 / 576  =  (0.0001, 200, 64, 4, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.693434; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.669980; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.606880; Train acc: 0.742188; Dev acc 0.730469\n",
      "Epoch 20; Step 540; Loss 0.521964; Train acc: 0.886719; Dev acc 0.746094\n",
      "Epoch 25; Step 675; Loss 0.432983; Train acc: 0.882812; Dev acc 0.773438\n",
      "Epoch 30; Step 810; Loss 0.390392; Train acc: 0.914062; Dev acc 0.742188\n",
      "Best dev accuracy is 0.7734375\n",
      "Best accuracy:  0.7734375\n",
      "343 / 576  =  (0.0001, 200, 64, 4, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693148; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "344 / 576  =  (0.0001, 200, 64, 5, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.690851; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.655668; Train acc: 0.562500; Dev acc 0.601562\n",
      "Epoch 15; Step 405; Loss 0.576723; Train acc: 0.820312; Dev acc 0.765625\n",
      "Epoch 20; Step 540; Loss 0.555615; Train acc: 0.855469; Dev acc 0.750000\n",
      "Epoch 25; Step 675; Loss 0.546982; Train acc: 0.906250; Dev acc 0.773438\n",
      "Epoch 30; Step 810; Loss 0.542688; Train acc: 0.898438; Dev acc 0.765625\n",
      "Best dev accuracy is 0.7734375\n",
      "Best accuracy:  0.7734375\n",
      "345 / 576  =  (0.0001, 200, 64, 5, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.692558; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.669657; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.547086; Train acc: 0.777344; Dev acc 0.714844\n",
      "Epoch 20; Step 540; Loss 0.565054; Train acc: 0.859375; Dev acc 0.773438\n",
      "Epoch 25; Step 675; Loss 0.537422; Train acc: 0.882812; Dev acc 0.738281\n",
      "Epoch 30; Step 810; Loss 0.557491; Train acc: 0.917969; Dev acc 0.742188\n",
      "Best dev accuracy is 0.7734375\n",
      "Best accuracy:  0.7734375\n",
      "346 / 576  =  (0.0001, 200, 64, 5, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.496094; Dev acc 0.476562\n",
      "Epoch 5; Step 135; Loss 0.693153; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.668033; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.573748; Train acc: 0.820312; Dev acc 0.718750\n",
      "Epoch 20; Step 540; Loss 0.548595; Train acc: 0.859375; Dev acc 0.726562\n",
      "Epoch 25; Step 675; Loss 0.534757; Train acc: 0.875000; Dev acc 0.753906\n",
      "Epoch 30; Step 810; Loss 0.551960; Train acc: 0.867188; Dev acc 0.753906\n",
      "Best dev accuracy is 0.75390625\n",
      "Best accuracy:  0.75390625\n",
      "347 / 576  =  (0.0001, 200, 64, 5, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "348 / 576  =  (0.0001, 200, 64, 5, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "349 / 576  =  (0.0001, 200, 64, 5, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "350 / 576  =  (0.0001, 200, 64, 5, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.692802; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.684640; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.602176; Train acc: 0.722656; Dev acc 0.707031\n",
      "Epoch 20; Step 540; Loss 0.571368; Train acc: 0.878906; Dev acc 0.785156\n",
      "Epoch 25; Step 675; Loss 0.584818; Train acc: 0.867188; Dev acc 0.777344\n",
      "Epoch 30; Step 810; Loss 0.541114; Train acc: 0.902344; Dev acc 0.726562\n",
      "Best dev accuracy is 0.78515625\n",
      "Best accuracy:  0.78515625\n",
      "351 / 576  =  (0.0001, 200, 64, 5, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693148; Train acc: 0.496094; Dev acc 0.550781\n",
      "Epoch 5; Step 135; Loss 0.692682; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.691353; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.629048; Train acc: 0.679688; Dev acc 0.667969\n",
      "Epoch 20; Step 540; Loss 0.549387; Train acc: 0.824219; Dev acc 0.746094\n",
      "Epoch 25; Step 675; Loss 0.456807; Train acc: 0.898438; Dev acc 0.785156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30; Step 810; Loss 0.398672; Train acc: 0.886719; Dev acc 0.742188\n",
      "Best dev accuracy is 0.78515625\n",
      "Best accuracy:  0.78515625\n",
      "352 / 576  =  (0.0001, 200, 128, 2, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.692981; Train acc: 0.480469; Dev acc 0.539062\n",
      "Epoch 5; Step 135; Loss 0.693208; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.641437; Train acc: 0.675781; Dev acc 0.675781\n",
      "Epoch 15; Step 405; Loss 0.504459; Train acc: 0.835938; Dev acc 0.753906\n",
      "Epoch 20; Step 540; Loss 0.429196; Train acc: 0.863281; Dev acc 0.742188\n",
      "Epoch 25; Step 675; Loss 0.414739; Train acc: 0.867188; Dev acc 0.750000\n",
      "Epoch 30; Step 810; Loss 0.403091; Train acc: 0.894531; Dev acc 0.785156\n",
      "Best dev accuracy is 0.78515625\n",
      "Best accuracy:  0.78515625\n",
      "353 / 576  =  (0.0001, 200, 128, 2, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693210; Train acc: 0.511719; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693215; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.661467; Train acc: 0.679688; Dev acc 0.703125\n",
      "Epoch 15; Step 405; Loss 0.511751; Train acc: 0.839844; Dev acc 0.777344\n",
      "Epoch 20; Step 540; Loss 0.458899; Train acc: 0.871094; Dev acc 0.718750\n",
      "Epoch 25; Step 675; Loss 0.417791; Train acc: 0.917969; Dev acc 0.734375\n",
      "Epoch 30; Step 810; Loss 0.398238; Train acc: 0.914062; Dev acc 0.753906\n",
      "Best dev accuracy is 0.77734375\n",
      "Best accuracy:  0.77734375\n",
      "354 / 576  =  (0.0001, 200, 128, 2, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693157; Train acc: 0.531250; Dev acc 0.480469\n",
      "Epoch 5; Step 135; Loss 0.688612; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.656755; Train acc: 0.695312; Dev acc 0.652344\n",
      "Epoch 15; Step 405; Loss 0.519640; Train acc: 0.816406; Dev acc 0.765625\n",
      "Epoch 20; Step 540; Loss 0.434359; Train acc: 0.886719; Dev acc 0.777344\n",
      "Epoch 25; Step 675; Loss 0.420652; Train acc: 0.929688; Dev acc 0.757812\n",
      "Epoch 30; Step 810; Loss 0.374999; Train acc: 0.925781; Dev acc 0.738281\n",
      "Best dev accuracy is 0.77734375\n",
      "Best accuracy:  0.77734375\n",
      "355 / 576  =  (0.0001, 200, 128, 2, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693087; Train acc: 0.539062; Dev acc 0.484375\n",
      "Epoch 5; Step 135; Loss 0.689759; Train acc: 0.503906; Dev acc 0.542969\n",
      "Epoch 10; Step 270; Loss 0.637655; Train acc: 0.687500; Dev acc 0.640625\n",
      "Epoch 15; Step 405; Loss 0.522117; Train acc: 0.855469; Dev acc 0.746094\n",
      "Epoch 20; Step 540; Loss 0.416481; Train acc: 0.886719; Dev acc 0.785156\n",
      "Epoch 25; Step 675; Loss 0.421124; Train acc: 0.894531; Dev acc 0.773438\n",
      "Epoch 30; Step 810; Loss 0.413339; Train acc: 0.929688; Dev acc 0.738281\n",
      "Best dev accuracy is 0.78515625\n",
      "Best accuracy:  0.78515625\n",
      "356 / 576  =  (0.0001, 200, 128, 2, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693178; Train acc: 0.503906; Dev acc 0.464844\n",
      "Epoch 5; Step 135; Loss 0.691664; Train acc: 0.496094; Dev acc 0.550781\n",
      "Epoch 10; Step 270; Loss 0.648169; Train acc: 0.628906; Dev acc 0.671875\n",
      "Epoch 15; Step 405; Loss 0.541186; Train acc: 0.820312; Dev acc 0.777344\n",
      "Epoch 20; Step 540; Loss 0.437155; Train acc: 0.894531; Dev acc 0.750000\n",
      "Epoch 25; Step 675; Loss 0.433413; Train acc: 0.878906; Dev acc 0.746094\n",
      "Epoch 30; Step 810; Loss 0.411081; Train acc: 0.906250; Dev acc 0.781250\n",
      "Best dev accuracy is 0.78125\n",
      "Best accuracy:  0.78125\n",
      "357 / 576  =  (0.0001, 200, 128, 2, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693138; Train acc: 0.515625; Dev acc 0.472656\n",
      "Epoch 5; Step 135; Loss 0.692812; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.657482; Train acc: 0.671875; Dev acc 0.613281\n",
      "Epoch 15; Step 405; Loss 0.531463; Train acc: 0.847656; Dev acc 0.742188\n",
      "Epoch 20; Step 540; Loss 0.462436; Train acc: 0.886719; Dev acc 0.769531\n",
      "Epoch 25; Step 675; Loss 0.434631; Train acc: 0.898438; Dev acc 0.738281\n",
      "Epoch 30; Step 810; Loss 0.411699; Train acc: 0.937500; Dev acc 0.765625\n",
      "Best dev accuracy is 0.76953125\n",
      "Best accuracy:  0.76953125\n",
      "358 / 576  =  (0.0001, 200, 128, 2, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693110; Train acc: 0.445312; Dev acc 0.460938\n",
      "Epoch 5; Step 135; Loss 0.693509; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.661706; Train acc: 0.566406; Dev acc 0.593750\n",
      "Epoch 15; Step 405; Loss 0.603517; Train acc: 0.730469; Dev acc 0.714844\n",
      "Epoch 20; Step 540; Loss 0.574223; Train acc: 0.804688; Dev acc 0.718750\n",
      "Epoch 25; Step 675; Loss 0.572977; Train acc: 0.871094; Dev acc 0.726562\n",
      "Epoch 30; Step 810; Loss 0.447727; Train acc: 0.882812; Dev acc 0.765625\n",
      "Best dev accuracy is 0.765625\n",
      "Best accuracy:  0.765625\n",
      "359 / 576  =  (0.0001, 200, 128, 2, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693155; Train acc: 0.492188; Dev acc 0.542969\n",
      "Epoch 5; Step 135; Loss 0.691572; Train acc: 0.503906; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.652197; Train acc: 0.621094; Dev acc 0.652344\n",
      "Epoch 15; Step 405; Loss 0.529894; Train acc: 0.796875; Dev acc 0.761719\n",
      "Epoch 20; Step 540; Loss 0.450120; Train acc: 0.898438; Dev acc 0.753906\n",
      "Epoch 25; Step 675; Loss 0.457652; Train acc: 0.894531; Dev acc 0.769531\n",
      "Epoch 30; Step 810; Loss 0.429538; Train acc: 0.890625; Dev acc 0.761719\n",
      "Best dev accuracy is 0.76953125\n",
      "Best accuracy:  0.76953125\n",
      "360 / 576  =  (0.0001, 200, 128, 3, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693079; Train acc: 0.496094; Dev acc 0.550781\n",
      "Epoch 5; Step 135; Loss 0.690130; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.604780; Train acc: 0.722656; Dev acc 0.691406\n",
      "Epoch 15; Step 405; Loss 0.430926; Train acc: 0.851562; Dev acc 0.773438\n",
      "Epoch 20; Step 540; Loss 0.397846; Train acc: 0.871094; Dev acc 0.738281\n",
      "Epoch 25; Step 675; Loss 0.395067; Train acc: 0.894531; Dev acc 0.777344\n",
      "Epoch 30; Step 810; Loss 0.388459; Train acc: 0.910156; Dev acc 0.761719\n",
      "Best dev accuracy is 0.77734375\n",
      "Best accuracy:  0.77734375\n",
      "361 / 576  =  (0.0001, 200, 128, 3, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693078; Train acc: 0.492188; Dev acc 0.554688\n",
      "Epoch 5; Step 135; Loss 0.688871; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.591278; Train acc: 0.714844; Dev acc 0.722656\n",
      "Epoch 15; Step 405; Loss 0.451133; Train acc: 0.875000; Dev acc 0.789062\n",
      "Epoch 20; Step 540; Loss 0.429865; Train acc: 0.871094; Dev acc 0.781250\n",
      "Epoch 25; Step 675; Loss 0.385390; Train acc: 0.910156; Dev acc 0.753906\n",
      "Epoch 30; Step 810; Loss 0.402187; Train acc: 0.894531; Dev acc 0.765625\n",
      "Best dev accuracy is 0.7890625\n",
      "Best accuracy:  0.7890625\n",
      "362 / 576  =  (0.0001, 200, 128, 3, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693151; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.691402; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.624265; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.578330; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.566687; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.542263; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.544590; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "363 / 576  =  (0.0001, 200, 128, 3, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693089; Train acc: 0.503906; Dev acc 0.539062\n",
      "Epoch 5; Step 135; Loss 0.689564; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.608462; Train acc: 0.703125; Dev acc 0.726562\n",
      "Epoch 15; Step 405; Loss 0.566841; Train acc: 0.863281; Dev acc 0.750000\n",
      "Epoch 20; Step 540; Loss 0.532999; Train acc: 0.878906; Dev acc 0.734375\n",
      "Epoch 25; Step 675; Loss 0.552739; Train acc: 0.875000; Dev acc 0.753906\n",
      "Epoch 30; Step 810; Loss 0.536198; Train acc: 0.937500; Dev acc 0.734375\n",
      "Best dev accuracy is 0.75390625\n",
      "Best accuracy:  0.75390625\n",
      "364 / 576  =  (0.0001, 200, 128, 3, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693144; Train acc: 0.496094; Dev acc 0.429688\n",
      "Epoch 5; Step 135; Loss 0.693257; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.635635; Train acc: 0.640625; Dev acc 0.625000\n",
      "Epoch 15; Step 405; Loss 0.488666; Train acc: 0.804688; Dev acc 0.785156\n",
      "Epoch 20; Step 540; Loss 0.415839; Train acc: 0.875000; Dev acc 0.746094\n",
      "Epoch 25; Step 675; Loss 0.392383; Train acc: 0.914062; Dev acc 0.773438\n",
      "Epoch 30; Step 810; Loss 0.362109; Train acc: 0.886719; Dev acc 0.781250\n",
      "Best dev accuracy is 0.78515625\n",
      "Best accuracy:  0.78515625\n",
      "365 / 576  =  (0.0001, 200, 128, 3, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693144; Train acc: 0.441406; Dev acc 0.496094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5; Step 135; Loss 0.690263; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.629636; Train acc: 0.601562; Dev acc 0.613281\n",
      "Epoch 15; Step 405; Loss 0.560352; Train acc: 0.843750; Dev acc 0.726562\n",
      "Epoch 20; Step 540; Loss 0.536522; Train acc: 0.847656; Dev acc 0.750000\n",
      "Epoch 25; Step 675; Loss 0.557449; Train acc: 0.871094; Dev acc 0.726562\n",
      "Epoch 30; Step 810; Loss 0.536065; Train acc: 0.894531; Dev acc 0.734375\n",
      "Best dev accuracy is 0.75\n",
      "Best accuracy:  0.75\n",
      "366 / 576  =  (0.0001, 200, 128, 3, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693153; Train acc: 0.527344; Dev acc 0.488281\n",
      "Epoch 5; Step 135; Loss 0.693080; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.680035; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.590532; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.565662; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.563018; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.540815; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.48828125\n",
      "Best accuracy:  0.48828125\n",
      "367 / 576  =  (0.0001, 200, 128, 3, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693197; Train acc: 0.519531; Dev acc 0.484375\n",
      "Epoch 5; Step 135; Loss 0.692209; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.640669; Train acc: 0.632812; Dev acc 0.671875\n",
      "Epoch 15; Step 405; Loss 0.498030; Train acc: 0.835938; Dev acc 0.808594\n",
      "Epoch 20; Step 540; Loss 0.414768; Train acc: 0.898438; Dev acc 0.746094\n",
      "Epoch 25; Step 675; Loss 0.386058; Train acc: 0.921875; Dev acc 0.742188\n",
      "Epoch 30; Step 810; Loss 0.376284; Train acc: 0.898438; Dev acc 0.761719\n",
      "Best dev accuracy is 0.80859375\n",
      "Best accuracy:  0.80859375\n",
      "368 / 576  =  (0.0001, 200, 128, 4, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693137; Train acc: 0.523438; Dev acc 0.542969\n",
      "Epoch 5; Step 135; Loss 0.693070; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.599922; Train acc: 0.714844; Dev acc 0.644531\n",
      "Epoch 15; Step 405; Loss 0.573945; Train acc: 0.812500; Dev acc 0.753906\n",
      "Epoch 20; Step 540; Loss 0.542439; Train acc: 0.867188; Dev acc 0.757812\n",
      "Epoch 25; Step 675; Loss 0.511158; Train acc: 0.914062; Dev acc 0.761719\n",
      "Epoch 30; Step 810; Loss 0.530660; Train acc: 0.933594; Dev acc 0.718750\n",
      "Best dev accuracy is 0.76171875\n",
      "Best accuracy:  0.76171875\n",
      "369 / 576  =  (0.0001, 200, 128, 4, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693151; Train acc: 0.503906; Dev acc 0.570312\n",
      "Epoch 5; Step 135; Loss 0.692020; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.573737; Train acc: 0.769531; Dev acc 0.730469\n",
      "Epoch 15; Step 405; Loss 0.455970; Train acc: 0.871094; Dev acc 0.773438\n",
      "Epoch 20; Step 540; Loss 0.412389; Train acc: 0.902344; Dev acc 0.796875\n",
      "Epoch 25; Step 675; Loss 0.390935; Train acc: 0.890625; Dev acc 0.746094\n",
      "Epoch 30; Step 810; Loss 0.374044; Train acc: 0.906250; Dev acc 0.738281\n",
      "Best dev accuracy is 0.796875\n",
      "Best accuracy:  0.796875\n",
      "370 / 576  =  (0.0001, 200, 128, 4, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693134; Train acc: 0.488281; Dev acc 0.554688\n",
      "Epoch 5; Step 135; Loss 0.689299; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.607719; Train acc: 0.761719; Dev acc 0.707031\n",
      "Epoch 15; Step 405; Loss 0.587072; Train acc: 0.839844; Dev acc 0.746094\n",
      "Epoch 20; Step 540; Loss 0.556729; Train acc: 0.878906; Dev acc 0.750000\n",
      "Epoch 25; Step 675; Loss 0.536983; Train acc: 0.882812; Dev acc 0.730469\n",
      "Epoch 30; Step 810; Loss 0.544171; Train acc: 0.910156; Dev acc 0.753906\n",
      "Best dev accuracy is 0.75390625\n",
      "Best accuracy:  0.75390625\n",
      "371 / 576  =  (0.0001, 200, 128, 4, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693150; Train acc: 0.496094; Dev acc 0.468750\n",
      "Epoch 5; Step 135; Loss 0.687820; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.610004; Train acc: 0.710938; Dev acc 0.683594\n",
      "Epoch 15; Step 405; Loss 0.539688; Train acc: 0.843750; Dev acc 0.753906\n",
      "Epoch 20; Step 540; Loss 0.554961; Train acc: 0.890625; Dev acc 0.730469\n",
      "Epoch 25; Step 675; Loss 0.548614; Train acc: 0.898438; Dev acc 0.777344\n",
      "Epoch 30; Step 810; Loss 0.526940; Train acc: 0.886719; Dev acc 0.718750\n",
      "Best dev accuracy is 0.77734375\n",
      "Best accuracy:  0.77734375\n",
      "372 / 576  =  (0.0001, 200, 128, 4, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693161; Train acc: 0.484375; Dev acc 0.441406\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "373 / 576  =  (0.0001, 200, 128, 4, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693172; Train acc: 0.507812; Dev acc 0.480469\n",
      "Epoch 5; Step 135; Loss 0.687423; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.592584; Train acc: 0.707031; Dev acc 0.707031\n",
      "Epoch 15; Step 405; Loss 0.433143; Train acc: 0.855469; Dev acc 0.718750\n",
      "Epoch 20; Step 540; Loss 0.433857; Train acc: 0.890625; Dev acc 0.750000\n",
      "Epoch 25; Step 675; Loss 0.389619; Train acc: 0.894531; Dev acc 0.765625\n",
      "Epoch 30; Step 810; Loss 0.382238; Train acc: 0.925781; Dev acc 0.734375\n",
      "Best dev accuracy is 0.765625\n",
      "Best accuracy:  0.765625\n",
      "374 / 576  =  (0.0001, 200, 128, 4, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.511719; Dev acc 0.472656\n",
      "Epoch 5; Step 135; Loss 0.689768; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.611782; Train acc: 0.683594; Dev acc 0.687500\n",
      "Epoch 15; Step 405; Loss 0.563678; Train acc: 0.851562; Dev acc 0.710938\n",
      "Epoch 20; Step 540; Loss 0.568257; Train acc: 0.851562; Dev acc 0.714844\n",
      "Epoch 25; Step 675; Loss 0.539491; Train acc: 0.898438; Dev acc 0.761719\n",
      "Epoch 30; Step 810; Loss 0.558101; Train acc: 0.890625; Dev acc 0.746094\n",
      "Best dev accuracy is 0.76171875\n",
      "Best accuracy:  0.76171875\n",
      "375 / 576  =  (0.0001, 200, 128, 4, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693145; Train acc: 0.527344; Dev acc 0.445312\n",
      "Epoch 5; Step 135; Loss 0.687474; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.626297; Train acc: 0.710938; Dev acc 0.691406\n",
      "Epoch 15; Step 405; Loss 0.571904; Train acc: 0.804688; Dev acc 0.757812\n",
      "Epoch 20; Step 540; Loss 0.534914; Train acc: 0.886719; Dev acc 0.746094\n",
      "Epoch 25; Step 675; Loss 0.555051; Train acc: 0.882812; Dev acc 0.789062\n",
      "Epoch 30; Step 810; Loss 0.535678; Train acc: 0.921875; Dev acc 0.742188\n",
      "Best dev accuracy is 0.7890625\n",
      "Best accuracy:  0.7890625\n",
      "376 / 576  =  (0.0001, 200, 128, 5, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693149; Train acc: 0.492188; Dev acc 0.539062\n",
      "Epoch 5; Step 135; Loss 0.688690; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.524832; Train acc: 0.773438; Dev acc 0.769531\n",
      "Epoch 15; Step 405; Loss 0.457041; Train acc: 0.878906; Dev acc 0.765625\n",
      "Epoch 20; Step 540; Loss 0.399793; Train acc: 0.894531; Dev acc 0.769531\n",
      "Epoch 25; Step 675; Loss 0.407221; Train acc: 0.910156; Dev acc 0.746094\n",
      "Epoch 30; Step 810; Loss 0.400084; Train acc: 0.898438; Dev acc 0.796875\n",
      "Best dev accuracy is 0.796875\n",
      "Best accuracy:  0.796875\n",
      "377 / 576  =  (0.0001, 200, 128, 5, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693154; Train acc: 0.519531; Dev acc 0.488281\n",
      "Epoch 5; Step 135; Loss 0.685081; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.585357; Train acc: 0.750000; Dev acc 0.746094\n",
      "Epoch 15; Step 405; Loss 0.566484; Train acc: 0.863281; Dev acc 0.765625\n",
      "Epoch 20; Step 540; Loss 0.551476; Train acc: 0.828125; Dev acc 0.738281\n",
      "Epoch 25; Step 675; Loss 0.543493; Train acc: 0.910156; Dev acc 0.730469\n",
      "Epoch 30; Step 810; Loss 0.553675; Train acc: 0.906250; Dev acc 0.699219\n",
      "Best dev accuracy is 0.765625\n",
      "Best accuracy:  0.765625\n",
      "378 / 576  =  (0.0001, 200, 128, 5, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.496094; Dev acc 0.550781\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.55078125\n",
      "Best accuracy:  0.55078125\n",
      "379 / 576  =  (0.0001, 200, 128, 5, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.500000; Dev acc 0.554688\n",
      "Epoch 5; Step 135; Loss 0.690294; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.593763; Train acc: 0.769531; Dev acc 0.734375\n",
      "Epoch 15; Step 405; Loss 0.573620; Train acc: 0.843750; Dev acc 0.738281\n",
      "Epoch 20; Step 540; Loss 0.550162; Train acc: 0.886719; Dev acc 0.730469\n",
      "Epoch 25; Step 675; Loss 0.553860; Train acc: 0.867188; Dev acc 0.746094\n",
      "Epoch 30; Step 810; Loss 0.530023; Train acc: 0.878906; Dev acc 0.753906\n",
      "Best dev accuracy is 0.75390625\n",
      "Best accuracy:  0.75390625\n",
      "380 / 576  =  (0.0001, 200, 128, 5, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.507812; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.690386; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.622797; Train acc: 0.750000; Dev acc 0.652344\n",
      "Epoch 15; Step 405; Loss 0.540252; Train acc: 0.847656; Dev acc 0.750000\n",
      "Epoch 20; Step 540; Loss 0.549997; Train acc: 0.875000; Dev acc 0.792969\n",
      "Epoch 25; Step 675; Loss 0.562667; Train acc: 0.894531; Dev acc 0.750000\n",
      "Epoch 30; Step 810; Loss 0.523129; Train acc: 0.886719; Dev acc 0.750000\n",
      "Best dev accuracy is 0.79296875\n",
      "Best accuracy:  0.79296875\n",
      "381 / 576  =  (0.0001, 200, 128, 5, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.480469; Dev acc 0.464844\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.46484375\n",
      "Best accuracy:  0.46484375\n",
      "382 / 576  =  (0.0001, 200, 128, 5, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693142; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "383 / 576  =  (0.0001, 200, 128, 5, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693148; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.682863; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.603281; Train acc: 0.742188; Dev acc 0.699219\n",
      "Epoch 15; Step 405; Loss 0.569747; Train acc: 0.812500; Dev acc 0.722656\n",
      "Epoch 20; Step 540; Loss 0.529079; Train acc: 0.851562; Dev acc 0.785156\n",
      "Epoch 25; Step 675; Loss 0.552517; Train acc: 0.875000; Dev acc 0.765625\n",
      "Epoch 30; Step 810; Loss 0.515307; Train acc: 0.914062; Dev acc 0.765625\n",
      "Best dev accuracy is 0.78515625\n",
      "Best accuracy:  0.78515625\n",
      "384 / 576  =  (1e-05, 10, 64, 2, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693148; Train acc: 0.464844; Dev acc 0.464844\n",
      "Epoch 5; Step 135; Loss 0.693155; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693204; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693230; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693121; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692945; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.692967; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "385 / 576  =  (1e-05, 10, 64, 2, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693151; Train acc: 0.472656; Dev acc 0.445312\n",
      "Epoch 5; Step 135; Loss 0.693070; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693066; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693069; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.692921; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.693043; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.693005; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "386 / 576  =  (1e-05, 10, 64, 2, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693169; Train acc: 0.476562; Dev acc 0.539062\n",
      "Epoch 5; Step 135; Loss 0.693038; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693070; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693174; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693030; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.693258; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.693494; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "387 / 576  =  (1e-05, 10, 64, 2, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693149; Train acc: 0.539062; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.693135; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693200; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.692993; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693014; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.693310; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.692909; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "388 / 576  =  (1e-05, 10, 64, 2, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693143; Train acc: 0.511719; Dev acc 0.550781\n",
      "Epoch 5; Step 135; Loss 0.693057; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693120; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693154; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.692914; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.693209; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.692966; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.55078125\n",
      "Best accuracy:  0.55078125\n",
      "389 / 576  =  (1e-05, 10, 64, 2, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693137; Train acc: 0.480469; Dev acc 0.574219\n",
      "Epoch 5; Step 135; Loss 0.693096; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693052; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.692968; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693047; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692883; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.692851; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.57421875\n",
      "Best accuracy:  0.57421875\n",
      "390 / 576  =  (1e-05, 10, 64, 2, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.550781; Dev acc 0.476562\n",
      "Epoch 5; Step 135; Loss 0.693136; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693052; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693019; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693150; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692929; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.693059; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "391 / 576  =  (1e-05, 10, 64, 2, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693161; Train acc: 0.507812; Dev acc 0.492188\n",
      "Epoch 5; Step 135; Loss 0.693159; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693172; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.692957; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693037; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.693009; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.693142; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "392 / 576  =  (1e-05, 10, 64, 3, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693148; Train acc: 0.535156; Dev acc 0.503906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5; Step 135; Loss 0.693128; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.692963; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.692999; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693086; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.693042; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.693174; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "393 / 576  =  (1e-05, 10, 64, 3, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693148; Train acc: 0.500000; Dev acc 0.457031\n",
      "Epoch 5; Step 135; Loss 0.693147; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693147; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693147; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693142; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693143; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693130; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.45703125\n",
      "Best accuracy:  0.45703125\n",
      "394 / 576  =  (1e-05, 10, 64, 3, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693150; Train acc: 0.484375; Dev acc 0.515625\n",
      "Epoch 5; Step 135; Loss 0.693124; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693037; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693188; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693165; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692871; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.693374; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "395 / 576  =  (1e-05, 10, 64, 3, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693151; Train acc: 0.496094; Dev acc 0.527344\n",
      "Epoch 5; Step 135; Loss 0.693108; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693206; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693132; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693103; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692915; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.693316; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "396 / 576  =  (1e-05, 10, 64, 3, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.523438; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693143; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693055; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693100; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693217; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692952; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.693175; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "397 / 576  =  (1e-05, 10, 64, 3, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693148; Train acc: 0.488281; Dev acc 0.519531\n",
      "Epoch 5; Step 135; Loss 0.693210; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693121; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693052; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693038; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.693007; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.692711; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "398 / 576  =  (1e-05, 10, 64, 3, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693149; Train acc: 0.511719; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693100; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693027; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693049; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693012; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692655; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.692672; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "399 / 576  =  (1e-05, 10, 64, 3, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693148; Train acc: 0.472656; Dev acc 0.527344\n",
      "Epoch 5; Step 135; Loss 0.693187; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693020; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693129; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693220; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692944; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.693117; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "400 / 576  =  (1e-05, 10, 64, 4, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.511719; Dev acc 0.535156\n",
      "Epoch 5; Step 135; Loss 0.693165; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693120; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693083; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693154; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692824; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.692862; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "401 / 576  =  (1e-05, 10, 64, 4, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.457031; Dev acc 0.558594\n",
      "Epoch 5; Step 135; Loss 0.693081; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693106; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.692998; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.692868; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692951; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.692894; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.55859375\n",
      "Best accuracy:  0.55859375\n",
      "402 / 576  =  (1e-05, 10, 64, 4, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.484375; Dev acc 0.535156\n",
      "Epoch 5; Step 135; Loss 0.693210; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693073; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693038; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693168; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692718; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.692929; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "403 / 576  =  (1e-05, 10, 64, 4, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.480469; Dev acc 0.550781\n",
      "Epoch 5; Step 135; Loss 0.693083; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693104; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693307; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693001; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692887; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.692903; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.55078125\n",
      "Best accuracy:  0.55078125\n",
      "404 / 576  =  (1e-05, 10, 64, 4, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.503906; Dev acc 0.460938\n",
      "Epoch 5; Step 135; Loss 0.693115; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693184; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693052; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.692914; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692976; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.693026; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "405 / 576  =  (1e-05, 10, 64, 4, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.500000; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.693096; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693237; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693003; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.692985; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.693198; Train acc: 0.496094; Dev acc 0.546875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30; Step 810; Loss 0.692849; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "406 / 576  =  (1e-05, 10, 64, 4, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693149; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "407 / 576  =  (1e-05, 10, 64, 4, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.496094; Dev acc 0.527344\n",
      "Epoch 5; Step 135; Loss 0.693147; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693184; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693077; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.692912; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692946; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.693121; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "408 / 576  =  (1e-05, 10, 64, 5, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693148; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.693131; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693185; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693092; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.692879; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.693160; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.692739; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "409 / 576  =  (1e-05, 10, 64, 5, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "410 / 576  =  (1e-05, 10, 64, 5, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.484375; Dev acc 0.425781\n",
      "Epoch 5; Step 135; Loss 0.693110; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693027; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.692936; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.692998; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692919; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.692374; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "411 / 576  =  (1e-05, 10, 64, 5, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "412 / 576  =  (1e-05, 10, 64, 5, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.496094; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "413 / 576  =  (1e-05, 10, 64, 5, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 5; Step 135; Loss 0.693032; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693109; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693133; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693214; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692623; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.692693; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "414 / 576  =  (1e-05, 10, 64, 5, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "415 / 576  =  (1e-05, 10, 64, 5, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.492188; Dev acc 0.550781\n",
      "Epoch 5; Step 135; Loss 0.693052; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693136; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693167; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693178; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.693190; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.692690; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.55078125\n",
      "Best accuracy:  0.55078125\n",
      "416 / 576  =  (1e-05, 10, 128, 2, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693148; Train acc: 0.503906; Dev acc 0.437500\n",
      "Epoch 5; Step 135; Loss 0.693147; Train acc: 0.507812; Dev acc 0.449219\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.507812; Dev acc 0.460938\n",
      "Epoch 15; Step 405; Loss 0.693133; Train acc: 0.535156; Dev acc 0.511719\n",
      "Epoch 20; Step 540; Loss 0.693093; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692827; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.692587; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "417 / 576  =  (1e-05, 10, 128, 2, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693141; Train acc: 0.535156; Dev acc 0.468750\n",
      "Epoch 5; Step 135; Loss 0.693011; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693040; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.692837; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693109; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692853; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.692542; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "418 / 576  =  (1e-05, 10, 128, 2, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693143; Train acc: 0.527344; Dev acc 0.519531\n",
      "Epoch 5; Step 135; Loss 0.693151; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693066; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.692962; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693107; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692266; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.693498; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "419 / 576  =  (1e-05, 10, 128, 2, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693188; Train acc: 0.496094; Dev acc 0.449219\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.558594; Dev acc 0.453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10; Step 270; Loss 0.693053; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.692920; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.692893; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692708; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.693433; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "420 / 576  =  (1e-05, 10, 128, 2, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693153; Train acc: 0.511719; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693061; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.692932; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.692901; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693505; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.693067; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.691953; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "421 / 576  =  (1e-05, 10, 128, 2, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693142; Train acc: 0.554688; Dev acc 0.535156\n",
      "Epoch 5; Step 135; Loss 0.693031; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693243; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693247; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693316; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692928; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.692121; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "422 / 576  =  (1e-05, 10, 128, 2, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693150; Train acc: 0.554688; Dev acc 0.527344\n",
      "Epoch 5; Step 135; Loss 0.693041; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693009; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.692588; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.692598; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.693671; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.692427; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "423 / 576  =  (1e-05, 10, 128, 2, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693168; Train acc: 0.500000; Dev acc 0.539062\n",
      "Epoch 5; Step 135; Loss 0.693129; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.692996; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693127; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.692898; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.693030; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.692660; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "424 / 576  =  (1e-05, 10, 128, 3, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.492188; Dev acc 0.460938\n",
      "Epoch 5; Step 135; Loss 0.693144; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693051; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.692573; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.692614; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.693058; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.693069; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "425 / 576  =  (1e-05, 10, 128, 3, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.500000; Dev acc 0.457031\n",
      "Epoch 5; Step 135; Loss 0.693069; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693018; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.692969; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.692549; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.693173; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.693467; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "426 / 576  =  (1e-05, 10, 128, 3, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693145; Train acc: 0.503906; Dev acc 0.468750\n",
      "Epoch 5; Step 135; Loss 0.693094; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693177; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.692936; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693136; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692690; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.692877; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "427 / 576  =  (1e-05, 10, 128, 3, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693152; Train acc: 0.492188; Dev acc 0.531250\n",
      "Epoch 5; Step 135; Loss 0.693048; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.692919; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.692790; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693009; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.693535; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.692633; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "428 / 576  =  (1e-05, 10, 128, 3, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693145; Train acc: 0.527344; Dev acc 0.492188\n",
      "Epoch 5; Step 135; Loss 0.693175; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693138; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693148; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.692418; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.693658; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.693189; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "429 / 576  =  (1e-05, 10, 128, 3, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693154; Train acc: 0.531250; Dev acc 0.550781\n",
      "Epoch 5; Step 135; Loss 0.692982; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.692960; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693025; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.692678; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692441; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.693071; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.55078125\n",
      "Best accuracy:  0.55078125\n",
      "430 / 576  =  (1e-05, 10, 128, 3, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693140; Train acc: 0.464844; Dev acc 0.531250\n",
      "Epoch 5; Step 135; Loss 0.693113; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.692973; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693322; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.692715; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692514; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.692587; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "431 / 576  =  (1e-05, 10, 128, 3, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.531250; Dev acc 0.488281\n",
      "Epoch 5; Step 135; Loss 0.693227; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693064; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.692899; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.692760; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692757; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.692208; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "432 / 576  =  (1e-05, 10, 128, 4, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.507812; Dev acc 0.449219\n",
      "Epoch 5; Step 135; Loss 0.693145; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.692952; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693183; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693654; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.691817; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.693867; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "433 / 576  =  (1e-05, 10, 128, 4, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.519531; Dev acc 0.445312\n",
      "Epoch 5; Step 135; Loss 0.693133; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.692965; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.692936; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693518; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692668; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.691935; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "434 / 576  =  (1e-05, 10, 128, 4, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693150; Train acc: 0.488281; Dev acc 0.500000\n",
      "Epoch 5; Step 135; Loss 0.693127; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693072; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.692788; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.692543; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.691482; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.693307; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "435 / 576  =  (1e-05, 10, 128, 4, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.531250; Dev acc 0.480469\n",
      "Epoch 5; Step 135; Loss 0.693060; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693196; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.692819; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693024; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.693083; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.693041; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "436 / 576  =  (1e-05, 10, 128, 4, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693144; Train acc: 0.472656; Dev acc 0.550781\n",
      "Epoch 5; Step 135; Loss 0.693172; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693061; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.692977; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.692666; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.693684; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.692923; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.55078125\n",
      "Best accuracy:  0.55078125\n",
      "437 / 576  =  (1e-05, 10, 128, 4, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693158; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693199; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693167; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693030; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.693061; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.692945; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "438 / 576  =  (1e-05, 10, 128, 4, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.492188; Dev acc 0.464844\n",
      "Epoch 5; Step 135; Loss 0.693039; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693130; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693139; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.692858; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692871; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.694268; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "439 / 576  =  (1e-05, 10, 128, 4, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693145; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693179; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.692974; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.692917; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693045; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.693009; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.692473; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "440 / 576  =  (1e-05, 10, 128, 5, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.492188; Dev acc 0.472656\n",
      "Epoch 5; Step 135; Loss 0.693088; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693126; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.692557; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.691684; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692708; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.692158; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "441 / 576  =  (1e-05, 10, 128, 5, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693148; Train acc: 0.507812; Dev acc 0.542969\n",
      "Epoch 5; Step 135; Loss 0.693136; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.692874; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693108; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693831; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692562; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.694174; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "442 / 576  =  (1e-05, 10, 128, 5, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "443 / 576  =  (1e-05, 10, 128, 5, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.507812; Dev acc 0.472656\n",
      "Epoch 5; Step 135; Loss 0.693117; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693076; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.692999; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.692280; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.691829; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.691943; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "444 / 576  =  (1e-05, 10, 128, 5, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693149; Train acc: 0.496094; Dev acc 0.492188\n",
      "Epoch 5; Step 135; Loss 0.693115; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.692969; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693400; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.692886; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.691545; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.692234; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "445 / 576  =  (1e-05, 10, 128, 5, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.511719; Dev acc 0.578125\n",
      "Epoch 5; Step 135; Loss 0.692989; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.692945; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.692837; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693009; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.693547; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.692528; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.578125\n",
      "Best accuracy:  0.578125\n",
      "446 / 576  =  (1e-05, 10, 128, 5, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693148; Train acc: 0.503906; Dev acc 0.457031\n",
      "Epoch 5; Step 135; Loss 0.693110; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693102; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693446; Train acc: 0.496094; Dev acc 0.546875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20; Step 540; Loss 0.692877; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.693103; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.692170; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "447 / 576  =  (1e-05, 10, 128, 5, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693148; Train acc: 0.507812; Dev acc 0.449219\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "448 / 576  =  (1e-05, 50, 64, 2, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693129; Train acc: 0.445312; Dev acc 0.500000\n",
      "Epoch 5; Step 135; Loss 0.693085; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693177; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693206; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693061; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.693162; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.693131; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "449 / 576  =  (1e-05, 50, 64, 2, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693125; Train acc: 0.484375; Dev acc 0.554688\n",
      "Epoch 5; Step 135; Loss 0.693136; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.692990; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693192; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693120; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692828; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.693074; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.5546875\n",
      "Best accuracy:  0.5546875\n",
      "450 / 576  =  (1e-05, 50, 64, 2, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693140; Train acc: 0.535156; Dev acc 0.531250\n",
      "Epoch 5; Step 135; Loss 0.693094; Train acc: 0.500000; Dev acc 0.550781\n",
      "Epoch 10; Step 270; Loss 0.692991; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693128; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693097; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692977; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.692716; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.55078125\n",
      "Best accuracy:  0.55078125\n",
      "451 / 576  =  (1e-05, 50, 64, 2, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693149; Train acc: 0.542969; Dev acc 0.507812\n",
      "Epoch 5; Step 135; Loss 0.693081; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693021; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.692960; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.692899; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692677; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.692799; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "452 / 576  =  (1e-05, 50, 64, 2, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693127; Train acc: 0.480469; Dev acc 0.535156\n",
      "Epoch 5; Step 135; Loss 0.693125; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693191; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693180; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693032; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.693014; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.693304; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "453 / 576  =  (1e-05, 50, 64, 2, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693158; Train acc: 0.507812; Dev acc 0.457031\n",
      "Epoch 5; Step 135; Loss 0.693109; Train acc: 0.484375; Dev acc 0.554688\n",
      "Epoch 10; Step 270; Loss 0.693147; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693135; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693093; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.693063; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.692605; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.5546875\n",
      "Best accuracy:  0.5546875\n",
      "454 / 576  =  (1e-05, 50, 64, 2, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.500000; Dev acc 0.468750\n",
      "Epoch 5; Step 135; Loss 0.693139; Train acc: 0.511719; Dev acc 0.496094\n",
      "Epoch 10; Step 270; Loss 0.693046; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693076; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693157; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.693098; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.693149; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "455 / 576  =  (1e-05, 50, 64, 2, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693182; Train acc: 0.531250; Dev acc 0.480469\n",
      "Epoch 5; Step 135; Loss 0.693169; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693204; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693140; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693076; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.693264; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.693542; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "456 / 576  =  (1e-05, 50, 64, 3, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693145; Train acc: 0.484375; Dev acc 0.476562\n",
      "Epoch 5; Step 135; Loss 0.693140; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693076; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693300; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.692746; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692872; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.693084; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "457 / 576  =  (1e-05, 50, 64, 3, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693153; Train acc: 0.500000; Dev acc 0.457031\n",
      "Epoch 5; Step 135; Loss 0.693167; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693071; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693163; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693188; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.693195; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.693117; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "458 / 576  =  (1e-05, 50, 64, 3, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.507812; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693144; Train acc: 0.519531; Dev acc 0.507812\n",
      "Epoch 10; Step 270; Loss 0.693171; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693035; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693284; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692932; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.692789; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "459 / 576  =  (1e-05, 50, 64, 3, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693155; Train acc: 0.511719; Dev acc 0.460938\n",
      "Epoch 5; Step 135; Loss 0.693128; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693134; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.692966; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.692542; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692904; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.693092; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "460 / 576  =  (1e-05, 50, 64, 3, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693141; Train acc: 0.480469; Dev acc 0.550781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5; Step 135; Loss 0.693179; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693079; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.692878; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693023; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692773; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.692633; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.55078125\n",
      "Best accuracy:  0.55078125\n",
      "461 / 576  =  (1e-05, 50, 64, 3, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693152; Train acc: 0.460938; Dev acc 0.476562\n",
      "Epoch 5; Step 135; Loss 0.693124; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693129; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693145; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693038; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.693018; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.692942; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "462 / 576  =  (1e-05, 50, 64, 3, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693144; Train acc: 0.503906; Dev acc 0.511719\n",
      "Epoch 5; Step 135; Loss 0.693178; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693266; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693201; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693199; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.693233; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.692912; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "463 / 576  =  (1e-05, 50, 64, 3, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693141; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693116; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693104; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693069; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693162; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.693234; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.693241; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "464 / 576  =  (1e-05, 50, 64, 4, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.507812; Dev acc 0.492188\n",
      "Epoch 5; Step 135; Loss 0.693109; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693210; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.692848; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693085; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692856; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.693448; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "465 / 576  =  (1e-05, 50, 64, 4, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693142; Train acc: 0.492188; Dev acc 0.531250\n",
      "Epoch 5; Step 135; Loss 0.693106; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693112; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693161; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.692933; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.693041; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.693144; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "466 / 576  =  (1e-05, 50, 64, 4, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.488281; Dev acc 0.449219\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.457031\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.527344; Dev acc 0.429688\n",
      "Epoch 25; Step 675; Loss 0.693229; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.693290; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "467 / 576  =  (1e-05, 50, 64, 4, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.535156; Dev acc 0.437500\n",
      "Epoch 5; Step 135; Loss 0.693084; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693068; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.692928; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.692646; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692860; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.692453; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "468 / 576  =  (1e-05, 50, 64, 4, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.496094; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "469 / 576  =  (1e-05, 50, 64, 4, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693148; Train acc: 0.531250; Dev acc 0.476562\n",
      "Epoch 5; Step 135; Loss 0.693120; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693101; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693163; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.692988; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.693124; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.693110; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "470 / 576  =  (1e-05, 50, 64, 4, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.535156; Dev acc 0.558594\n",
      "Epoch 5; Step 135; Loss 0.693129; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.692998; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.692898; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.692557; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.693214; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.692787; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.55859375\n",
      "Best accuracy:  0.55859375\n",
      "471 / 576  =  (1e-05, 50, 64, 4, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693149; Train acc: 0.429688; Dev acc 0.449219\n",
      "Epoch 5; Step 135; Loss 0.693144; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693123; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.692907; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693108; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.693099; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.692866; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "472 / 576  =  (1e-05, 50, 64, 5, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693065; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.692999; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.693107; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.693035; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "473 / 576  =  (1e-05, 50, 64, 5, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "474 / 576  =  (1e-05, 50, 64, 5, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.488281; Dev acc 0.449219\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "475 / 576  =  (1e-05, 50, 64, 5, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.527344; Dev acc 0.464844\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.46484375\n",
      "Best accuracy:  0.46484375\n",
      "476 / 576  =  (1e-05, 50, 64, 5, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.523438; Dev acc 0.539062\n",
      "Epoch 5; Step 135; Loss 0.693147; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693022; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.692997; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693172; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692597; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.692875; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "477 / 576  =  (1e-05, 50, 64, 5, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.503906; Dev acc 0.503906\n",
      "Epoch 5; Step 135; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693146; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.50390625\n",
      "Best accuracy:  0.50390625\n",
      "478 / 576  =  (1e-05, 50, 64, 5, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.484375; Dev acc 0.542969\n",
      "Epoch 5; Step 135; Loss 0.693158; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693079; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693060; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.692804; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.693254; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.692450; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "479 / 576  =  (1e-05, 50, 64, 5, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.496094; Dev acc 0.550781\n",
      "Epoch 5; Step 135; Loss 0.693139; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693132; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693089; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.692986; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692767; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.693398; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.55078125\n",
      "Best accuracy:  0.55078125\n",
      "480 / 576  =  (1e-05, 50, 128, 2, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693128; Train acc: 0.511719; Dev acc 0.507812\n",
      "Epoch 5; Step 135; Loss 0.693079; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.692999; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.692853; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693592; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.691960; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.693456; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "481 / 576  =  (1e-05, 50, 128, 2, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693158; Train acc: 0.492188; Dev acc 0.515625\n",
      "Epoch 5; Step 135; Loss 0.693147; Train acc: 0.496094; Dev acc 0.550781\n",
      "Epoch 10; Step 270; Loss 0.692843; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.692965; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693332; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692645; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.692865; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.55078125\n",
      "Best accuracy:  0.55078125\n",
      "482 / 576  =  (1e-05, 50, 128, 2, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693099; Train acc: 0.527344; Dev acc 0.531250\n",
      "Epoch 5; Step 135; Loss 0.693141; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.692863; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693238; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.692006; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.693761; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.693497; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "483 / 576  =  (1e-05, 50, 128, 2, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693137; Train acc: 0.492188; Dev acc 0.441406\n",
      "Epoch 5; Step 135; Loss 0.693106; Train acc: 0.554688; Dev acc 0.527344\n",
      "Epoch 10; Step 270; Loss 0.692971; Train acc: 0.496094; Dev acc 0.542969\n",
      "Epoch 15; Step 405; Loss 0.692980; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693303; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692809; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.693380; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "484 / 576  =  (1e-05, 50, 128, 2, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693216; Train acc: 0.488281; Dev acc 0.515625\n",
      "Epoch 5; Step 135; Loss 0.693119; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693072; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.692769; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693427; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692532; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.692901; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "485 / 576  =  (1e-05, 50, 128, 2, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693136; Train acc: 0.507812; Dev acc 0.476562\n",
      "Epoch 5; Step 135; Loss 0.693174; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693036; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693225; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.692594; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692575; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.692572; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "486 / 576  =  (1e-05, 50, 128, 2, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693153; Train acc: 0.503906; Dev acc 0.437500\n",
      "Epoch 5; Step 135; Loss 0.693142; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 10; Step 270; Loss 0.693129; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 15; Step 405; Loss 0.693115; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 20; Step 540; Loss 0.693124; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 25; Step 675; Loss 0.693123; Train acc: 0.503906; Dev acc 0.453125\n",
      "Epoch 30; Step 810; Loss 0.693112; Train acc: 0.503906; Dev acc 0.453125\n",
      "Best dev accuracy is 0.453125\n",
      "Best accuracy:  0.453125\n",
      "487 / 576  =  (1e-05, 50, 128, 2, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693221; Train acc: 0.476562; Dev acc 0.542969\n",
      "Epoch 5; Step 135; Loss 0.693088; Train acc: 0.496094; Dev acc 0.546875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10; Step 270; Loss 0.692638; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.692959; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693457; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692280; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.693110; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "488 / 576  =  (1e-05, 50, 128, 3, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693148; Train acc: 0.546875; Dev acc 0.484375\n",
      "Epoch 5; Step 135; Loss 0.693102; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.692919; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693269; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.692482; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692669; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.693536; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "489 / 576  =  (1e-05, 50, 128, 3, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693154; Train acc: 0.480469; Dev acc 0.464844\n",
      "Epoch 5; Step 135; Loss 0.693078; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693117; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.692711; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693107; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692676; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.692554; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "490 / 576  =  (1e-05, 50, 128, 3, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693160; Train acc: 0.546875; Dev acc 0.460938\n",
      "Epoch 5; Step 135; Loss 0.693122; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693101; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.692995; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693682; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.693055; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.693388; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "491 / 576  =  (1e-05, 50, 128, 3, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693154; Train acc: 0.476562; Dev acc 0.472656\n",
      "Epoch 5; Step 135; Loss 0.693074; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.692818; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.692924; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.692822; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.693157; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.692339; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "492 / 576  =  (1e-05, 50, 128, 3, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693148; Train acc: 0.457031; Dev acc 0.523438\n",
      "Epoch 5; Step 135; Loss 0.693175; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.692849; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.692610; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.692959; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692801; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.692270; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "493 / 576  =  (1e-05, 50, 128, 3, 1e-05, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693133; Train acc: 0.542969; Dev acc 0.535156\n",
      "Epoch 5; Step 135; Loss 0.693100; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693131; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.692912; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693157; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692816; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.692525; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "494 / 576  =  (1e-05, 50, 128, 3, 1e-05, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693153; Train acc: 0.496094; Dev acc 0.460938\n",
      "Epoch 5; Step 135; Loss 0.693121; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693027; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.692932; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.692857; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692541; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.691700; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "495 / 576  =  (1e-05, 50, 128, 3, 1e-05, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.500000; Dev acc 0.460938\n",
      "Epoch 5; Step 135; Loss 0.693147; Train acc: 0.503906; Dev acc 0.449219\n",
      "Epoch 10; Step 270; Loss 0.693352; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693023; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.692962; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.693175; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.692688; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "496 / 576  =  (1e-05, 50, 128, 4, 1e-08, 0)\n",
      "Epoch 0; Step 0; Loss 0.693146; Train acc: 0.523438; Dev acc 0.460938\n",
      "Epoch 5; Step 135; Loss 0.693116; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693151; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693190; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.692744; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692147; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.693521; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "497 / 576  =  (1e-05, 50, 128, 4, 1e-08, 0.1)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.515625; Dev acc 0.464844\n",
      "Epoch 5; Step 135; Loss 0.693086; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.692964; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.692821; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.692875; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.693383; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.692672; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "498 / 576  =  (1e-05, 50, 128, 4, 1e-08, 0.3)\n",
      "Epoch 0; Step 0; Loss 0.693150; Train acc: 0.511719; Dev acc 0.457031\n",
      "Epoch 5; Step 135; Loss 0.693133; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693138; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693261; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.693058; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.693510; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.691916; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "499 / 576  =  (1e-05, 50, 128, 4, 1e-08, 0.5)\n",
      "Epoch 0; Step 0; Loss 0.693147; Train acc: 0.472656; Dev acc 0.437500\n",
      "Epoch 5; Step 135; Loss 0.692955; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.692931; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 15; Step 405; Loss 0.693407; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 20; Step 540; Loss 0.692800; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 25; Step 675; Loss 0.692631; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 30; Step 810; Loss 0.693143; Train acc: 0.496094; Dev acc 0.546875\n",
      "Best dev accuracy is 0.546875\n",
      "Best accuracy:  0.546875\n",
      "500 / 576  =  (1e-05, 50, 128, 4, 1e-05, 0)\n",
      "Epoch 0; Step 0; Loss 0.693142; Train acc: 0.496094; Dev acc 0.542969\n",
      "Epoch 5; Step 135; Loss 0.693108; Train acc: 0.496094; Dev acc 0.546875\n",
      "Epoch 10; Step 270; Loss 0.693336; Train acc: 0.496094; Dev acc 0.546875\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-fa186539dd2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                                  \u001b[0mtrain_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                  \u001b[0mtrain_eval_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                                  dev_iterator = eval_iter(dev_set[:500], batch_size))\n\u001b[0m",
      "\u001b[0;32m<ipython-input-40-610f28ccd542>\u001b[0m in \u001b[0;36mhparameter_search_dan\u001b[0;34m(model, model_criterion, lr_list, embed_list, hidden_size_list, num_layers_list, weight_decay_list, dropout_rates, num_epochs, train_iterator, train_eval_iterator, dev_iterator)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         best_dev_acc = training_loop(batch_size, num_epochs, dan, model_criterion, \n\u001b[0;32m---> 42\u001b[0;31m                                           optimizer, train_iterator, dev_iterator, train_eval_iterator)\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Best accuracy: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_dev_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-d554da03e80b>\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(batch_size, num_epochs, model, loss_, optim, training_iter, dev_iter, train_eval_iter, verbose)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mlossy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mlossy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dev_accs = hparameter_search_dan(DAN, model_criterion = torch.nn.CrossEntropyLoss(), \n",
    "                                 lr_list = [1e-3, 1e-4, 1e-5],\n",
    "                                 embed_list = [10, 50, 200], hidden_size_list = [64, 128],\n",
    "                                 num_layers_list = [2, 3, 4, 5], weight_decay_list = [1e-8, 1e-5], \n",
    "                                 dropout_rates = [0, 0.1, 0.3, 0.5], num_epochs = 30,\n",
    "                                 train_iterator = data_iter(training_set, batch_size),\n",
    "                                 train_eval_iterator = eval_iter(training_set[:500], batch_size),\n",
    "                                 dev_iterator = eval_iter(dev_set[:500], batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Analysis and Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def read_and_clean_(search_data_path, params = [\"lr\", \"embed_size\", \"hidden_size\",\"nlayers\",\"wd\",\"dropout\"]):\n",
    "    \"\"\"Args:\n",
    "    - search_data_path: (str) filepath to the validation accuracy data,\n",
    "    - params: (list) names of hyperparameters used in the search\n",
    "    \n",
    "    Returns:\n",
    "    - search_data: (df) cleaned DataFrame with hyperparameter sets as columns,\n",
    "                   and corresponding maximum dev accuracies as values \n",
    "                   \"\"\"\n",
    "    search_data = pd.DataFrame(pd.read_csv(search_data_path, header=None)).drop(0, 1)\n",
    "    col_num = search_data.shape[1]\n",
    "    col_params = []\n",
    "\n",
    "    for i in range(col_num):\n",
    "        col_params.append([*search_data[i + 1].iloc[:len(params)]])\n",
    "\n",
    "    col_params = [str(x) for x in col_params]\n",
    "    search_data.columns = col_params\n",
    "    search_data = search_data.iloc[len(params):]\n",
    "    search_data.index = range(len(search_data))\n",
    "    search_data = pd.DataFrame(search_data.iloc[0])\n",
    "    param_lists = [x.replace(\"[\",\"\").replace(\"]\",\"\").split(\",\") for x in search_data.index.values]\n",
    "    \n",
    "    for i in range(len(params)):\n",
    "        search_data[params[i]] = [float(x[i]) for x in param_lists]\n",
    "        \n",
    "    search_data.columns = [\"dev_acc\"] + params\n",
    "    search_data.index = range(len(search_data))\n",
    "    return search_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_data = read_and_clean_(\"dan_dev_accuracy.csv\", \n",
    "                              params = [\"lr\", \"embed_size\", \"hidden_size\",\"nlayers\",\"wd\",\"dropout\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(search_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.453125"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(search_data[\"dev_acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82421875"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(search_data[\"dev_acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "best20 = search_data.sort_values(by=\"dev_acc\", ascending=False).iloc[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Comments__: The DAN model was trained with 500 different parameter sets, and the __maximum__ development set accuracies were recorded for each. \n",
    "\n",
    "- Maximum  Dev Set Accuracy Reached by a Model: __82.4%__\n",
    "\n",
    "The 20 best models according to development accuracy are listed below. The column names show the hyperparameters, the values show the parameter value used to initialize each model, and the dev_acc column shows the maximum development set accuracy recorded for that specific model. \n",
    "\n",
    "__The hyperparameters that yielded the best dev accuracy can be seen on the first row of the best_20 dataframe below.__ Please see the further analysis below. \n",
    "\n",
    "Some notes: \n",
    "* Since lr = 1e-5 models performed very poorly - some of them were not even able to fit to the training set - I later removed those from the analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dev_acc</th>\n",
       "      <th>lr</th>\n",
       "      <th>embed_size</th>\n",
       "      <th>hidden_size</th>\n",
       "      <th>nlayers</th>\n",
       "      <th>wd</th>\n",
       "      <th>dropout</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.824219</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>10.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>0.816406</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>200.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>0.808594</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>50.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>0.808594</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>200.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.804688</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>50.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>0.804688</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>200.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>0.800781</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>200.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0.800781</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>200.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.796875</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>10.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>0.796875</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>50.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.796875</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>200.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>0.796875</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>200.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>0.796875</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>200.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.792969</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>50.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>0.792969</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>200.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>0.792969</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>200.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>0.789062</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>200.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>0.789062</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>50.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>0.789062</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>200.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.789062</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>50.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dev_acc      lr  embed_size  hidden_size  nlayers            wd  dropout\n",
       "4    0.824219  0.0010        10.0         64.0      2.0  1.000000e-05      0.0\n",
       "325  0.816406  0.0001       200.0         64.0      2.0  1.000000e-05      0.1\n",
       "287  0.808594  0.0001        50.0         64.0      5.0  1.000000e-05      0.5\n",
       "367  0.808594  0.0001       200.0        128.0      3.0  1.000000e-05      0.5\n",
       "299  0.804688  0.0001        50.0        128.0      3.0  1.000000e-08      0.5\n",
       "327  0.804688  0.0001       200.0         64.0      2.0  1.000000e-05      0.5\n",
       "329  0.800781  0.0001       200.0         64.0      3.0  1.000000e-08      0.1\n",
       "182  0.800781  0.0010       200.0        128.0      4.0  1.000000e-05      0.3\n",
       "47   0.796875  0.0010        10.0        128.0      3.0  1.000000e-05      0.5\n",
       "308  0.796875  0.0001        50.0        128.0      4.0  1.000000e-05      0.0\n",
       "130  0.796875  0.0010       200.0         64.0      2.0  1.000000e-08      0.3\n",
       "376  0.796875  0.0001       200.0        128.0      5.0  1.000000e-08      0.0\n",
       "369  0.796875  0.0001       200.0        128.0      4.0  1.000000e-08      0.1\n",
       "103  0.792969  0.0010        50.0        128.0      2.0  1.000000e-05      0.5\n",
       "380  0.792969  0.0001       200.0        128.0      5.0  1.000000e-05      0.0\n",
       "326  0.792969  0.0001       200.0         64.0      2.0  1.000000e-05      0.3\n",
       "333  0.789062  0.0001       200.0         64.0      3.0  1.000000e-05      0.1\n",
       "315  0.789062  0.0001        50.0        128.0      5.0  1.000000e-08      0.5\n",
       "361  0.789062  0.0001       200.0        128.0      3.0  1.000000e-08      0.1\n",
       "100  0.789062  0.0010        50.0        128.0      2.0  1.000000e-05      0.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# completely taking out lr = 1e-5 because those models never even\n",
    "# did good on the training set. \n",
    "search_data = search_data[(search_data[\"lr\"]!=1e-5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average Dev Accuracy by Dropout Rate\n",
    "\n",
    "It's very interesting (and convincing) to see that models with 0.5 dropout rate actually performed better on average than the models with 0.1 and 0.3 dropout rates. The plot below did not reproduce the same results as the article. This might be a result of using different hyperparameter sets or not using pretrained word embedddings as the authors did. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.rcParams[\"font.size\"] = 12\n",
    "dropouts = sorted([*set(search_data[\"dropout\"])])\n",
    "dev_acc = [np.mean(search_data[search_data[\"dropout\"]==dropouts[i]][\"dev_acc\"]) for i in range(len(dropouts))]\n",
    "plt.xlabel(\"Word Dropout Rate\")\n",
    "plt.ylabel(\"Mean Dev Set Accuracy\")\n",
    "plt.title(\"Development Set Performance\")\n",
    "plt.plot(dropouts, dev_acc, marker=\"o\", color=\"b\", alpha=0.5, linewidth=2.5, markersize=8)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average Dev Accuracy by Number of Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.rcParams[\"font.size\"] = 12\n",
    "n_layers = sorted([*set(search_data[\"nlayers\"])])\n",
    "dev_acc = [np.mean(search_data[search_data[\"nlayers\"]==n_layers[i]][\"dev_acc\"]) for i in range(len(n_layers))]\n",
    "plt.xlabel(\"Number of Layers\")\n",
    "plt.ylabel(\"Mean Dev Set Accuracy\")\n",
    "plt.title(\"Development Set Performance\")\n",
    "plt.plot(n_layers, dev_acc, marker=\"o\", color=\"b\", alpha=0.6, linewidth=2.5, markersize=8)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = sorted([*set(search_data[\"nlayers\"])])\n",
    "dropouts = sorted([*set(search_data[\"dropout\"])])\n",
    "dropout_accuracy = {}\n",
    "\n",
    "for i in n_layers:\n",
    "    dropout_accuracy[i] = []\n",
    "    for j in dropouts:\n",
    "        dropout_accuracy[i].append(np.mean(search_data[(search_data[\"nlayers\"]==i)&(search_data[\"dropout\"]==j)][\"dev_acc\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2.0: [0.6624755859375, 0.70263671875, 0.6571044921875, 0.6773681640625],\n",
       " 3.0: [0.63623046875, 0.64404296875, 0.61865234375, 0.6173095703125],\n",
       " 4.0: [0.598664314516129,\n",
       "  0.6386088709677419,\n",
       "  0.6402469758064516,\n",
       "  0.635710685483871],\n",
       " 5.0: [0.6036458333333333, 0.58203125, 0.6278645833333333, 0.6407552083333333]}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.0, 3.0, 4.0, 5.0]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Dev Accuracy')"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.rcParams[\"font.size\"] = 12\n",
    "\n",
    "for i in n_layers:\n",
    "    plt.plot(dropouts, dropout_accuracy[int(i)], marker=\"o\", markersize = 8, linewidth = 2.5,\n",
    "             label=\"layers =\" + str(i), alpha=0.5)\n",
    "    \n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.title(\"Mean Dev Accuracy by Dropout Rate for Different # Layers\")\n",
    "plt.xlabel(\"Dropout Rate\")\n",
    "plt.ylabel(\"Dev Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this plot, we can see that:\n",
    "* __2-layer__ models: The dropout rate that works the best is 0.1. This might be due to the fact that the models are relatively small and do not have the opportunity to overfit as much as the larger models do. \n",
    "* __4-layer__ models: All dropout rates greater than zero outperform 0 dropout on average, for at least 4% on dev set accuracy. \n",
    "* __5-layer__ models: More than 0.1 dropout rate is needed for the word-dropout regularization to work. We can see on the red line that models that have 0.5 dropout rate outperform the ones that have 0 dropout by 4% on average. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Dev Accuracy')"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_dropout_accuracy = {}\n",
    "for i in n_layers:\n",
    "    max_dropout_accuracy[i] = []\n",
    "    for j in dropouts:\n",
    "        max_dropout_accuracy[i].append(np.max(search_data[(search_data[\"nlayers\"]==i)&(search_data[\"dropout\"]==j)][\"dev_acc\"]))\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.rcParams[\"font.size\"] = 12\n",
    "\n",
    "for i in n_layers:\n",
    "    plt.plot(dropouts, max_dropout_accuracy[int(i)], marker=\"o\", markersize = 8, linewidth = 2.5,\n",
    "             label=\"layers =\" + str(i), alpha=0.5)\n",
    "    \n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.title(\"Max Dev Accuracy by Dropout Rate for Different # Layers\")\n",
    "plt.xlabel(\"Dropout Rate\")\n",
    "plt.ylabel(\"Dev Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average Dev Accuracy by Embedding Size\n",
    "\n",
    "As expected, the models with larger word embeddings performed better than the ones with smaller word embeddings. The larger the embeddings get, the more \"dimensions\" of the word they can express, so it is not surprising at all.\n",
    "\n",
    "One interesting thing to see below is, there is a large change in the accuracy score from size 10 to size 50. However, the marginal return got smaller from 50 to 200. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.rcParams[\"font.size\"] = 12\n",
    "embeds = sorted([*set(search_data[\"embed_size\"])])\n",
    "dev_acc = [np.mean(search_data[search_data[\"embed_size\"]==embeds[i]][\"dev_acc\"]) for i in range(len(embeds))]\n",
    "plt.xlabel(\"Embedding Size\")\n",
    "plt.ylabel(\"Mean Dev Set Accuracy\")\n",
    "plt.title(\"Development Set Performance\")\n",
    "plt.plot(embeds, dev_acc, marker=\"o\", color=\"b\", alpha=0.6, linewidth=2.5, markersize=8)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average Dev Accuracy by Hidden Size\n",
    "\n",
    "I tried 64 and 128 as hidden sizes and was expecting to see an increase in development accuracy for larger hidden size. The plot below confirms that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.rcParams[\"font.size\"] = 12\n",
    "hiddens = sorted([*set(search_data[\"hidden_size\"])])\n",
    "dev_acc = [np.mean(search_data[search_data[\"hidden_size\"]==hiddens[i]][\"dev_acc\"]) for i in range(len(hiddens))]\n",
    "plt.xlabel(\"Hidden Size\")\n",
    "plt.ylabel(\"Mean Dev Set Accuracy\")\n",
    "plt.title(\"Development Set Performance\")\n",
    "plt.plot(hiddens, dev_acc, marker=\"o\", color=\"b\", alpha=0.6, linewidth=2.5, markersize=8)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average Dev Accuracy by Learning Rate\n",
    "\n",
    "1e-4 learning rate works better for this model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.rcParams[\"font.size\"] = 12\n",
    "lrs = sorted([*set(search_data[\"lr\"])])\n",
    "dev_acc = [np.mean(search_data[search_data[\"lr\"]==lrs[i]][\"dev_acc\"]) for i in range(len(lrs))]\n",
    "plt.xlabel(\"Learning Rate\")\n",
    "plt.ylabel(\"Mean Dev Set Accuracy\")\n",
    "plt.title(\"Development Set Performance\")\n",
    "plt.plot(lrs, dev_acc, marker=\"o\", color=\"b\", alpha=0.6, linewidth=2.5, markersize=8)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Part 3: short questions (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1. Name, and briefly describe, 3 other possible composition functions, instead of the DAN, you could use to build sentence representations.__\n",
    "\n",
    "__Answer:__ We could use:\n",
    "\n",
    "- A __Convolutional Neural Network__ to compute the hidden representation of the sentences. \n",
    "\n",
    "      We can start by embedding the words in exactly the same way we did with DAN. The convolutional layer(s) in the network would consist of 1-dimensional convolutions followed by a method of pooling and a nonlinearity. After the convolutions provide the representations, there should be linear layer(s) (hidden_size x n, connected by a nonlinearity if more than one), and the last linear layer's output dimension should be equal to the number of classes that we are considering (for this problem, 2). Since we want the output of the network to reflect the assigned probabilities or log probabilities of each class, we need to add a softmax layer at the end. \n",
    "      \n",
    "- A type of __Recurrent Neural Network__ to compute the hidden representation of the sentences. \n",
    "\n",
    "        After obtaining the word embeddings, we could feed it to an LSTM or a GRU. Both of these models take into account the order in which the tokens are arranged and use gated structures to determine how much information to preserve/forget from the previous states and use from the new input token. If we used a bidirectional model (which would \"scan\" the sequence starting from both ends) we would concatenate the hidden representations obtained in each direction and feed the vector to a linear layer (hidden_size*num_directions, num_classes). Also, we could augment the unit with multiple layers, and compress the layered final hidden state by some method of aggregation, e.g. averaging over layers before feeding it into the linear layer. Then, we would obtain the class probabilities by using softmax function. \n",
    "\n",
    "- A __Phrase-level Self-Attention Network__ or PSAN. The authors suggest that, since the attention is applied phrase level, instead of sentence level, the model is better at semantically and syntactically distant information, which intuitively makes sence.\n",
    "\n",
    "        This model would also require embedding the words in the same way as we did with DAN. Then, a multi-dimensional attention mechanism computes the alignment score of tokens within a phrase for each dimension of the embedding, and a mask prevents computing a token's alignment with itself. After these alignment scores are calculated, they are used as the weights in computing the weighted sum of the token representations. Then, these representations are compared with their own weighed sums, using a comparison function. Since the model works on phrase representations, it utilizes a parsing tree and updates along the hierarchies are managed by a gated updating structure. Again, after obtaining the representation of a sentence using PSAN, we would feed it to a linear layer (hidden_size x num_classes) followed by a non-linearity and a softmax to finally obtain the class probabilities. The details can be found here: http://aclweb.org/anthology/D18-1408 \n",
    "\n",
    "__2. Explain how dropout regularizes a model.__\n",
    "\n",
    "__Answer:__\n",
    "\n",
    "    I. Dropout, as in dropping out (zeroing) some hidden units in the model, regularizes a model by creating parallel ensembles that consist of the subsets of the same model. Not using all units at each training session prevents the model from overfitting to the training data.\n",
    "    II. Word dropout used in DAN, on the other hand, randomly drops out a certain ratio of embeddings from the average, before the mean vector is fed into the linear layers. This enables the model to learn from a random subset of tokens at each training step. \n",
    "\n",
    "__3. What are the shortcomings for training for a fixed number of epochs? Give an alternative.__\n",
    "\n",
    "__Answer:__ The point where a model reaches maximum validation accuracy depends highly on both the model parameters or architecture and the hyperparameters. A model with a given hyperparameter set might find the optimum weight matrix after 20 epochs, whereas the same model with a different combination of parameters might need a smaller/greater number of epochs to find this point.\n",
    "\n",
    "On the other hand, once the model and the hyperparameters are fixed, but we are looking for the optimal number of epochs, two things might happen: \n",
    "        \n",
    "    I. When the models are trained for a fixed number of epochs, it is generally the case that they are missing the point where the maximum dev/validation accuracy is reached. Instead, stopping training once the validation accuracy stops increasing or starts decreasing (early stopping) should yield better results. \n",
    "    II. Similarly we might be training the model for a number of epochs that is too small to maximize the validation accuracy. Here we need to train for more epochs, and then use early stopping to prevent the model from over-training. \n",
    "\n",
    "__4. Explain why you might use random search rather than grid search.__\n",
    "\n",
    "__Answer:__ \n",
    "\n",
    "- With grid search, it takes a lot of time (especially when the model is a large one) to cover the whole search space you want to cover, whereas with random search we randomly select points within the search space and can alternate between remote points. Therefore random search may yield the same or better validation results more quickly. Here's a paper that empirically evaluates the two and shows that random search is actually more effective: http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf \n",
    "\n",
    "__Bonus__ (5 points): briefly describe the Nelder–Mead method and how you might use it to do hyperparamter tuning. What are the tradeoffs between using Nelder-Mead vs random search?\n",
    "\n",
    "__Answer:__ Given an objective function that consists of n variables, the Nelder-Mead method finds the local minimum of the function using a simplex or more generally a series of simplices. (A simplex is a generalized version of a triangle to an arbitrary number of dimensions.) It starts with a single simplex, compares the function value at each corner of the shape, then replaces the highest value with another point. Using this method, the algorithm generates new simplices, each smaller than the older ones, and continues its search by comparing each vertex/corner of the shape with other vertices. \n",
    "\n",
    "Changing the higher objective values with lower ones while generating smaller shapes minimizes the probability of missing the local minimum.\n",
    "\n",
    "As an example, think of a function with two variables. The search space will be a plane, and a simplex on a plane is basically a triangle. First, we compute the function values for all three vertices, and then replace the vertex with the highest value with another point $(x_m y_m)$ that has a potentially lower objective and continue with the comparison. Then we can generate another triangle by selecting another point $(x_n, y_n)$ outside of the initial shape, and compare the objective value of this point with the other two corners, and so on."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
