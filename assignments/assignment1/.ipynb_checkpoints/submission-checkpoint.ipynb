{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"tocheading\">Natural Language Understanding DS-GA 1012 Homework 1</h1>\n",
    "<div id=\"toc\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Due Feburary 13, 2019 at 2pm (ET)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch, torchvision\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "import argparse\n",
    "from collections import Counter\n",
    "import operator\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: Exploring effect of context size [30 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We face many implicit and explicit design decisions in creating distributional word representations. For example, in lecture and in lab, we created word vectors using a co-occurence matrix built on neighboring pairs of words. We might suspect, however, that we can get more signal of word similarity by considering larger contexts than pairs of words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Co-occurence Matrix\n",
    "__a__. Write `build_cooccurrence_matrix`, which generates the co-occurence matrix for a window of arbitrary size and for the vocabulary of `max_vocab_size` most frequent words. Feel free to modify the code used in lab [10 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_(string, list_of_char):\n",
    "    for x in list_of_char:\n",
    "        string = string.replace(str(x), \"\")\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_list(filepath, mode=\"w\"):\n",
    "    \"\"\"args\n",
    "        - filepath: path to text file\n",
    "        - mode: \"w\" for word, \"s\" for sentence list\n",
    "    \n",
    "    returns:\n",
    "        - text_list: word or sentence list depending on the mode\"\"\"\n",
    "    \n",
    "    text = open(filepath, \"r\")\n",
    "    \n",
    "    if mode == \"w\":\n",
    "        text_list = text.read().replace(\"\\t\",\" \").replace(\"\\n\",\" \")\n",
    "        text_list = remove_(text_list,range(10)).lower().split(\" \")[1:]\n",
    "    elif mode == \"s\":\n",
    "        text_list = text.read().split(\"\\n\")\n",
    "        text_list = [sent.replace(\"\\t\",\"\") for sent in text_list]\n",
    "        text_list = [remove_(x,range(10)).lower().split(\" \") for x in text_list][1:]\n",
    "\n",
    "    else:\n",
    "        raise ValueError (\"mode must be 'w'(word) or 's'(sentence)!\")\n",
    "        \n",
    "    return text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sentence = text_to_list(\"data/datasetSentences.txt\", \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_word = text_to_list(\"data/datasetSentences.txt\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sentence'"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_word[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cooccurrence_matrix(data, \n",
    "                              max_vocab_size=10000, \n",
    "                              context_size=1):\n",
    "    \n",
    "    \"\"\" Build a co-occurrence matrix\n",
    "    \n",
    "    args:\n",
    "        - data: iterable where each item is a list of tokens (string) \n",
    "        - max_vocab_size: maximum vocabulary size\n",
    "        - context_size: window around a word that is considered context\n",
    "            context_size=1 should consider pairs of adjacent words\n",
    "            \n",
    "    returns:\n",
    "        - co-occurrence matrix: numpy array where row i corresponds \n",
    "        to the co-occurrence counts for word i\"\"\"\n",
    "    \n",
    "    assert (type(data) == list or type(data) == np.ndarray), \"First input must be a list or a numpy ndarray!\"\n",
    "    \n",
    "    if type(data) == list:\n",
    "        assert (len(data) > 0), \"Data must be non-empty.\"\n",
    "    else:\n",
    "        assert (data.shape[0] > 0), \"Data must be non-empty.\"\n",
    "        \n",
    "    ## assuming data is a list of sentences (each split into tokens)\n",
    "    word_data = ((\" \").join([(\" \").join(x) for x in data])).split(\" \")\n",
    "    word2count = Counter(word_data)\n",
    "    sorted_by_freq = sorted(word2count.items(), \n",
    "                            key=lambda kv: kv[1])\n",
    "    \n",
    "    # vocab = {word: count} for the most frequent max_vocab_size words\n",
    "    vocab = dict(sorted_by_freq[-max_vocab_size:])\n",
    "    keys = [*vocab.keys()]\n",
    "    \n",
    "    token2id = {}\n",
    "    id2token = {}\n",
    "    \n",
    "    id2token[len(keys)] = \"<UNK>\"\n",
    "    token2id[\"<UNK>\"] = len(keys)\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        data[i] = [x if x in [*vocab.keys()] else \"<UNK>\" for x in data[i]]\n",
    "        \n",
    "    for j in range(len(keys)):\n",
    "        id2token[j] = keys[j]\n",
    "        \n",
    "    for token in keys:\n",
    "        token2id[token] = keys.index(token)\n",
    "    \n",
    "    edge = len(keys)\n",
    "    comatrix = np.zeros((edge, edge))\n",
    "    \n",
    "    # dict where each key is a unique token and each value is another dict of other unique keys \n",
    "    # that hold cooccurrence counts\n",
    "    full_keys = keys + [\"<UNK>\"]\n",
    "    occurrences = OrderedDict((key, OrderedDict((key, 0) for key in full_keys)) for key in full_keys)\n",
    "\n",
    "\n",
    "    for sent in data:\n",
    "        sent_length = len(sent)\n",
    "        if context_size >= sent_length:\n",
    "            for i in range(sent_length):\n",
    "                for item in sent:\n",
    "                    occurrences[sent[i]][item] += 1\n",
    "        else:\n",
    "            for i in range(sent_length):\n",
    "                if i <= context_size and sent_length - context_size - 1 <= i:\n",
    "                    for item in sent:\n",
    "                        occurrences[sent[i]][item] += 1\n",
    "                elif i <= context_size and sent_length - context_size - 1 > i:\n",
    "                    for item in sent[:i+context_size+1]:\n",
    "                        occurrences[sent[i]][item] += 1\n",
    "                elif i > context_size and sent_length - context_size - 1 > i:\n",
    "                    for item in sent[i-context_size:i+context_size+1]:\n",
    "                        occurrences[sent[i]][item] += 1\n",
    "                elif i > context_size and sent_length - context_size - 1 <= i:\n",
    "                    for item in sent[i-context_size:]:\n",
    "                        occurrences[sent[i]][item] += 1\n",
    "\n",
    "    for i in range(edge):\n",
    "        for key in full_keys:\n",
    "            if token2id[key] == i:\n",
    "                comatrix[token2id[key]] = np.array([occurrences[key][co] for co in [*occurrences[key].keys()]])\n",
    "                    \n",
    "    return token2id, id2token, comatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token2id, id2token, co_matrix = build_cooccurrence_matrix(data_sentence, max_vocab_size=10000, context_size=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix for Sentence Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your implementation of `build_cooccurrence_matrix` to generate the co-occurence matrix from the sentences of [SST](http://nlp.stanford.edu/~socherr/stanfordSentimentTreebank.zip) (file `datasetSentences.txt`) with `context_size=2` and `max_vocab_size=10000`. What is the co-occurrence count of the words \"the\" and \"end\"? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token2id, id2token, co_matrix = build_cooccurrence_matrix(data_sentence, max_vocab_size=10000, context_size=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f'the id: {token2id[\"the\"]}')\n",
    "print (f'and id: {token2id[\"and\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_matrix[token2id[\"the\"]][token2id[\"and\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context Size Effect\n",
    "__b__. Plot the effect of varying context size in $\\{1, 2, 3, 4\\}$ (leaving all the other settings the same) on the quality of the learned word embeddings, as measured by performance (Spearman correlation) on the word similarity dataset [MTurk-771](http://www2.mta.ac.il/~gideon/mturk771.html) between human judgments and cosine similarity of the learned word vectors (see lab). [12 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each word couple in mturk dataset\n",
    "#     get mturk similarity\n",
    "#     get vocab_size x 1 vectors from the cooccurrence matrix, normalize them\n",
    "#         AND measure their cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity(token1, token2, mturk_df, \n",
    "                   token2id, cooccurrence_matrix):\n",
    "    \n",
    "    mturk_similarity = float(mturk_df[(mturk_df[\"word1\"]==token1)\\\n",
    "                                      &(mturk_df[\"word2\"]==token2)][\"similarity\"])\n",
    "    \n",
    "    keys = [*token2id.keys()]\n",
    "    \n",
    "    if token1 not in keys or token2 not in keys:\n",
    "        co_similarity = 0\n",
    "    else:\n",
    "        co_similarity = cooccurrence_matrix[token2id[token1],token2id[token2]]\n",
    "    \n",
    "    return mturk_similarity, co_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct an mturk_similarity and a co_similarity vector and \n",
    "# get their Spearman correlation\n",
    "\n",
    "# change context size and redo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Context Size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Context Size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Context Size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Context Size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__c__. Briefly discuss the pros and cons of varying \n",
    "\n",
    "    I.  the context size \n",
    "    II.  the vocabulary size \n",
    "    III. using bigrams instead of unigrams \n",
    "    IV. using subword tokens instead of words. [8 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Pointwise Mutual Information [20 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In lecture, we introduced __pointwise mutual information__ (PMI), which addresses the issue of normalization removing information about absolute magnitudes of counts. The PMI for word $\\times$ context pair $(w,c)$ is \n",
    "\n",
    "$$\\log\\left(\\frac{P(w,c)}{P(w) \\cdot P(c)}\\right)$$\n",
    "\n",
    "with $\\log(0) = 0$. This is a measure of how far that cell's value deviates from what we would expect given the row and column sums for that cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PMI\n",
    "\n",
    "__a__. Implement `pmi`, a function which takes in a co-occurence matrix and returns the matrix with PMI normalization applied. [15 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pmi(mat):\n",
    "    \"\"\"Pointwise mutual information\n",
    "    \n",
    "    args:\n",
    "        - mat: 2d np.array to apply PMI\n",
    "        \n",
    "    returns:\n",
    "        - pmi_mat: matrix of same shape with PMI applied\n",
    "    \"\"\"    \n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply PMI to the co-occurence matrix computed above with `context_size=1`. What is the PMI between the words \"the\" and \"end\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PPMI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__b__. We also consider an extension of PMI, positive PMI (PPMI), that maps all negative PMI values to 0.0 ([Levy and Goldberg 2014](http://papers.nips.cc/paper/5477-neural-word-embedding-as-implicit-matrix-factorization)). \n",
    "Write `ppmi`, which is the same as `pmi` except it applies PPMI instead of PMI (feel free to implement it as an option of `pmi`). What is the PMI of the words \"the\" and \"start\"? The PPMI? [5 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Analyzing PMI [25 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reweight Matrix\n",
    "\n",
    "__a__. Consider the matrix `np.array([[1.0, 0.0, 0.0], [1000.0, 1000.0, 4000.0], [1000.0, 2000.0, 999.0]])`. Reweight this matrix using `ppmi`. \n",
    "\n",
    "    I. What is the value obtained for cell `[0,0]`, and \n",
    "    II. (ii) give a brief description for what is likely problematic about this value. [10 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with the Problematic Value\n",
    "__b__. Give a suggestion for dealing with the problematic value and explain why it deals with this. Demonstrate your suggestion empirically [10 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PMI for Word-Word Co-occurence Matrix\n",
    "__c__. Consider starting with a word-word co-occurence matrix and apply PMI to this matrix. \n",
    "\n",
    "        I. Which of the following describe the resulting vectors: sparse, dense, high-dimensional, low-dimensional\n",
    "        II. If you wanted the opposite style of representation, what could you do? [5 pts]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Word Analogy Evaluation [25 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word analogies provide another kind of evaluation for distributed representations. Here, we are given three vectors A, B, and C, in the relationship\n",
    "\n",
    "_A is to B as C is to __ _\n",
    "\n",
    "and asked to identify the fourth that completes the analogy. These analogies are by and large substantially easier than the classic brain-teaser analogies that used to appear on tests like the SAT, but it's still an interesting, demanding\n",
    "task. \n",
    "\n",
    "The core idea is that we make predictions by creating the vector\n",
    "\n",
    "$$(A - B) + C$$ \n",
    "\n",
    "and then ranking all vectors based on their distance from this new vector, choosing the closest as our prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analogy Completion\n",
    "__a__. Implement the function `analogy_completion`. [9 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analogy_completion(a, b, c, mat):\n",
    "    \"\"\"Compute ? in \n",
    "    a is to b as c is to ? \n",
    "    as the closest to (b-a) + c\n",
    "    \"\"\"\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GloVe\n",
    "__b__. Our simple word embeddings likely won't perform well on this task. Let's instead look at some high quality pretrained word embeddings. Write code to load 300-dimensional [GloVe word embeddings](http://nlp.stanford.edu/data/glove.840B.300d.zip) trained on 840B tokens. Each line of the file is formatted as a word followed by 300 floats that make up its corresponding word embedding (all space delimited). The entries of GloVe word embeddings are not counts, but instead are learned via machine learning. Use your `analogy_completion` code to complete the following analogies using the GloVe word embeddings. [6 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- \"Beijing\" is to \"China\" as \"Paris\" is to ?\n",
    "- \"gold\" is to \"first\" as \"silver\" is to ?\n",
    "- \"Italian\" is to \"mozzarella\" as \"American\" is to ?\n",
    "- \"research\" is to \"fun\" as \"engineering\" is to ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate GloVe\n",
    "c. Let's get a more quantitative, aggregate sense of the quality of GloVe embeddings. Load the analogies from `gram6-nationality-adjective.txt` and evaluate GloVe embeddings. Report the mean reciprocal rank of the correct answer (the last word on each line) for each analogy. [10 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Solution__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analogy_evaluation(glove_vecs, test_file, verbose=False):\n",
    "    \"\"\"Basic analogies evaluation for a file `src_filename `\n",
    "    in `question-data/`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------    \n",
    "    mat : 2d np.array\n",
    "        The VSM being evaluated.\n",
    "        \n",
    "    rownames : list of str\n",
    "        The names of the rows in `mat`.\n",
    "        \n",
    "    src_filename : str\n",
    "        Basename of the file to be evaluated. It's assumed to be in\n",
    "        `vsmdata_home`/question-data.\n",
    "        \n",
    "    distfunc : function mapping vector pairs to floats (default: `cosine`)\n",
    "        The measure of distance between vectors. Can also be `euclidean`, \n",
    "        `matching`, `jaccard`, as well as any other distance measure \n",
    "        between 1d vectors.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    (float, float)\n",
    "        The first is the mean reciprocal rank of the predictions and \n",
    "        the second is the accuracy of the predictions.\n",
    "    \n",
    "    \"\"\"\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9391509433962264, defaultdict(int, {True: 97, False: 9}))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy_evaluation(glove_vecs, \"gram6-nationality-adjective.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
